Namespace(cuda=True, directory='program_data/cpp_babi_format_Sep-29-2018-0000011', is_training_ggnn=True, log_path='program_data/cpp_babi_format_Sep-29-2018-0000011/logs', lr=0.01, manualSeed=0, model_path='program_data/cpp_babi_format_Sep-29-2018-0000011/cpp_babi_format_Sep-29-2018-0000011-104.cpkl', n_classes=104, n_hidden=50, n_steps=5, niter=150, size_vocabulary=354, state_dim=5, test_batch_size=32, testing=False, train_batch_size=128, training=True, training_percentage=1.0, verbal=True, workers=2)
Random Seed:  0
  0% 0/104 [00:00<?, ?it/s]  1% 1/104 [00:00<00:14,  7.11it/s]  2% 2/104 [00:00<00:18,  5.56it/s]  3% 3/104 [00:00<00:17,  5.79it/s]  4% 4/104 [00:00<00:18,  5.48it/s]  5% 5/104 [00:01<00:19,  5.06it/s]  6% 6/104 [00:01<00:20,  4.77it/s]  7% 7/104 [00:01<00:21,  4.56it/s]  8% 8/104 [00:01<00:24,  3.92it/s]  9% 9/104 [00:02<00:23,  4.00it/s] 10% 10/104 [00:02<00:23,  3.94it/s] 11% 11/104 [00:02<00:21,  4.40it/s] 12% 12/104 [00:02<00:18,  4.91it/s] 12% 13/104 [00:02<00:19,  4.65it/s] 13% 14/104 [00:03<00:19,  4.54it/s] 14% 15/104 [00:03<00:18,  4.85it/s] 15% 16/104 [00:03<00:19,  4.49it/s] 16% 17/104 [00:03<00:18,  4.60it/s] 17% 18/104 [00:04<00:20,  4.11it/s] 18% 19/104 [00:04<00:24,  3.54it/s] 19% 20/104 [00:04<00:20,  4.01it/s] 20% 21/104 [00:04<00:19,  4.19it/s] 21% 22/104 [00:04<00:18,  4.55it/s] 22% 23/104 [00:05<00:15,  5.15it/s] 23% 24/104 [00:05<00:20,  3.83it/s] 24% 25/104 [00:05<00:18,  4.36it/s] 25% 26/104 [00:05<00:14,  5.21it/s] 26% 27/104 [00:06<00:15,  5.05it/s] 27% 28/104 [00:06<00:13,  5.63it/s] 28% 29/104 [00:06<00:12,  5.97it/s] 30% 31/104 [00:06<00:11,  6.21it/s] 31% 32/104 [00:07<00:19,  3.76it/s] 32% 33/104 [00:07<00:16,  4.36it/s] 33% 34/104 [00:07<00:13,  5.24it/s] 34% 35/104 [00:07<00:13,  5.14it/s] 35% 36/104 [00:07<00:12,  5.33it/s] 36% 37/104 [00:07<00:12,  5.51it/s] 37% 38/104 [00:08<00:11,  5.68it/s] 38% 39/104 [00:08<00:13,  4.91it/s] 38% 40/104 [00:08<00:18,  3.47it/s] 39% 41/104 [00:09<00:16,  3.75it/s] 40% 42/104 [00:09<00:14,  4.37it/s] 41% 43/104 [00:09<00:12,  5.06it/s] 42% 44/104 [00:09<00:11,  5.15it/s] 43% 45/104 [00:09<00:10,  5.81it/s] 44% 46/104 [00:09<00:11,  5.13it/s] 45% 47/104 [00:09<00:09,  5.95it/s] 46% 48/104 [00:10<00:11,  5.07it/s] 47% 49/104 [00:10<00:10,  5.35it/s] 48% 50/104 [00:10<00:09,  5.77it/s] 49% 51/104 [00:11<00:16,  3.12it/s] 50% 52/104 [00:11<00:13,  3.74it/s] 51% 53/104 [00:11<00:11,  4.33it/s] 52% 54/104 [00:11<00:09,  5.08it/s] 53% 55/104 [00:11<00:10,  4.70it/s] 54% 56/104 [00:11<00:09,  5.20it/s] 55% 57/104 [00:12<00:08,  5.38it/s] 56% 58/104 [00:12<00:08,  5.39it/s] 57% 59/104 [00:12<00:09,  4.65it/s] 58% 60/104 [00:12<00:08,  5.23it/s] 59% 61/104 [00:12<00:07,  5.95it/s] 60% 62/104 [00:12<00:06,  6.73it/s] 61% 63/104 [00:13<00:07,  5.76it/s] 62% 64/104 [00:14<00:14,  2.75it/s] 62% 65/104 [00:14<00:11,  3.27it/s] 63% 66/104 [00:14<00:10,  3.55it/s] 64% 67/104 [00:14<00:08,  4.20it/s] 65% 68/104 [00:14<00:07,  4.75it/s] 66% 69/104 [00:14<00:08,  4.26it/s] 67% 70/104 [00:15<00:07,  4.65it/s] 68% 71/104 [00:15<00:07,  4.59it/s] 69% 72/104 [00:15<00:07,  4.50it/s] 70% 73/104 [00:15<00:06,  4.55it/s] 71% 74/104 [00:16<00:06,  4.56it/s] 72% 75/104 [00:16<00:06,  4.59it/s] 73% 76/104 [00:16<00:06,  4.59it/s] 74% 77/104 [00:17<00:10,  2.57it/s] 75% 78/104 [00:17<00:08,  3.02it/s] 76% 79/104 [00:17<00:07,  3.52it/s] 77% 80/104 [00:17<00:06,  3.62it/s] 78% 81/104 [00:18<00:05,  3.87it/s] 79% 82/104 [00:18<00:05,  4.39it/s] 80% 83/104 [00:18<00:04,  4.30it/s] 81% 84/104 [00:18<00:03,  5.01it/s] 82% 85/104 [00:18<00:03,  5.17it/s] 83% 86/104 [00:18<00:03,  5.40it/s] 84% 87/104 [00:19<00:02,  5.78it/s] 85% 88/104 [00:19<00:02,  6.45it/s] 86% 89/104 [00:19<00:02,  6.46it/s] 87% 90/104 [00:19<00:02,  6.71it/s] 88% 91/104 [00:19<00:01,  7.40it/s] 88% 92/104 [00:19<00:02,  5.61it/s] 89% 93/104 [00:20<00:01,  6.00it/s] 90% 94/104 [00:20<00:01,  5.94it/s] 91% 95/104 [00:20<00:01,  6.00it/s] 92% 96/104 [00:20<00:01,  5.61it/s] 93% 97/104 [00:21<00:02,  2.50it/s] 94% 98/104 [00:21<00:01,  3.10it/s] 95% 99/104 [00:21<00:01,  3.64it/s] 96% 100/104 [00:21<00:00,  4.13it/s] 97% 101/104 [00:22<00:00,  4.51it/s] 98% 102/104 [00:22<00:00,  4.32it/s] 99% 103/104 [00:22<00:00,  4.87it/s]100% 104/104 [00:22<00:00,  5.28it/s]
Number of all training data : 34627
Max node id : 348
  0% 0/104 [00:00<?, ?it/s]  2% 2/104 [00:00<00:10,  9.64it/s]  4% 4/104 [00:00<00:09, 10.70it/s]  6% 6/104 [00:00<00:09, 10.70it/s]  8% 8/104 [00:00<00:09, 10.15it/s]  9% 9/104 [00:00<00:09,  9.62it/s] 11% 11/104 [00:01<00:09, 10.32it/s] 12% 13/104 [00:01<00:07, 11.43it/s] 14% 15/104 [00:01<00:08, 11.02it/s] 16% 17/104 [00:01<00:07, 11.53it/s] 18% 19/104 [00:01<00:08, 10.22it/s] 20% 21/104 [00:01<00:08, 10.32it/s] 22% 23/104 [00:02<00:07, 11.02it/s] 24% 25/104 [00:02<00:07, 11.12it/s] 26% 27/104 [00:02<00:06, 11.58it/s] 28% 29/104 [00:02<00:06, 12.33it/s] 30% 31/104 [00:02<00:05, 12.79it/s] 32% 33/104 [00:02<00:05, 12.12it/s] 34% 35/104 [00:04<00:17,  3.86it/s] 36% 37/104 [00:04<00:13,  4.85it/s] 38% 39/104 [00:04<00:11,  5.67it/s] 39% 41/104 [00:04<00:09,  6.64it/s] 41% 43/104 [00:04<00:07,  8.00it/s] 43% 45/104 [00:05<00:06,  9.15it/s] 45% 47/104 [00:05<00:05,  9.74it/s] 47% 49/104 [00:05<00:05,  9.76it/s] 49% 51/104 [00:05<00:05,  9.83it/s] 51% 53/104 [00:05<00:04, 10.79it/s] 53% 55/104 [00:05<00:04, 11.06it/s] 55% 57/104 [00:06<00:04, 11.70it/s] 57% 59/104 [00:06<00:04, 10.85it/s] 59% 61/104 [00:06<00:03, 12.03it/s] 61% 63/104 [00:06<00:03, 12.00it/s] 62% 65/104 [00:06<00:03, 10.83it/s] 64% 67/104 [00:07<00:03, 11.00it/s] 66% 69/104 [00:07<00:03, 10.58it/s] 68% 71/104 [00:07<00:03, 10.56it/s] 70% 73/104 [00:07<00:03, 10.09it/s] 72% 75/104 [00:07<00:02, 10.05it/s] 74% 77/104 [00:08<00:02, 10.30it/s] 76% 79/104 [00:08<00:02, 10.56it/s] 78% 81/104 [00:08<00:02,  9.87it/s] 80% 83/104 [00:08<00:02,  9.99it/s] 82% 85/104 [00:08<00:01, 10.85it/s] 84% 87/104 [00:08<00:01, 11.50it/s] 86% 89/104 [00:09<00:01, 12.43it/s] 88% 91/104 [00:09<00:00, 13.49it/s] 89% 93/104 [00:09<00:00, 12.19it/s] 91% 95/104 [00:10<00:02,  3.72it/s] 93% 97/104 [00:10<00:01,  4.70it/s] 95% 99/104 [00:11<00:00,  5.80it/s] 97% 101/104 [00:11<00:00,  6.80it/s] 99% 103/104 [00:11<00:00,  7.55it/s]100% 104/104 [00:11<00:00,  9.00it/s]
Number of all testing data : 17367
Max node id : 353
/opt/conda/lib/python3.6/site-packages/torch/onnx/utils.py:365: UserWarning: ONNX export failed on ATen operator stack because torch.onnx.symbolic.stack does not exist
  .format(op_name, op_name))
/opt/conda/lib/python3.6/site-packages/tensorboardX/pytorch_graph.py:43: UserWarning: Error getting attributes of node %68 : Dynamic = onnx::Constant[value={1}](), scope: GGNN/Propogator[propogator], error is VariableType::ID() not implemented
  warnings.warn("Error getting attributes of node {}, error is {}".format(attrs, e))
/opt/conda/lib/python3.6/site-packages/tensorboardX/pytorch_graph.py:43: UserWarning: Error getting attributes of node %113 : Dynamic = onnx::Constant[value={1}](), scope: GGNN/Propogator[propogator], error is VariableType::ID() not implemented
  warnings.warn("Error getting attributes of node {}, error is {}".format(attrs, e))
/opt/conda/lib/python3.6/site-packages/tensorboardX/pytorch_graph.py:43: UserWarning: Error getting attributes of node %158 : Dynamic = onnx::Constant[value={1}](), scope: GGNN/Propogator[propogator], error is VariableType::ID() not implemented
  warnings.warn("Error getting attributes of node {}, error is {}".format(attrs, e))
/opt/conda/lib/python3.6/site-packages/tensorboardX/pytorch_graph.py:43: UserWarning: Error getting attributes of node %203 : Dynamic = onnx::Constant[value={1}](), scope: GGNN/Propogator[propogator], error is VariableType::ID() not implemented
  warnings.warn("Error getting attributes of node {}, error is {}".format(attrs, e))
/opt/conda/lib/python3.6/site-packages/tensorboardX/pytorch_graph.py:43: UserWarning: Error getting attributes of node %248 : Dynamic = onnx::Constant[value={1}](), scope: GGNN/Propogator[propogator], error is VariableType::ID() not implemented
  warnings.warn("Error getting attributes of node {}, error is {}".format(attrs, e))
[0/150][0/271] Loss: 4.6421
[0/150][28/271] Loss: 4.6175
[0/150][56/271] Loss: 4.5724
[0/150][84/271] Loss: 4.5345
[0/150][112/271] Loss: 4.5433
[0/150][140/271] Loss: 4.4401
[0/150][168/271] Loss: 4.4717
[0/150][196/271] Loss: 4.4782
[0/150][224/271] Loss: 4.4082
[0/150][252/271] Loss: 4.4241
Test set: Average loss: 0.1386, Accuracy: 4123/17367 (23%)
[1/150][0/271] Loss: 4.4577
[1/150][28/271] Loss: 4.4828
[1/150][56/271] Loss: 4.3642
[1/150][84/271] Loss: 4.3769
[1/150][112/271] Loss: 4.4026
[1/150][140/271] Loss: 4.3827
[1/150][168/271] Loss: 4.3578
[1/150][196/271] Loss: 4.3965
[1/150][224/271] Loss: 4.4158
[1/150][252/271] Loss: 4.4239
Test set: Average loss: 0.1376, Accuracy: 4648/17367 (26%)
[2/150][0/271] Loss: 4.3728
[2/150][28/271] Loss: 4.3054
[2/150][56/271] Loss: 4.3879
[2/150][84/271] Loss: 4.3595
[2/150][112/271] Loss: 4.3278
[2/150][140/271] Loss: 4.3389
[2/150][168/271] Loss: 4.4198
[2/150][196/271] Loss: 4.3660
[2/150][224/271] Loss: 4.3653
[2/150][252/271] Loss: 4.4256
Test set: Average loss: 0.1366, Accuracy: 5225/17367 (30%)
[3/150][0/271] Loss: 4.3376
[3/150][28/271] Loss: 4.2020
[3/150][56/271] Loss: 4.3081
[3/150][84/271] Loss: 4.3914
[3/150][112/271] Loss: 4.3161
[3/150][140/271] Loss: 4.3364
[3/150][168/271] Loss: 4.2757
[3/150][196/271] Loss: 4.3806
[3/150][224/271] Loss: 4.3576
[3/150][252/271] Loss: 4.2644
Test set: Average loss: 0.1351, Accuracy: 6038/17367 (34%)
[4/150][0/271] Loss: 4.3445
[4/150][28/271] Loss: 4.2857
[4/150][56/271] Loss: 4.2682
[4/150][84/271] Loss: 4.2829
[4/150][112/271] Loss: 4.3397
[4/150][140/271] Loss: 4.2916
[4/150][168/271] Loss: 4.2965
[4/150][196/271] Loss: 4.2801
[4/150][224/271] Loss: 4.2804
[4/150][252/271] Loss: 4.3071
Test set: Average loss: 0.1348, Accuracy: 6196/17367 (35%)
[5/150][0/271] Loss: 4.3265
[5/150][28/271] Loss: 4.2513
[5/150][56/271] Loss: 4.3021
[5/150][84/271] Loss: 4.3065
[5/150][112/271] Loss: 4.2866
[5/150][140/271] Loss: 4.2687
[5/150][168/271] Loss: 4.3405
[5/150][196/271] Loss: 4.2785
[5/150][224/271] Loss: 4.2860
[5/150][252/271] Loss: 4.2781
Test set: Average loss: 0.1344, Accuracy: 6422/17367 (36%)
[6/150][0/271] Loss: 4.2446
[6/150][28/271] Loss: 4.4138
[6/150][56/271] Loss: 4.2575
[6/150][84/271] Loss: 4.2898
[6/150][112/271] Loss: 4.2545
[6/150][140/271] Loss: 4.2851
[6/150][168/271] Loss: 4.3559
[6/150][196/271] Loss: 4.2657
[6/150][224/271] Loss: 4.2718
[6/150][252/271] Loss: 4.2842
Test set: Average loss: 0.1341, Accuracy: 6567/17367 (37%)
[7/150][0/271] Loss: 4.2812
[7/150][28/271] Loss: 4.3051
[7/150][56/271] Loss: 4.2500
[7/150][84/271] Loss: 4.2790
[7/150][112/271] Loss: 4.2187
[7/150][140/271] Loss: 4.2763
[7/150][168/271] Loss: 4.2666
[7/150][196/271] Loss: 4.3005
[7/150][224/271] Loss: 4.2630
[7/150][252/271] Loss: 4.2381
Test set: Average loss: 0.1337, Accuracy: 6746/17367 (38%)
[8/150][0/271] Loss: 4.1931
[8/150][28/271] Loss: 4.2324
[8/150][56/271] Loss: 4.2300
[8/150][84/271] Loss: 4.1120
[8/150][112/271] Loss: 4.2221
[8/150][140/271] Loss: 4.2317
[8/150][168/271] Loss: 4.2368
[8/150][196/271] Loss: 4.2845
[8/150][224/271] Loss: 4.3386
[8/150][252/271] Loss: 4.2777
Test set: Average loss: 0.1335, Accuracy: 6893/17367 (39%)
[9/150][0/271] Loss: 4.2373
[9/150][28/271] Loss: 4.2505
[9/150][56/271] Loss: 4.1933
[9/150][84/271] Loss: 4.2300
[9/150][112/271] Loss: 4.2060
[9/150][140/271] Loss: 4.3283
[9/150][168/271] Loss: 4.2331
[9/150][196/271] Loss: 4.2032
[9/150][224/271] Loss: 4.3413
[9/150][252/271] Loss: 4.2746
Test set: Average loss: 0.1333, Accuracy: 6957/17367 (40%)
[10/150][0/271] Loss: 4.1980
[10/150][28/271] Loss: 4.2351
[10/150][56/271] Loss: 4.2875
[10/150][84/271] Loss: 4.2102
[10/150][112/271] Loss: 4.2194
[10/150][140/271] Loss: 4.1785
[10/150][168/271] Loss: 4.1824
[10/150][196/271] Loss: 4.2521
[10/150][224/271] Loss: 4.2971
[10/150][252/271] Loss: 4.2818
Test set: Average loss: 0.1331, Accuracy: 7099/17367 (40%)
[11/150][0/271] Loss: 4.2354
[11/150][28/271] Loss: 4.2481
[11/150][56/271] Loss: 4.1973
[11/150][84/271] Loss: 4.1259
[11/150][112/271] Loss: 4.2024
[11/150][140/271] Loss: 4.2643
[11/150][168/271] Loss: 4.2260
[11/150][196/271] Loss: 4.2141
[11/150][224/271] Loss: 4.1664
[11/150][252/271] Loss: 4.2328
Test set: Average loss: 0.1331, Accuracy: 7068/17367 (40%)
[12/150][0/271] Loss: 4.2221
[12/150][28/271] Loss: 4.2263
[12/150][56/271] Loss: 4.2262
[12/150][84/271] Loss: 4.1767
[12/150][112/271] Loss: 4.1885
[12/150][140/271] Loss: 4.2907
[12/150][168/271] Loss: 4.1867
[12/150][196/271] Loss: 4.2400
[12/150][224/271] Loss: 4.1981
[12/150][252/271] Loss: 4.2568
Test set: Average loss: 0.1331, Accuracy: 7094/17367 (40%)
[13/150][0/271] Loss: 4.2118
[13/150][28/271] Loss: 4.2172
[13/150][56/271] Loss: 4.2360
[13/150][84/271] Loss: 4.1759
[13/150][112/271] Loss: 4.1897
[13/150][140/271] Loss: 4.2847
[13/150][168/271] Loss: 4.2090
[13/150][196/271] Loss: 4.2430
[13/150][224/271] Loss: 4.2340
[13/150][252/271] Loss: 4.1859
Test set: Average loss: 0.1327, Accuracy: 7298/17367 (42%)
[14/150][0/271] Loss: 4.2144
[14/150][28/271] Loss: 4.3081
[14/150][56/271] Loss: 4.2220
[14/150][84/271] Loss: 4.2741
[14/150][112/271] Loss: 4.1264
[14/150][140/271] Loss: 4.1509
[14/150][168/271] Loss: 4.1701
[14/150][196/271] Loss: 4.2292
[14/150][224/271] Loss: 4.2005
[14/150][252/271] Loss: 4.1936
Test set: Average loss: 0.1327, Accuracy: 7300/17367 (42%)
[15/150][0/271] Loss: 4.2124
[15/150][28/271] Loss: 4.1769
[15/150][56/271] Loss: 4.1757
[15/150][84/271] Loss: 4.1377
[15/150][112/271] Loss: 4.2326
[15/150][140/271] Loss: 4.2257
[15/150][168/271] Loss: 4.2092
[15/150][196/271] Loss: 4.1780
[15/150][224/271] Loss: 4.2261
[15/150][252/271] Loss: 4.1627
Test set: Average loss: 0.1328, Accuracy: 7216/17367 (41%)
[16/150][0/271] Loss: 4.2653
[16/150][28/271] Loss: 4.2245
[16/150][56/271] Loss: 4.2532
[16/150][84/271] Loss: 4.2288
[16/150][112/271] Loss: 4.1738
[16/150][140/271] Loss: 4.2970
[16/150][168/271] Loss: 4.1693
[16/150][196/271] Loss: 4.1838
[16/150][224/271] Loss: 4.2143
[16/150][252/271] Loss: 4.2233
Test set: Average loss: 0.1327, Accuracy: 7269/17367 (41%)
[17/150][0/271] Loss: 4.2172
[17/150][28/271] Loss: 4.2527
[17/150][56/271] Loss: 4.2458
[17/150][84/271] Loss: 4.1806
[17/150][112/271] Loss: 4.1674
[17/150][140/271] Loss: 4.2300
[17/150][168/271] Loss: 4.2441
[17/150][196/271] Loss: 4.2280
[17/150][224/271] Loss: 4.2234
[17/150][252/271] Loss: 4.1681
Test set: Average loss: 0.1326, Accuracy: 7317/17367 (42%)
[18/150][0/271] Loss: 4.2069
[18/150][28/271] Loss: 4.2151
[18/150][56/271] Loss: 4.2411
[18/150][84/271] Loss: 4.1874
[18/150][112/271] Loss: 4.1301
[18/150][140/271] Loss: 4.2140
[18/150][168/271] Loss: 4.1429
[18/150][196/271] Loss: 4.2377
[18/150][224/271] Loss: 4.1961
[18/150][252/271] Loss: 4.2098
Test set: Average loss: 0.1326, Accuracy: 7334/17367 (42%)
[19/150][0/271] Loss: 4.1462
[19/150][28/271] Loss: 4.1867
[19/150][56/271] Loss: 4.2427
[19/150][84/271] Loss: 4.2287
[19/150][112/271] Loss: 4.2030
[19/150][140/271] Loss: 4.1808
[19/150][168/271] Loss: 4.1829
[19/150][196/271] Loss: 4.2246
[19/150][224/271] Loss: 4.2718


[19/150][252/271] Loss: 4.1703

Test set: Average loss: 0.1325, Accuracy: 7398/17367 (42%)
[20/150][0/271] Loss: 4.1885
[20/150][28/271] Loss: 4.1747
[20/150][56/271] Loss: 4.1586
[20/150][84/271] Loss: 4.2157
[20/150][112/271] Loss: 4.1715
[20/150][140/271] Loss: 4.2504
[20/150][168/271] Loss: 4.1778
[20/150][196/271] Loss: 4.2094
[20/150][224/271] Loss: 4.2100
[20/150][252/271] Loss: 4.1347
Test set: Average loss: 0.1325, Accuracy: 7402/17367 (42%)
[21/150][0/271] Loss: 4.2826
[21/150][28/271] Loss: 4.2096
[21/150][56/271] Loss: 4.2285
[21/150][84/271] Loss: 4.2419
[21/150][112/271] Loss: 4.2650
[21/150][140/271] Loss: 4.0950
[21/150][168/271] Loss: 4.2264
[21/150][196/271] Loss: 4.1669
[21/150][224/271] Loss: 4.1827
[21/150][252/271] Loss: 4.2166
Test set: Average loss: 0.1325, Accuracy: 7392/17367 (42%)
[22/150][0/271] Loss: 4.2234
[22/150][28/271] Loss: 4.1317
[22/150][56/271] Loss: 4.1496
[22/150][84/271] Loss: 4.1757
[22/150][112/271] Loss: 4.2762
[22/150][140/271] Loss: 4.1302
[22/150][168/271] Loss: 4.1630
[22/150][196/271] Loss: 4.1546
[22/150][224/271] Loss: 4.2047
[22/150][252/271] Loss: 4.2551
Test set: Average loss: 0.1323, Accuracy: 7486/17367 (43%)
[23/150][0/271] Loss: 4.2323
[23/150][28/271] Loss: 4.1428
[23/150][56/271] Loss: 4.2733
[23/150][84/271] Loss: 4.1459
[23/150][112/271] Loss: 4.2528
[23/150][140/271] Loss: 4.1821
[23/150][168/271] Loss: 4.2290
[23/150][196/271] Loss: 4.1234
[23/150][224/271] Loss: 4.2297
[23/150][252/271] Loss: 4.2096
Test set: Average loss: 0.1326, Accuracy: 7344/17367 (42%)
[24/150][0/271] Loss: 4.2232
[24/150][28/271] Loss: 4.1618
[24/150][56/271] Loss: 4.2451
[24/150][84/271] Loss: 4.1887
[24/150][112/271] Loss: 4.2013
[24/150][140/271] Loss: 4.2441
[24/150][168/271] Loss: 4.1167
[24/150][196/271] Loss: 4.1260
[24/150][224/271] Loss: 4.2506
[24/150][252/271] Loss: 4.1693
Test set: Average loss: 0.1321, Accuracy: 7609/17367 (43%)
[25/150][0/271] Loss: 4.2515
[25/150][28/271] Loss: 4.1655
[25/150][56/271] Loss: 4.2162
[25/150][84/271] Loss: 4.1474
[25/150][112/271] Loss: 4.1773
[25/150][140/271] Loss: 4.1882
[25/150][168/271] Loss: 4.1118
[25/150][196/271] Loss: 4.1769
[25/150][224/271] Loss: 4.1237
[25/150][252/271] Loss: 4.2242
Test set: Average loss: 0.1322, Accuracy: 7557/17367 (43%)
[26/150][0/271] Loss: 4.1674
[26/150][28/271] Loss: 4.1559
[26/150][56/271] Loss: 4.1819
[26/150][84/271] Loss: 4.1849
[26/150][112/271] Loss: 4.1660
[26/150][140/271] Loss: 4.2352
[26/150][168/271] Loss: 4.1290
[26/150][196/271] Loss: 4.1783
[26/150][224/271] Loss: 4.1382
[26/150][252/271] Loss: 4.2257
Test set: Average loss: 0.1323, Accuracy: 7513/17367 (43%)
[27/150][0/271] Loss: 4.1785
[27/150][28/271] Loss: 4.2405
[27/150][56/271] Loss: 4.2294
[27/150][84/271] Loss: 4.2140
[27/150][112/271] Loss: 4.1900
[27/150][140/271] Loss: 4.2229
[27/150][168/271] Loss: 4.2603
[27/150][196/271] Loss: 4.0660
[27/150][224/271] Loss: 4.1995
[27/150][252/271] Loss: 4.2414
Test set: Average loss: 0.1321, Accuracy: 7638/17367 (43%)
[28/150][0/271] Loss: 4.1203
[28/150][28/271] Loss: 4.1897
[28/150][56/271] Loss: 4.1973
[28/150][84/271] Loss: 4.2492
[28/150][112/271] Loss: 4.2730
[28/150][140/271] Loss: 4.1820
[28/150][168/271] Loss: 4.0914
[28/150][196/271] Loss: 4.1616
[28/150][224/271] Loss: 4.1889
[28/150][252/271] Loss: 4.1564
Test set: Average loss: 0.1322, Accuracy: 7559/17367 (43%)
[29/150][0/271] Loss: 4.1228
[29/150][28/271] Loss: 4.1998
[29/150][56/271] Loss: 4.0538
[29/150][84/271] Loss: 4.1648
[29/150][112/271] Loss: 4.1787
[29/150][140/271] Loss: 4.1781
[29/150][168/271] Loss: 4.2003
[29/150][196/271] Loss: 4.1679
[29/150][224/271] Loss: 4.1383
[29/150][252/271] Loss: 4.1578
Test set: Average loss: 0.1322, Accuracy: 7557/17367 (43%)
[30/150][0/271] Loss: 4.1024
[30/150][28/271] Loss: 4.1874
[30/150][56/271] Loss: 4.1745
[30/150][84/271] Loss: 4.1430
[30/150][112/271] Loss: 4.2227
[30/150][140/271] Loss: 4.2767
[30/150][168/271] Loss: 4.2534
[30/150][196/271] Loss: 4.1165
[30/150][224/271] Loss: 4.1743
[30/150][252/271] Loss: 4.1905
Test set: Average loss: 0.1320, Accuracy: 7654/17367 (44%)
[31/150][0/271] Loss: 4.2015
[31/150][28/271] Loss: 4.1524
[31/150][56/271] Loss: 4.1870
[31/150][84/271] Loss: 4.1336
[31/150][112/271] Loss: 4.1374
[31/150][140/271] Loss: 4.1551
[31/150][168/271] Loss: 4.2297
[31/150][196/271] Loss: 4.1327
[31/150][224/271] Loss: 4.1376
[31/150][252/271] Loss: 4.2049
Test set: Average loss: 0.1322, Accuracy: 7538/17367 (43%)
[32/150][0/271] Loss: 4.2320
[32/150][28/271] Loss: 4.1992
[32/150][56/271] Loss: 4.0848
[32/150][84/271] Loss: 4.2362
[32/150][112/271] Loss: 4.2117
[32/150][140/271] Loss: 4.2476
[32/150][168/271] Loss: 4.2018
[32/150][196/271] Loss: 4.1626
[32/150][224/271] Loss: 4.0996
[32/150][252/271] Loss: 4.1488
Test set: Average loss: 0.1321, Accuracy: 7571/17367 (43%)
[33/150][0/271] Loss: 4.1959
[33/150][28/271] Loss: 4.1481
[33/150][56/271] Loss: 4.1030
[33/150][84/271] Loss: 4.1792
[33/150][112/271] Loss: 4.1268
[33/150][140/271] Loss: 4.2037
[33/150][168/271] Loss: 4.2212
[33/150][196/271] Loss: 4.1521
[33/150][224/271] Loss: 4.1538
[33/150][252/271] Loss: 4.1198
Test set: Average loss: 0.1321, Accuracy: 7598/17367 (43%)
[34/150][0/271] Loss: 4.2374
[34/150][28/271] Loss: 4.1902
[34/150][56/271] Loss: 4.1639
[34/150][84/271] Loss: 4.1215
[34/150][112/271] Loss: 4.1852
[34/150][140/271] Loss: 4.2576
[34/150][168/271] Loss: 4.1771
[34/150][196/271] Loss: 4.1243
[34/150][224/271] Loss: 4.2083
[34/150][252/271] Loss: 4.1736
Test set: Average loss: 0.1323, Accuracy: 7502/17367 (43%)
[35/150][0/271] Loss: 4.1113
[35/150][28/271] Loss: 4.2176
[35/150][56/271] Loss: 4.1914
[35/150][84/271] Loss: 4.1447
[35/150][112/271] Loss: 4.1471
[35/150][140/271] Loss: 4.2078
[35/150][168/271] Loss: 4.1930
[35/150][196/271] Loss: 4.2255
[35/150][224/271] Loss: 4.2807
[35/150][252/271] Loss: 4.2433
Test set: Average loss: 0.1320, Accuracy: 7668/17367 (44%)
[36/150][0/271] Loss: 4.1840
[36/150][28/271] Loss: 4.1740
[36/150][56/271] Loss: 4.0987
[36/150][84/271] Loss: 4.1542
[36/150][112/271] Loss: 4.2258
[36/150][140/271] Loss: 4.1734
[36/150][168/271] Loss: 4.2005
[36/150][196/271] Loss: 4.1415
[36/150][224/271] Loss: 4.1337
[36/150][252/271] Loss: 4.1177
Test set: Average loss: 0.1321, Accuracy: 7633/17367 (43%)
[37/150][0/271] Loss: 4.1464
[37/150][28/271] Loss: 4.0845
[37/150][56/271] Loss: 4.1568
[37/150][84/271] Loss: 4.1604
[37/150][112/271] Loss: 4.1229
[37/150][140/271] Loss: 4.0986
[37/150][168/271] Loss: 4.1019
[37/150][196/271] Loss: 4.1766
[37/150][224/271] Loss: 4.2022
[37/150][252/271] Loss: 4.1753
Test set: Average loss: 0.1320, Accuracy: 7641/17367 (43%)
[38/150][0/271] Loss: 4.1942
[38/150][28/271] Loss: 4.1280
[38/150][56/271] Loss: 4.2159


^CProcess Process-153:
Traceback (most recent call last):
  File "/opt/conda/lib/python3.6/multiprocessing/process.py", line 258, in _bootstrap
    self.run()
  File "/opt/conda/lib/python3.6/multiprocessing/process.py", line 93, in run
    self._target(*self._args, **self._kwargs)
  File "/opt/conda/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 52, in _worker_loop
    r = index_queue.get()
  File "/opt/conda/lib/python3.6/multiprocessing/queues.py", line 335, in get
    res = self._reader.recv_bytes()
  File "/opt/conda/lib/python3.6/multiprocessing/connection.py", line 216, in recv_bytes
    buf = self._recv_bytes(maxlength)
  File "/opt/conda/lib/python3.6/multiprocessing/connection.py", line 407, in _recv_bytes
    buf = self._recv(4)
  File "/opt/conda/lib/python3.6/multiprocessing/connection.py", line 379, in _recv
    chunk = read(handle, remaining)
KeyboardInterrupt
Traceback (most recent call last):
  File "main_ggnn.py", line 102, in <module>
    main(opt)
  File "main_ggnn.py", line 93, in main
    train(epoch, train_dataloader, net, criterion, optimizer, opt, writer)
  File "/e/utils/train_ggnn.py", line 17, in train
    adj_matrix = adj_matrix.cuda()
KeyboardInterrupt
zz(23%)
(26%)
(30%)
(34%)
(35%)
(36%)
(37%)
(38%)
(39%)
(40%)
(40%)
(40%)
(40%)
(41%)
(41%)
(42%)
(42%)
(42%)
(42%)
(42%)
(42%)
(42%)
(42%)
(43%)
(43%)
(43%)
(43%)
(43%)
(43%)
(43%)
(43%)
(43%)
(43%)
(43%)
(43%)
(43%)
(44%)
(44%)
