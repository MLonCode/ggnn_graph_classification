Namespace(cuda=True, is_training_ggnn=False, left_directory='program_data/github_cpp_babi_format_Oct-15-2018-0000024', log_path='program_data/github_cpp_babi_format_Oct-15-2018-0000024/logs', loss=0, lr=0.01, manualSeed=0, model_path='program_data/github_cpp_babi_format_Oct-15-2018-0000024/left-github_cpp_babi_format_Oct-15-2018-0000024-50.cpkl', n_classes=50, n_hidden=50, n_steps=8, niter=300, right_directory='program_data/cll_github_java_babi_format_Oct-15-2018-0000024', size_vocabulary=172, state_dim=5, test_batch_size=128, testing=False, train_batch_size=128, training=True, verbal=True, workers=2)
Random Seed:  0
Training Bi-GGNN with cross entropy loss................
Loading data...............
Number of all left training data : 3271
Number of all right training data : 3134
398
620
Left max node id : 172
Right max node id : 171
0it [00:00, ?it/s]50it [00:00, 9149.88it/s]
Number of all 1 pairs data : 3115
Number of all 0 pairs data : 3115
  0% 0/50 [00:00<?, ?it/s] 10% 5/50 [00:00<00:00, 47.12it/s] 20% 10/50 [00:00<00:00, 47.51it/s] 28% 14/50 [00:00<00:00, 40.17it/s] 38% 19/50 [00:00<00:00, 41.93it/s] 46% 23/50 [00:00<00:01, 24.88it/s] 60% 30/50 [00:00<00:00, 30.28it/s] 70% 35/50 [00:00<00:00, 34.15it/s] 80% 40/50 [00:01<00:00, 37.60it/s] 90% 45/50 [00:01<00:00, 37.28it/s]100% 50/50 [00:01<00:00, 36.13it/s]
  0% 0/50 [00:00<?, ?it/s] 16% 8/50 [00:00<00:00, 64.31it/s] 28% 14/50 [00:00<00:00, 56.09it/s] 42% 21/50 [00:00<00:00, 59.38it/s] 60% 30/50 [00:00<00:00, 40.10it/s] 76% 38/50 [00:00<00:00, 45.33it/s] 88% 44/50 [00:01<00:00, 45.54it/s] 98% 49/50 [00:01<00:00, 45.33it/s]100% 50/50 [00:01<00:00, 43.99it/s]
Number of all left testing data : 1653
Number of all right testing data : 1598
192
316
Left max node id : 172
Right max node id : 171
0it [00:00, ?it/s]50it [00:00, 14593.96it/s]
Number of all 1 pairs data : 1589
Number of all 0 pairs data : 1589
[0/300][0/49] Loss: 0.8028
[0/300][5/49] Loss: 0.8320
[0/300][10/49] Loss: 0.7507
[0/300][15/49] Loss: 0.6930
[0/300][20/49] Loss: 0.7024
[0/300][25/49] Loss: 0.7326
[0/300][30/49] Loss: 0.6918
[0/300][35/49] Loss: 0.6930
[0/300][40/49] Loss: 0.7361
[0/300][45/49] Loss: 0.6964
Saving model................
Test set: Average loss: 0.0055, Accuracy: 3115/6230 (50%)
[1/300][0/49] Loss: 0.6948
[1/300][5/49] Loss: 0.6938
[1/300][10/49] Loss: 0.6986
[1/300][15/49] Loss: 0.6909
[1/300][20/49] Loss: 0.6901
[1/300][25/49] Loss: 0.6934
[1/300][30/49] Loss: 0.6777
[1/300][35/49] Loss: 0.6937
[1/300][40/49] Loss: 0.6950
[1/300][45/49] Loss: 0.6927
Saving model................
Test set: Average loss: 0.0055, Accuracy: 3115/6230 (50%)
[2/300][0/49] Loss: 0.6970
[2/300][5/49] Loss: 0.6903
[2/300][10/49] Loss: 0.6921
[2/300][15/49] Loss: 0.6990
[2/300][20/49] Loss: 0.6940
[2/300][25/49] Loss: 0.6937
[2/300][30/49] Loss: 0.6966
[2/300][35/49] Loss: 0.6939
[2/300][40/49] Loss: 0.6941
[2/300][45/49] Loss: 0.7054
Saving model................
Test set: Average loss: 0.0055, Accuracy: 3115/6230 (50%)
[3/300][0/49] Loss: 0.7020
[3/300][5/49] Loss: 0.6831
[3/300][10/49] Loss: 0.7019
[3/300][15/49] Loss: 0.6899
[3/300][20/49] Loss: 0.6900
[3/300][25/49] Loss: 0.6935
[3/300][30/49] Loss: 0.6928
[3/300][35/49] Loss: 0.6938
[3/300][40/49] Loss: 0.6924
[3/300][45/49] Loss: 0.6922
Saving model................
Test set: Average loss: 0.0055, Accuracy: 3115/6230 (50%)
[4/300][0/49] Loss: 0.6970
[4/300][5/49] Loss: 0.6950
[4/300][10/49] Loss: 0.6900
[4/300][15/49] Loss: 0.6982
[4/300][20/49] Loss: 0.6884
[4/300][25/49] Loss: 0.6923
[4/300][30/49] Loss: 0.6933
[4/300][35/49] Loss: 0.7084
[4/300][40/49] Loss: 0.6937
[4/300][45/49] Loss: 0.6808
Saving model................
Test set: Average loss: 0.0055, Accuracy: 3115/6230 (50%)
[5/300][0/49] Loss: 0.6947
[5/300][5/49] Loss: 0.6931
[5/300][10/49] Loss: 0.6924
[5/300][15/49] Loss: 0.6926
[5/300][20/49] Loss: 0.6958
[5/300][25/49] Loss: 0.6933
[5/300][30/49] Loss: 0.7037
[5/300][35/49] Loss: 0.6925
[5/300][40/49] Loss: 0.6944
[5/300][45/49] Loss: 0.6911
Saving model................
Test set: Average loss: 0.0055, Accuracy: 3115/6230 (50%)
[6/300][0/49] Loss: 0.6922
[6/300][5/49] Loss: 0.6905
[6/300][10/49] Loss: 0.6958
[6/300][15/49] Loss: 0.6917
[6/300][20/49] Loss: 0.6901
[6/300][25/49] Loss: 0.6936
[6/300][30/49] Loss: 0.6951
[6/300][35/49] Loss: 0.6928
[6/300][40/49] Loss: 0.6933
[6/300][45/49] Loss: 0.7006
Saving model................
Test set: Average loss: 0.0055, Accuracy: 3115/6230 (50%)
[7/300][0/49] Loss: 0.6932
[7/300][5/49] Loss: 0.7196
[7/300][10/49] Loss: 0.7051
[7/300][15/49] Loss: 0.6959
[7/300][20/49] Loss: 0.7127
[7/300][25/49] Loss: 0.6926
[7/300][30/49] Loss: 0.6900
[7/300][35/49] Loss: 0.6908
[7/300][40/49] Loss: 0.6928
[7/300][45/49] Loss: 0.6946
Saving model................
Test set: Average loss: 0.0055, Accuracy: 3115/6230 (50%)
[8/300][0/49] Loss: 0.6978
[8/300][5/49] Loss: 0.6902
[8/300][10/49] Loss: 0.6944
[8/300][15/49] Loss: 0.6993
[8/300][20/49] Loss: 0.6929
[8/300][25/49] Loss: 0.6953
[8/300][30/49] Loss: 0.6975
[8/300][35/49] Loss: 0.6888
[8/300][40/49] Loss: 0.6939
[8/300][45/49] Loss: 0.6869
Saving model................
Test set: Average loss: 0.0055, Accuracy: 3115/6230 (50%)
[9/300][0/49] Loss: 0.6946
[9/300][5/49] Loss: 0.6944
[9/300][10/49] Loss: 0.6932
[9/300][15/49] Loss: 0.6939
[9/300][20/49] Loss: 0.6900
[9/300][25/49] Loss: 0.7163
[9/300][30/49] Loss: 0.6891
[9/300][35/49] Loss: 0.6919
[9/300][40/49] Loss: 0.6975
[9/300][45/49] Loss: 0.7060
Saving model................
Test set: Average loss: 0.0055, Accuracy: 3115/6230 (50%)
[10/300][0/49] Loss: 0.6969
[10/300][5/49] Loss: 0.6876
[10/300][10/49] Loss: 0.7027
[10/300][15/49] Loss: 0.6991
[10/300][20/49] Loss: 0.6943
[10/300][25/49] Loss: 0.6934
[10/300][30/49] Loss: 0.6922
[10/300][35/49] Loss: 0.6929
[10/300][40/49] Loss: 0.6956
[10/300][45/49] Loss: 0.6976
Saving model................
Test set: Average loss: 0.0055, Accuracy: 3113/6230 (49%)
[11/300][0/49] Loss: 0.6955
[11/300][5/49] Loss: 0.6889
[11/300][10/49] Loss: 0.6904
[11/300][15/49] Loss: 0.6964
[11/300][20/49] Loss: 0.6928
[11/300][25/49] Loss: 0.6930
[11/300][30/49] Loss: 0.6985
[11/300][35/49] Loss: 0.6924
[11/300][40/49] Loss: 0.7051
[11/300][45/49] Loss: 0.6943
Saving model................
Test set: Average loss: 0.0055, Accuracy: 3115/6230 (50%)
[12/300][0/49] Loss: 0.7031
[12/300][5/49] Loss: 0.6914
[12/300][10/49] Loss: 0.6991
[12/300][15/49] Loss: 0.6917
[12/300][20/49] Loss: 0.6956
[12/300][25/49] Loss: 0.7006
[12/300][30/49] Loss: 0.6932
[12/300][35/49] Loss: 0.6977
[12/300][40/49] Loss: 0.6927
[12/300][45/49] Loss: 0.6961
Saving model................
Test set: Average loss: 0.0055, Accuracy: 3115/6230 (50%)
[13/300][0/49] Loss: 0.6906
[13/300][5/49] Loss: 0.6942
[13/300][10/49] Loss: 0.6956
[13/300][15/49] Loss: 0.6926
[13/300][20/49] Loss: 0.6975
[13/300][25/49] Loss: 0.6927
[13/300][30/49] Loss: 0.6972
[13/300][35/49] Loss: 0.6970
[13/300][40/49] Loss: 0.6915
[13/300][45/49] Loss: 0.6907
Saving model................
Test set: Average loss: 0.0055, Accuracy: 3115/6230 (50%)
[14/300][0/49] Loss: 0.6847
[14/300][5/49] Loss: 0.6974
[14/300][10/49] Loss: 0.7039
[14/300][15/49] Loss: 0.6980
[14/300][20/49] Loss: 0.6959
[14/300][25/49] Loss: 0.6908
[14/300][30/49] Loss: 0.6969
[14/300][35/49] Loss: 0.6893
[14/300][40/49] Loss: 0.6872
[14/300][45/49] Loss: 0.6991
Saving model................
Test set: Average loss: 0.0056, Accuracy: 3115/6230 (50%)
[15/300][0/49] Loss: 0.7241
[15/300][5/49] Loss: 0.6936
[15/300][10/49] Loss: 0.6881
[15/300][15/49] Loss: 0.6831
[15/300][20/49] Loss: 0.7356
[15/300][25/49] Loss: 0.6964
[15/300][30/49] Loss: 0.6936
[15/300][35/49] Loss: 0.6937
[15/300][40/49] Loss: 0.6969
[15/300][45/49] Loss: 0.6952
Saving model................
Test set: Average loss: 0.0055, Accuracy: 3115/6230 (50%)
[16/300][0/49] Loss: 0.6993
[16/300][5/49] Loss: 0.7056
[16/300][10/49] Loss: 0.6927
[16/300][15/49] Loss: 0.6875
[16/300][20/49] Loss: 0.6908
[16/300][25/49] Loss: 0.7159
[16/300][30/49] Loss: 0.6933
[16/300][35/49] Loss: 0.6999
[16/300][40/49] Loss: 0.6961
[16/300][45/49] Loss: 0.6872
Saving model................
Test set: Average loss: 0.0055, Accuracy: 3115/6230 (50%)
[17/300][0/49] Loss: 0.6910
[17/300][5/49] Loss: 0.6956
[17/300][10/49] Loss: 0.6906
[17/300][15/49] Loss: 0.6928
[17/300][20/49] Loss: 0.6924
[17/300][25/49] Loss: 0.6926
[17/300][30/49] Loss: 0.6970
[17/300][35/49] Loss: 0.6934
[17/300][40/49] Loss: 0.6948
[17/300][45/49] Loss: 0.6916
Saving model................
Test set: Average loss: 0.0054, Accuracy: 3239/6230 (51%)
[18/300][0/49] Loss: 0.6932
[18/300][5/49] Loss: 0.6901
[18/300][10/49] Loss: 0.6988
[18/300][15/49] Loss: 0.7008
[18/300][20/49] Loss: 0.6913
[18/300][25/49] Loss: 0.6770
[18/300][30/49] Loss: 0.7015
[18/300][35/49] Loss: 0.6977
[18/300][40/49] Loss: 0.7046
[18/300][45/49] Loss: 0.6947
Saving model................
Test set: Average loss: 0.0054, Accuracy: 3223/6230 (51%)
[19/300][0/49] Loss: 0.6954
[19/300][5/49] Loss: 0.6932
[19/300][10/49] Loss: 0.6924
[19/300][15/49] Loss: 0.6948
[19/300][20/49] Loss: 0.6933
[19/300][25/49] Loss: 0.7002
[19/300][30/49] Loss: 0.7050
[19/300][35/49] Loss: 0.6952
[19/300][40/49] Loss: 0.6954
[19/300][45/49] Loss: 0.6949
Saving model................
Test set: Average loss: 0.0054, Accuracy: 3299/6230 (52%)
[20/300][0/49] Loss: 0.6945
[20/300][5/49] Loss: 0.6987
[20/300][10/49] Loss: 0.6918
[20/300][15/49] Loss: 0.6946
[20/300][20/49] Loss: 0.6890
[20/300][25/49] Loss: 0.6913
[20/300][30/49] Loss: 0.7002
[20/300][35/49] Loss: 0.6970
[20/300][40/49] Loss: 0.6931
[20/300][45/49] Loss: 0.6890
Saving model................
Test set: Average loss: 0.0055, Accuracy: 3120/6230 (50%)
[21/300][0/49] Loss: 0.6902
[21/300][5/49] Loss: 0.6897
[21/300][10/49] Loss: 0.6845
[21/300][15/49] Loss: 0.6928
[21/300][20/49] Loss: 0.6931
[21/300][25/49] Loss: 0.6842
[21/300][30/49] Loss: 0.6979
[21/300][35/49] Loss: 0.6939
[21/300][40/49] Loss: 0.6918
[21/300][45/49] Loss: 0.6928
Saving model................
Test set: Average loss: 0.0054, Accuracy: 3245/6230 (52%)
[22/300][0/49] Loss: 0.6951
[22/300][5/49] Loss: 0.6898
[22/300][10/49] Loss: 0.6931
[22/300][15/49] Loss: 0.6919
[22/300][20/49] Loss: 0.6938
[22/300][25/49] Loss: 0.6931
[22/300][30/49] Loss: 0.6837
[22/300][35/49] Loss: 0.6949
[22/300][40/49] Loss: 0.6904
[22/300][45/49] Loss: 0.6933
Saving model................
Test set: Average loss: 0.0054, Accuracy: 3273/6230 (52%)
[23/300][0/49] Loss: 0.6871
[23/300][5/49] Loss: 0.6928
[23/300][10/49] Loss: 0.6921
[23/300][15/49] Loss: 0.6946
[23/300][20/49] Loss: 0.6935
[23/300][25/49] Loss: 0.6889
[23/300][30/49] Loss: 0.7028
[23/300][35/49] Loss: 0.6941
[23/300][40/49] Loss: 0.6873
[23/300][45/49] Loss: 0.6931
Saving model................
Test set: Average loss: 0.0055, Accuracy: 3128/6230 (50%)
[24/300][0/49] Loss: 0.6968
[24/300][5/49] Loss: 0.6920
[24/300][10/49] Loss: 0.6853
[24/300][15/49] Loss: 0.6949
[24/300][20/49] Loss: 0.6818
[24/300][25/49] Loss: 0.6938
[24/300][30/49] Loss: 0.6916
[24/300][35/49] Loss: 0.6824
[24/300][40/49] Loss: 0.6920
[24/300][45/49] Loss: 0.6985
Saving model................
Test set: Average loss: 0.0054, Accuracy: 3310/6230 (53%)
[25/300][0/49] Loss: 0.6909
[25/300][5/49] Loss: 0.6918
[25/300][10/49] Loss: 0.6870
[25/300][15/49] Loss: 0.6940
[25/300][20/49] Loss: 0.6953
[25/300][25/49] Loss: 0.6909
[25/300][30/49] Loss: 0.6913
[25/300][35/49] Loss: 0.6924
[25/300][40/49] Loss: 0.6978
[25/300][45/49] Loss: 0.6871
Saving model................
Test set: Average loss: 0.0054, Accuracy: 3264/6230 (52%)
[26/300][0/49] Loss: 0.6848
[26/300][5/49] Loss: 0.6905
[26/300][10/49] Loss: 0.7022
[26/300][15/49] Loss: 0.6905
[26/300][20/49] Loss: 0.6981
[26/300][25/49] Loss: 0.6898
[26/300][30/49] Loss: 0.6839
[26/300][35/49] Loss: 0.6912
[26/300][40/49] Loss: 0.6738
[26/300][45/49] Loss: 0.6807
Saving model................
Test set: Average loss: 0.0053, Accuracy: 3610/6230 (57%)
[27/300][0/49] Loss: 0.6792
[27/300][5/49] Loss: 0.6478
[27/300][10/49] Loss: 0.6959
[27/300][15/49] Loss: 0.6736
[27/300][20/49] Loss: 0.6767
[27/300][25/49] Loss: 0.6928
[27/300][30/49] Loss: 0.6626
[27/300][35/49] Loss: 0.6499
[27/300][40/49] Loss: 0.6544
[27/300][45/49] Loss: 0.6577
Saving model................
Test set: Average loss: 0.0053, Accuracy: 3611/6230 (57%)
[28/300][0/49] Loss: 0.6780
[28/300][5/49] Loss: 0.6482
[28/300][10/49] Loss: 0.6583
[28/300][15/49] Loss: 0.6625
[28/300][20/49] Loss: 0.6497
[28/300][25/49] Loss: 0.6330
[28/300][30/49] Loss: 0.6919
[28/300][35/49] Loss: 0.6279
[28/300][40/49] Loss: 0.6690
[28/300][45/49] Loss: 0.6745
Saving model................
Test set: Average loss: 0.0051, Accuracy: 3835/6230 (61%)
[29/300][0/49] Loss: 0.6682
[29/300][5/49] Loss: 0.6653
[29/300][10/49] Loss: 0.6734
[29/300][15/49] Loss: 0.6315
[29/300][20/49] Loss: 0.6411
[29/300][25/49] Loss: 0.6344
[29/300][30/49] Loss: 0.6389
[29/300][35/49] Loss: 0.6495
[29/300][40/49] Loss: 0.6262
[29/300][45/49] Loss: 0.6177
Saving model................
Test set: Average loss: 0.0051, Accuracy: 3820/6230 (61%)
[30/300][0/49] Loss: 0.7134
[30/300][5/49] Loss: 0.6774
[30/300][10/49] Loss: 0.6200
[30/300][15/49] Loss: 0.6307
[30/300][20/49] Loss: 0.6737
[30/300][25/49] Loss: 0.6381
[30/300][30/49] Loss: 0.6422
[30/300][35/49] Loss: 0.6516
[30/300][40/49] Loss: 0.6293
[30/300][45/49] Loss: 0.6473
Saving model................
Test set: Average loss: 0.0051, Accuracy: 3918/6230 (62%)
[31/300][0/49] Loss: 0.6529
[31/300][5/49] Loss: 0.6083
[31/300][10/49] Loss: 0.6619
[31/300][15/49] Loss: 0.6745
[31/300][20/49] Loss: 0.6450
[31/300][25/49] Loss: 0.6268
[31/300][30/49] Loss: 0.6224
[31/300][35/49] Loss: 0.6014
[31/300][40/49] Loss: 0.6927
[31/300][45/49] Loss: 0.6717
Saving model................
Test set: Average loss: 0.0051, Accuracy: 3909/6230 (62%)
[32/300][0/49] Loss: 0.6290
[32/300][5/49] Loss: 0.5930
[32/300][10/49] Loss: 0.5884
[32/300][15/49] Loss: 0.6248
[32/300][20/49] Loss: 0.6152
[32/300][25/49] Loss: 0.6447
[32/300][30/49] Loss: 0.6351
[32/300][35/49] Loss: 0.6355
[32/300][40/49] Loss: 0.6848
[32/300][45/49] Loss: 0.6285
Saving model................
Test set: Average loss: 0.0050, Accuracy: 3978/6230 (63%)
[33/300][0/49] Loss: 0.6603
[33/300][5/49] Loss: 0.6349
[33/300][10/49] Loss: 0.6327
[33/300][15/49] Loss: 0.6974
[33/300][20/49] Loss: 0.6423
[33/300][25/49] Loss: 0.6520
[33/300][30/49] Loss: 0.6578
[33/300][35/49] Loss: 0.6268
[33/300][40/49] Loss: 0.6191
[33/300][45/49] Loss: 0.5913
Saving model................
Test set: Average loss: 0.0049, Accuracy: 4111/6230 (65%)
[34/300][0/49] Loss: 0.6532
[34/300][5/49] Loss: 0.6553
[34/300][10/49] Loss: 0.6165
[34/300][15/49] Loss: 0.6381
[34/300][20/49] Loss: 0.6298
[34/300][25/49] Loss: 0.5986
[34/300][30/49] Loss: 0.6239
[34/300][35/49] Loss: 0.6057
[34/300][40/49] Loss: 0.6267
[34/300][45/49] Loss: 0.6580
Saving model................
Test set: Average loss: 0.0049, Accuracy: 4170/6230 (66%)
[35/300][0/49] Loss: 0.6561
[35/300][5/49] Loss: 0.6308
[35/300][10/49] Loss: 0.6555
[35/300][15/49] Loss: 0.6465
[35/300][20/49] Loss: 0.5369
[35/300][25/49] Loss: 0.6353
[35/300][30/49] Loss: 0.5551
[35/300][35/49] Loss: 0.5846
[35/300][40/49] Loss: 0.6181
[35/300][45/49] Loss: 0.6037
Saving model................
Test set: Average loss: 0.0048, Accuracy: 4195/6230 (67%)
[36/300][0/49] Loss: 0.6830
[36/300][5/49] Loss: 0.6698
[36/300][10/49] Loss: 0.6080
[36/300][15/49] Loss: 0.6258
[36/300][20/49] Loss: 0.6185
[36/300][25/49] Loss: 0.7026
[36/300][30/49] Loss: 0.6339
[36/300][35/49] Loss: 0.5853
[36/300][40/49] Loss: 0.6143
[36/300][45/49] Loss: 0.6029
Saving model................
Test set: Average loss: 0.0048, Accuracy: 4255/6230 (68%)
[37/300][0/49] Loss: 0.6344
[37/300][5/49] Loss: 0.5873
[37/300][10/49] Loss: 0.5758
[37/300][15/49] Loss: 0.5813
[37/300][20/49] Loss: 0.6297
[37/300][25/49] Loss: 0.5962
[37/300][30/49] Loss: 0.6202
[37/300][35/49] Loss: 0.6380
[37/300][40/49] Loss: 0.5842
[37/300][45/49] Loss: 0.6245
Saving model................
Test set: Average loss: 0.0047, Accuracy: 4362/6230 (70%)
[38/300][0/49] Loss: 0.5608
[38/300][5/49] Loss: 0.6445
[38/300][10/49] Loss: 0.5644
[38/300][15/49] Loss: 0.5819
[38/300][20/49] Loss: 0.5868
[38/300][25/49] Loss: 0.6081
[38/300][30/49] Loss: 0.6531
[38/300][35/49] Loss: 0.5831
[38/300][40/49] Loss: 0.6143
[38/300][45/49] Loss: 0.5720
Saving model................
Test set: Average loss: 0.0047, Accuracy: 4329/6230 (69%)
[39/300][0/49] Loss: 0.5920
[39/300][5/49] Loss: 0.6500
[39/300][10/49] Loss: 0.6221
[39/300][15/49] Loss: 0.6729
[39/300][20/49] Loss: 0.5456
[39/300][25/49] Loss: 0.6160
[39/300][30/49] Loss: 0.6138
[39/300][35/49] Loss: 0.5691
[39/300][40/49] Loss: 0.6167
[39/300][45/49] Loss: 0.5863
Saving model................
Test set: Average loss: 0.0047, Accuracy: 4359/6230 (69%)
[40/300][0/49] Loss: 0.6632
[40/300][5/49] Loss: 0.6412
[40/300][10/49] Loss: 0.6545
[40/300][15/49] Loss: 0.5688
[40/300][20/49] Loss: 0.6133
[40/300][25/49] Loss: 0.5861
[40/300][30/49] Loss: 0.6195
[40/300][35/49] Loss: 0.5356
[40/300][40/49] Loss: 0.6331
[40/300][45/49] Loss: 0.5948
Saving model................
Test set: Average loss: 0.0048, Accuracy: 4290/6230 (68%)
[41/300][0/49] Loss: 0.5993
[41/300][5/49] Loss: 0.6282
[41/300][10/49] Loss: 0.5982
[41/300][15/49] Loss: 0.6246
[41/300][20/49] Loss: 0.6065
[41/300][25/49] Loss: 0.6169
[41/300][30/49] Loss: 0.5871
[41/300][35/49] Loss: 0.6087
[41/300][40/49] Loss: 0.5460
[41/300][45/49] Loss: 0.5872
Saving model................
Test set: Average loss: 0.0046, Accuracy: 4449/6230 (71%)
[42/300][0/49] Loss: 0.5885
[42/300][5/49] Loss: 0.5747
[42/300][10/49] Loss: 0.6014
[42/300][15/49] Loss: 0.5539
[42/300][20/49] Loss: 0.6661
[42/300][25/49] Loss: 0.5675
[42/300][30/49] Loss: 0.5954
[42/300][35/49] Loss: 0.5750
[42/300][40/49] Loss: 0.5576
[42/300][45/49] Loss: 0.5889
Saving model................
Test set: Average loss: 0.0046, Accuracy: 4451/6230 (71%)
[43/300][0/49] Loss: 0.5827
[43/300][5/49] Loss: 0.6403
[43/300][10/49] Loss: 0.6224
[43/300][15/49] Loss: 0.5706
[43/300][20/49] Loss: 0.6228
[43/300][25/49] Loss: 0.5905
[43/300][30/49] Loss: 0.5576
[43/300][35/49] Loss: 0.6116
[43/300][40/49] Loss: 0.5631
[43/300][45/49] Loss: 0.6079
Saving model................
Test set: Average loss: 0.0046, Accuracy: 4465/6230 (71%)
[44/300][0/49] Loss: 0.5571
[44/300][5/49] Loss: 0.5887
[44/300][10/49] Loss: 0.5644
[44/300][15/49] Loss: 0.5433
[44/300][20/49] Loss: 0.6502
[44/300][25/49] Loss: 0.5320
[44/300][30/49] Loss: 0.5699
[44/300][35/49] Loss: 0.5435
[44/300][40/49] Loss: 0.5308
[44/300][45/49] Loss: 0.5649
Saving model................
Test set: Average loss: 0.0045, Accuracy: 4538/6230 (72%)
[45/300][0/49] Loss: 0.5714
[45/300][5/49] Loss: 0.5290
[45/300][10/49] Loss: 0.5756
[45/300][15/49] Loss: 0.5741
[45/300][20/49] Loss: 0.5872
[45/300][25/49] Loss: 0.5732
[45/300][30/49] Loss: 0.5952
[45/300][35/49] Loss: 0.5682
[45/300][40/49] Loss: 0.4999
[45/300][45/49] Loss: 0.5624
Saving model................
Test set: Average loss: 0.0045, Accuracy: 4538/6230 (72%)
[46/300][0/49] Loss: 0.6789
[46/300][5/49] Loss: 0.5534
[46/300][10/49] Loss: 0.5479
[46/300][15/49] Loss: 0.5677
[46/300][20/49] Loss: 0.5503
[46/300][25/49] Loss: 0.6209
[46/300][30/49] Loss: 0.6094
[46/300][35/49] Loss: 0.5654
[46/300][40/49] Loss: 0.5611
[46/300][45/49] Loss: 0.5722
Saving model................
Test set: Average loss: 0.0046, Accuracy: 4489/6230 (72%)
[47/300][0/49] Loss: 0.5906
[47/300][5/49] Loss: 0.5636
[47/300][10/49] Loss: 0.5612
[47/300][15/49] Loss: 0.5827
[47/300][20/49] Loss: 0.5561
[47/300][25/49] Loss: 0.5784
[47/300][30/49] Loss: 0.5766
[47/300][35/49] Loss: 0.6036
[47/300][40/49] Loss: 0.5398
[47/300][45/49] Loss: 0.5542
Saving model................
Test set: Average loss: 0.0045, Accuracy: 4577/6230 (73%)
[48/300][0/49] Loss: 0.5818
[48/300][5/49] Loss: 0.6119
[48/300][10/49] Loss: 0.5399
[48/300][15/49] Loss: 0.6235
[48/300][20/49] Loss: 0.5403
[48/300][25/49] Loss: 0.5769
[48/300][30/49] Loss: 0.5767
[48/300][35/49] Loss: 0.5269
[48/300][40/49] Loss: 0.5682
[48/300][45/49] Loss: 0.5939
Saving model................
Test set: Average loss: 0.0045, Accuracy: 4522/6230 (72%)
[49/300][0/49] Loss: 0.5308
[49/300][5/49] Loss: 0.5559
[49/300][10/49] Loss: 0.5303
[49/300][15/49] Loss: 0.5704
[49/300][20/49] Loss: 0.5857
[49/300][25/49] Loss: 0.5936
[49/300][30/49] Loss: 0.5360
[49/300][35/49] Loss: 0.5839
[49/300][40/49] Loss: 0.5613
[49/300][45/49] Loss: 0.5728
Saving model................
Test set: Average loss: 0.0045, Accuracy: 4575/6230 (73%)
[50/300][0/49] Loss: 0.5473
[50/300][5/49] Loss: 0.5017
[50/300][10/49] Loss: 0.5324
[50/300][15/49] Loss: 0.5737
[50/300][20/49] Loss: 0.5983
[50/300][25/49] Loss: 0.5430
[50/300][30/49] Loss: 0.4956
[50/300][35/49] Loss: 0.5840
[50/300][40/49] Loss: 0.5671
[50/300][45/49] Loss: 0.5602
Saving model................
Test set: Average loss: 0.0044, Accuracy: 4678/6230 (75%)
[51/300][0/49] Loss: 0.5124
[51/300][5/49] Loss: 0.5609
[51/300][10/49] Loss: 0.5894
[51/300][15/49] Loss: 0.5608
[51/300][20/49] Loss: 0.5063
[51/300][25/49] Loss: 0.5613
[51/300][30/49] Loss: 0.5748
[51/300][35/49] Loss: 0.5801
[51/300][40/49] Loss: 0.5149
[51/300][45/49] Loss: 0.5273
Saving model................
Test set: Average loss: 0.0044, Accuracy: 4641/6230 (74%)
[52/300][0/49] Loss: 0.5001
[52/300][5/49] Loss: 0.5188
[52/300][10/49] Loss: 0.5535
[52/300][15/49] Loss: 0.5656
[52/300][20/49] Loss: 0.5763
[52/300][25/49] Loss: 0.6427
[52/300][30/49] Loss: 0.5575
[52/300][35/49] Loss: 0.5391
[52/300][40/49] Loss: 0.5598
[52/300][45/49] Loss: 0.5768
Saving model................
Test set: Average loss: 0.0044, Accuracy: 4676/6230 (75%)
[53/300][0/49] Loss: 0.5948
[53/300][5/49] Loss: 0.5640
[53/300][10/49] Loss: 0.5430
[53/300][15/49] Loss: 0.5421
[53/300][20/49] Loss: 0.5131
[53/300][25/49] Loss: 0.5601
[53/300][30/49] Loss: 0.5985
[53/300][35/49] Loss: 0.6109
[53/300][40/49] Loss: 0.5605
[53/300][45/49] Loss: 0.5783
Saving model................
Test set: Average loss: 0.0044, Accuracy: 4646/6230 (74%)
[54/300][0/49] Loss: 0.5449
[54/300][5/49] Loss: 0.5419
[54/300][10/49] Loss: 0.5592
[54/300][15/49] Loss: 0.5525
[54/300][20/49] Loss: 0.5652
[54/300][25/49] Loss: 0.5618
[54/300][30/49] Loss: 0.5567
[54/300][35/49] Loss: 0.6041
[54/300][40/49] Loss: 0.5466
[54/300][45/49] Loss: 0.5616
Saving model................
Test set: Average loss: 0.0043, Accuracy: 4758/6230 (76%)
[55/300][0/49] Loss: 0.5362
[55/300][5/49] Loss: 0.5583
[55/300][10/49] Loss: 0.5090
[55/300][15/49] Loss: 0.6026
[55/300][20/49] Loss: 0.5246
[55/300][25/49] Loss: 0.5614
[55/300][30/49] Loss: 0.5422
[55/300][35/49] Loss: 0.5405
[55/300][40/49] Loss: 0.5496
[55/300][45/49] Loss: 0.6153
Saving model................
Test set: Average loss: 0.0042, Accuracy: 4775/6230 (76%)
[56/300][0/49] Loss: 0.5785
[56/300][5/49] Loss: 0.5471
[56/300][10/49] Loss: 0.5629
[56/300][15/49] Loss: 0.5798
[56/300][20/49] Loss: 0.5491
[56/300][25/49] Loss: 0.5429
[56/300][30/49] Loss: 0.4997
[56/300][35/49] Loss: 0.5601
[56/300][40/49] Loss: 0.5473
[56/300][45/49] Loss: 0.5740
Saving model................
Test set: Average loss: 0.0043, Accuracy: 4772/6230 (76%)
[57/300][0/49] Loss: 0.5961
[57/300][5/49] Loss: 0.6152
[57/300][10/49] Loss: 0.4756
[57/300][15/49] Loss: 0.4920
[57/300][20/49] Loss: 0.5233
[57/300][25/49] Loss: 0.6071
[57/300][30/49] Loss: 0.4739
[57/300][35/49] Loss: 0.5118
[57/300][40/49] Loss: 0.4896
[57/300][45/49] Loss: 0.5756
Saving model................
Test set: Average loss: 0.0042, Accuracy: 4763/6230 (76%)
[58/300][0/49] Loss: 0.5467
[58/300][5/49] Loss: 0.5510
[58/300][10/49] Loss: 0.5080
[58/300][15/49] Loss: 0.6116
[58/300][20/49] Loss: 0.5328
[58/300][25/49] Loss: 0.5602
[58/300][30/49] Loss: 0.5262
[58/300][35/49] Loss: 0.6042
[58/300][40/49] Loss: 0.5296
[58/300][45/49] Loss: 0.5937
Saving model................
Test set: Average loss: 0.0042, Accuracy: 4752/6230 (76%)
[59/300][0/49] Loss: 0.5410
[59/300][5/49] Loss: 0.5260
[59/300][10/49] Loss: 0.4976
[59/300][15/49] Loss: 0.5521
[59/300][20/49] Loss: 0.5766
[59/300][25/49] Loss: 0.4784
[59/300][30/49] Loss: 0.5556
[59/300][35/49] Loss: 0.6090
[59/300][40/49] Loss: 0.5353
[59/300][45/49] Loss: 0.4995
Saving model................
Test set: Average loss: 0.0043, Accuracy: 4701/6230 (75%)
[60/300][0/49] Loss: 0.6058
[60/300][5/49] Loss: 0.5720
[60/300][10/49] Loss: 0.5712
[60/300][15/49] Loss: 0.5444
[60/300][20/49] Loss: 0.5415
[60/300][25/49] Loss: 0.5286
[60/300][30/49] Loss: 0.6026
[60/300][35/49] Loss: 0.5225
[60/300][40/49] Loss: 0.5524
[60/300][45/49] Loss: 0.5070
Saving model................
Test set: Average loss: 0.0043, Accuracy: 4760/6230 (76%)
[61/300][0/49] Loss: 0.5328
[61/300][5/49] Loss: 0.4767
[61/300][10/49] Loss: 0.6245
[61/300][15/49] Loss: 0.4746
[61/300][20/49] Loss: 0.5390
[61/300][25/49] Loss: 0.5544
[61/300][30/49] Loss: 0.5631
[61/300][35/49] Loss: 0.5257
[61/300][40/49] Loss: 0.5683
[61/300][45/49] Loss: 0.5891
Saving model................
Test set: Average loss: 0.0042, Accuracy: 4850/6230 (77%)
[62/300][0/49] Loss: 0.5511
[62/300][5/49] Loss: 0.4717
[62/300][10/49] Loss: 0.4827
[62/300][15/49] Loss: 0.5329
[62/300][20/49] Loss: 0.5652
[62/300][25/49] Loss: 0.5313
[62/300][30/49] Loss: 0.4940
[62/300][35/49] Loss: 0.5897
[62/300][40/49] Loss: 0.5216
[62/300][45/49] Loss: 0.6070
Saving model................
Test set: Average loss: 0.0042, Accuracy: 4787/6230 (76%)
[63/300][0/49] Loss: 0.5809
[63/300][5/49] Loss: 0.4610
[63/300][10/49] Loss: 0.5729
[63/300][15/49] Loss: 0.5614
[63/300][20/49] Loss: 0.5474
[63/300][25/49] Loss: 0.5646
[63/300][30/49] Loss: 0.5564
[63/300][35/49] Loss: 0.4851
[63/300][40/49] Loss: 0.5611
[63/300][45/49] Loss: 0.5217
Saving model................
Test set: Average loss: 0.0043, Accuracy: 4741/6230 (76%)
[64/300][0/49] Loss: 0.5116
[64/300][5/49] Loss: 0.5594
[64/300][10/49] Loss: 0.5385
[64/300][15/49] Loss: 0.5367
[64/300][20/49] Loss: 0.5438
[64/300][25/49] Loss: 0.5646
[64/300][30/49] Loss: 0.4696
[64/300][35/49] Loss: 0.4831
[64/300][40/49] Loss: 0.4797
[64/300][45/49] Loss: 0.4914
Saving model................
Test set: Average loss: 0.0042, Accuracy: 4813/6230 (77%)
[65/300][0/49] Loss: 0.5176
[65/300][5/49] Loss: 0.5146
[65/300][10/49] Loss: 0.6205
[65/300][15/49] Loss: 0.5352
[65/300][20/49] Loss: 0.5096
[65/300][25/49] Loss: 0.5522
[65/300][30/49] Loss: 0.5155
[65/300][35/49] Loss: 0.5527
[65/300][40/49] Loss: 0.5529
[65/300][45/49] Loss: 0.5345
Saving model................
Test set: Average loss: 0.0041, Accuracy: 4919/6230 (78%)
[66/300][0/49] Loss: 0.5032
[66/300][5/49] Loss: 0.5374
[66/300][10/49] Loss: 0.5887
[66/300][15/49] Loss: 0.5582
[66/300][20/49] Loss: 0.5108
[66/300][25/49] Loss: 0.5403
[66/300][30/49] Loss: 0.5488
[66/300][35/49] Loss: 0.4908
[66/300][40/49] Loss: 0.5608
[66/300][45/49] Loss: 0.5488
Saving model................
Test set: Average loss: 0.0041, Accuracy: 4875/6230 (78%)
[67/300][0/49] Loss: 0.5302
[67/300][5/49] Loss: 0.5488
[67/300][10/49] Loss: 0.5635
[67/300][15/49] Loss: 0.6130
[67/300][20/49] Loss: 0.5682
[67/300][25/49] Loss: 0.5688
[67/300][30/49] Loss: 0.4523
[67/300][35/49] Loss: 0.4948
[67/300][40/49] Loss: 0.6124
[67/300][45/49] Loss: 0.5391
Saving model................
Test set: Average loss: 0.0043, Accuracy: 4737/6230 (76%)
[68/300][0/49] Loss: 0.5017
[68/300][5/49] Loss: 0.5343
[68/300][10/49] Loss: 0.5618
[68/300][15/49] Loss: 0.5447
[68/300][20/49] Loss: 0.5616
[68/300][25/49] Loss: 0.5330
[68/300][30/49] Loss: 0.5189
[68/300][35/49] Loss: 0.5070
[68/300][40/49] Loss: 0.5105
[68/300][45/49] Loss: 0.5804
Saving model................
Test set: Average loss: 0.0041, Accuracy: 4904/6230 (78%)
[69/300][0/49] Loss: 0.5158
[69/300][5/49] Loss: 0.4988
[69/300][10/49] Loss: 0.4850
[69/300][15/49] Loss: 0.5430
[69/300][20/49] Loss: 0.5303
[69/300][25/49] Loss: 0.5083
[69/300][30/49] Loss: 0.4734
[69/300][35/49] Loss: 0.4808
[69/300][40/49] Loss: 0.5344
[69/300][45/49] Loss: 0.5555
Saving model................
Test set: Average loss: 0.0040, Accuracy: 4958/6230 (79%)
[70/300][0/49] Loss: 0.5995
[70/300][5/49] Loss: 0.4618
[70/300][10/49] Loss: 0.4810
[70/300][15/49] Loss: 0.5616
[70/300][20/49] Loss: 0.5565
[70/300][25/49] Loss: 0.5374
[70/300][30/49] Loss: 0.5073
[70/300][35/49] Loss: 0.6029
[70/300][40/49] Loss: 0.5247
[70/300][45/49] Loss: 0.5572
Saving model................
Test set: Average loss: 0.0041, Accuracy: 4871/6230 (78%)
[71/300][0/49] Loss: 0.5022
[71/300][5/49] Loss: 0.5406
[71/300][10/49] Loss: 0.4981
[71/300][15/49] Loss: 0.5685
[71/300][20/49] Loss: 0.5048
[71/300][25/49] Loss: 0.4780
[71/300][30/49] Loss: 0.5179
[71/300][35/49] Loss: 0.5833
[71/300][40/49] Loss: 0.5130
[71/300][45/49] Loss: 0.5174
Saving model................
Test set: Average loss: 0.0040, Accuracy: 4959/6230 (79%)
[72/300][0/49] Loss: 0.5183
[72/300][5/49] Loss: 0.5302
[72/300][10/49] Loss: 0.5454
[72/300][15/49] Loss: 0.5774
[72/300][20/49] Loss: 0.5222
[72/300][25/49] Loss: 0.4948
[72/300][30/49] Loss: 0.5356
[72/300][35/49] Loss: 0.5701
[72/300][40/49] Loss: 0.4816
[72/300][45/49] Loss: 0.5507
Saving model................
Test set: Average loss: 0.0040, Accuracy: 4958/6230 (79%)
[73/300][0/49] Loss: 0.4819
[73/300][5/49] Loss: 0.4739
[73/300][10/49] Loss: 0.5726
[73/300][15/49] Loss: 0.5147
[73/300][20/49] Loss: 0.5382
[73/300][25/49] Loss: 0.5744
[73/300][30/49] Loss: 0.5526
[73/300][35/49] Loss: 0.5397
[73/300][40/49] Loss: 0.5277
[73/300][45/49] Loss: 0.4956
Saving model................
Test set: Average loss: 0.0041, Accuracy: 4931/6230 (79%)
[74/300][0/49] Loss: 0.4760
[74/300][5/49] Loss: 0.5368
[74/300][10/49] Loss: 0.5123
[74/300][15/49] Loss: 0.4519
[74/300][20/49] Loss: 0.5059
[74/300][25/49] Loss: 0.5597
[74/300][30/49] Loss: 0.5620
[74/300][35/49] Loss: 0.5309
[74/300][40/49] Loss: 0.5229
[74/300][45/49] Loss: 0.5049
Saving model................
Test set: Average loss: 0.0041, Accuracy: 4946/6230 (79%)
[75/300][0/49] Loss: 0.5311
[75/300][5/49] Loss: 0.5201
[75/300][10/49] Loss: 0.5552
[75/300][15/49] Loss: 0.4826
[75/300][20/49] Loss: 0.5508
[75/300][25/49] Loss: 0.5418
[75/300][30/49] Loss: 0.5545
[75/300][35/49] Loss: 0.4946
[75/300][40/49] Loss: 0.5202
[75/300][45/49] Loss: 0.5047
Saving model................
Test set: Average loss: 0.0041, Accuracy: 4903/6230 (78%)
[76/300][0/49] Loss: 0.5123
[76/300][5/49] Loss: 0.4807
[76/300][10/49] Loss: 0.4677
[76/300][15/49] Loss: 0.5492
[76/300][20/49] Loss: 0.5084
[76/300][25/49] Loss: 0.4882
[76/300][30/49] Loss: 0.5174
[76/300][35/49] Loss: 0.5096
[76/300][40/49] Loss: 0.5372
[76/300][45/49] Loss: 0.5626
Saving model................
Test set: Average loss: 0.0042, Accuracy: 4794/6230 (76%)
[77/300][0/49] Loss: 0.5063
[77/300][5/49] Loss: 0.5348
[77/300][10/49] Loss: 0.5057
[77/300][15/49] Loss: 0.5348
[77/300][20/49] Loss: 0.5015
[77/300][25/49] Loss: 0.5112
[77/300][30/49] Loss: 0.4551
[77/300][35/49] Loss: 0.4870
[77/300][40/49] Loss: 0.5114
[77/300][45/49] Loss: 0.5256
Saving model................
Test set: Average loss: 0.0040, Accuracy: 5013/6230 (80%)
[78/300][0/49] Loss: 0.4822
[78/300][5/49] Loss: 0.5017
[78/300][10/49] Loss: 0.5365
[78/300][15/49] Loss: 0.4906
[78/300][20/49] Loss: 0.4814
[78/300][25/49] Loss: 0.5499
[78/300][30/49] Loss: 0.5609
[78/300][35/49] Loss: 0.5314
[78/300][40/49] Loss: 0.5179
[78/300][45/49] Loss: 0.5379
Saving model................
Test set: Average loss: 0.0040, Accuracy: 5014/6230 (80%)
[79/300][0/49] Loss: 0.5158
[79/300][5/49] Loss: 0.5344
[79/300][10/49] Loss: 0.5573
[79/300][15/49] Loss: 0.5810
[79/300][20/49] Loss: 0.5066
[79/300][25/49] Loss: 0.4835
[79/300][30/49] Loss: 0.4980
[79/300][35/49] Loss: 0.5260
[79/300][40/49] Loss: 0.5154
[79/300][45/49] Loss: 0.5138
Saving model................
Test set: Average loss: 0.0040, Accuracy: 4990/6230 (80%)
[80/300][0/49] Loss: 0.4695
[80/300][5/49] Loss: 0.5259
[80/300][10/49] Loss: 0.5380
[80/300][15/49] Loss: 0.5154
[80/300][20/49] Loss: 0.5409
[80/300][25/49] Loss: 0.4834
[80/300][30/49] Loss: 0.5320
[80/300][35/49] Loss: 0.5508
[80/300][40/49] Loss: 0.5494
[80/300][45/49] Loss: 0.5052
Saving model................
Test set: Average loss: 0.0040, Accuracy: 5029/6230 (80%)
[81/300][0/49] Loss: 0.5030
[81/300][5/49] Loss: 0.4900
[81/300][10/49] Loss: 0.5274
[81/300][15/49] Loss: 0.5318
[81/300][20/49] Loss: 0.5396
[81/300][25/49] Loss: 0.5185
[81/300][30/49] Loss: 0.5599
[81/300][35/49] Loss: 0.4950
[81/300][40/49] Loss: 0.5928
[81/300][45/49] Loss: 0.5056
Saving model................
Test set: Average loss: 0.0040, Accuracy: 4964/6230 (79%)
[82/300][0/49] Loss: 0.4919
[82/300][5/49] Loss: 0.4945
[82/300][10/49] Loss: 0.4807
[82/300][15/49] Loss: 0.5314
[82/300][20/49] Loss: 0.5258
[82/300][25/49] Loss: 0.4883
[82/300][30/49] Loss: 0.5595
[82/300][35/49] Loss: 0.5269
[82/300][40/49] Loss: 0.5402
[82/300][45/49] Loss: 0.5717
Saving model................
Test set: Average loss: 0.0040, Accuracy: 5002/6230 (80%)
[83/300][0/49] Loss: 0.5254
[83/300][5/49] Loss: 0.5226
[83/300][10/49] Loss: 0.4721
[83/300][15/49] Loss: 0.4949
[83/300][20/49] Loss: 0.5569
[83/300][25/49] Loss: 0.5309
[83/300][30/49] Loss: 0.5392
[83/300][35/49] Loss: 0.4900
[83/300][40/49] Loss: 0.5476
[83/300][45/49] Loss: 0.5239
Saving model................
Test set: Average loss: 0.0040, Accuracy: 5035/6230 (80%)
[84/300][0/49] Loss: 0.4531
[84/300][5/49] Loss: 0.5089
[84/300][10/49] Loss: 0.5030
[84/300][15/49] Loss: 0.4672
[84/300][20/49] Loss: 0.5704
[84/300][25/49] Loss: 0.4672
[84/300][30/49] Loss: 0.5061
[84/300][35/49] Loss: 0.4680
[84/300][40/49] Loss: 0.4849
[84/300][45/49] Loss: 0.4814
Saving model................
Test set: Average loss: 0.0040, Accuracy: 5008/6230 (80%)
[85/300][0/49] Loss: 0.5764
[85/300][5/49] Loss: 0.4775
[85/300][10/49] Loss: 0.4742
[85/300][15/49] Loss: 0.5433
[85/300][20/49] Loss: 0.5222
[85/300][25/49] Loss: 0.5625
[85/300][30/49] Loss: 0.5440
[85/300][35/49] Loss: 0.4484
[85/300][40/49] Loss: 0.5186
[85/300][45/49] Loss: 0.5267
Saving model................
Test set: Average loss: 0.0040, Accuracy: 5011/6230 (80%)
[86/300][0/49] Loss: 0.5315
[86/300][5/49] Loss: 0.5512
[86/300][10/49] Loss: 0.4681
[86/300][15/49] Loss: 0.4847
[86/300][20/49] Loss: 0.5024
[86/300][25/49] Loss: 0.5005
[86/300][30/49] Loss: 0.5634
[86/300][35/49] Loss: 0.5128
[86/300][40/49] Loss: 0.4885
[86/300][45/49] Loss: 0.5176
Saving model................
Test set: Average loss: 0.0039, Accuracy: 5047/6230 (81%)
[87/300][0/49] Loss: 0.5173
[87/300][5/49] Loss: 0.5270
[87/300][10/49] Loss: 0.5497
[87/300][15/49] Loss: 0.5437
[87/300][20/49] Loss: 0.5057
[87/300][25/49] Loss: 0.5475
[87/300][30/49] Loss: 0.5449
[87/300][35/49] Loss: 0.4988
[87/300][40/49] Loss: 0.5140
[87/300][45/49] Loss: 0.5003
Saving model................
Test set: Average loss: 0.0041, Accuracy: 4909/6230 (78%)
[88/300][0/49] Loss: 0.5840
[88/300][5/49] Loss: 0.5167
[88/300][10/49] Loss: 0.4535
[88/300][15/49] Loss: 0.5356
[88/300][20/49] Loss: 0.5020
[88/300][25/49] Loss: 0.4940
[88/300][30/49] Loss: 0.4855
[88/300][35/49] Loss: 0.4526
[88/300][40/49] Loss: 0.4763
[88/300][45/49] Loss: 0.4818
Saving model................
Test set: Average loss: 0.0040, Accuracy: 5011/6230 (80%)
[89/300][0/49] Loss: 0.5080
[89/300][5/49] Loss: 0.5246
[89/300][10/49] Loss: 0.4601
[89/300][15/49] Loss: 0.5409
[89/300][20/49] Loss: 0.5709
[89/300][25/49] Loss: 0.5324
[89/300][30/49] Loss: 0.4748
[89/300][35/49] Loss: 0.4916
[89/300][40/49] Loss: 0.5005
[89/300][45/49] Loss: 0.4711
Saving model................
Test set: Average loss: 0.0040, Accuracy: 5008/6230 (80%)
[90/300][0/49] Loss: 0.5283
[90/300][5/49] Loss: 0.5269
[90/300][10/49] Loss: 0.5186
[90/300][15/49] Loss: 0.4915
[90/300][20/49] Loss: 0.5420
[90/300][25/49] Loss: 0.5258
[90/300][30/49] Loss: 0.4377
[90/300][35/49] Loss: 0.4771
[90/300][40/49] Loss: 0.5523
[90/300][45/49] Loss: 0.5474
Saving model................
Test set: Average loss: 0.0041, Accuracy: 4906/6230 (78%)
[91/300][0/49] Loss: 0.5506
[91/300][5/49] Loss: 0.5354
[91/300][10/49] Loss: 0.4802
[91/300][15/49] Loss: 0.5776
[91/300][20/49] Loss: 0.4983
[91/300][25/49] Loss: 0.4795
[91/300][30/49] Loss: 0.4750
[91/300][35/49] Loss: 0.4847
[91/300][40/49] Loss: 0.4880
[91/300][45/49] Loss: 0.4737
Saving model................
Test set: Average loss: 0.0039, Accuracy: 5091/6230 (81%)
[92/300][0/49] Loss: 0.5118
[92/300][5/49] Loss: 0.6159
[92/300][10/49] Loss: 0.4890
[92/300][15/49] Loss: 0.4963
[92/300][20/49] Loss: 0.4866
[92/300][25/49] Loss: 0.5423
[92/300][30/49] Loss: 0.5368
[92/300][35/49] Loss: 0.5014
[92/300][40/49] Loss: 0.4374
[92/300][45/49] Loss: 0.5283
Saving model................
Test set: Average loss: 0.0039, Accuracy: 5060/6230 (81%)
[93/300][0/49] Loss: 0.4713
[93/300][5/49] Loss: 0.4819
[93/300][10/49] Loss: 0.4360
[93/300][15/49] Loss: 0.5184
[93/300][20/49] Loss: 0.4512
[93/300][25/49] Loss: 0.5253
[93/300][30/49] Loss: 0.5329
[93/300][35/49] Loss: 0.4697
[93/300][40/49] Loss: 0.5214
[93/300][45/49] Loss: 0.4678
Saving model................
Test set: Average loss: 0.0039, Accuracy: 5096/6230 (81%)
[94/300][0/49] Loss: 0.4574
[94/300][5/49] Loss: 0.4944
[94/300][10/49] Loss: 0.5006
[94/300][15/49] Loss: 0.5543
[94/300][20/49] Loss: 0.4866
[94/300][25/49] Loss: 0.4512
[94/300][30/49] Loss: 0.4776
[94/300][35/49] Loss: 0.5147
[94/300][40/49] Loss: 0.5466
[94/300][45/49] Loss: 0.4985
Saving model................
Test set: Average loss: 0.0040, Accuracy: 5016/6230 (80%)
[95/300][0/49] Loss: 0.5514
[95/300][5/49] Loss: 0.4444
[95/300][10/49] Loss: 0.5247
[95/300][15/49] Loss: 0.5111
[95/300][20/49] Loss: 0.5373
[95/300][25/49] Loss: 0.5124
[95/300][30/49] Loss: 0.6025
[95/300][35/49] Loss: 0.5003
[95/300][40/49] Loss: 0.4801
[95/300][45/49] Loss: 0.5173
Saving model................
Test set: Average loss: 0.0039, Accuracy: 5039/6230 (80%)
[96/300][0/49] Loss: 0.5197
[96/300][5/49] Loss: 0.5345
[96/300][10/49] Loss: 0.4732
[96/300][15/49] Loss: 0.4730
[96/300][20/49] Loss: 0.5170
[96/300][25/49] Loss: 0.5046
[96/300][30/49] Loss: 0.5203
[96/300][35/49] Loss: 0.4827
[96/300][40/49] Loss: 0.4708
[96/300][45/49] Loss: 0.4423
Saving model................
Test set: Average loss: 0.0039, Accuracy: 5094/6230 (81%)
[97/300][0/49] Loss: 0.4582
[97/300][5/49] Loss: 0.4588
[97/300][10/49] Loss: 0.5036
[97/300][15/49] Loss: 0.5023
[97/300][20/49] Loss: 0.4580
[97/300][25/49] Loss: 0.5047
[97/300][30/49] Loss: 0.4685
[97/300][35/49] Loss: 0.5058
[97/300][40/49] Loss: 0.5338
[97/300][45/49] Loss: 0.5116
Saving model................
Test set: Average loss: 0.0038, Accuracy: 5114/6230 (82%)
[98/300][0/49] Loss: 0.5060
[98/300][5/49] Loss: 0.4989
[98/300][10/49] Loss: 0.5240
[98/300][15/49] Loss: 0.5058
[98/300][20/49] Loss: 0.5151
[98/300][25/49] Loss: 0.4377
[98/300][30/49] Loss: 0.5459
[98/300][35/49] Loss: 0.4868
[98/300][40/49] Loss: 0.4812
[98/300][45/49] Loss: 0.4658
Saving model................
Test set: Average loss: 0.0039, Accuracy: 5096/6230 (81%)
[99/300][0/49] Loss: 0.4664
[99/300][5/49] Loss: 0.5148
[99/300][10/49] Loss: 0.4897
[99/300][15/49] Loss: 0.4713
[99/300][20/49] Loss: 0.4827
[99/300][25/49] Loss: 0.5143
[99/300][30/49] Loss: 0.5383
[99/300][35/49] Loss: 0.4859
[99/300][40/49] Loss: 0.4875
[99/300][45/49] Loss: 0.5441
Saving model................
Test set: Average loss: 0.0039, Accuracy: 5044/6230 (80%)
[100/300][0/49] Loss: 0.5363
[100/300][5/49] Loss: 0.4750
[100/300][10/49] Loss: 0.4732
[100/300][15/49] Loss: 0.5612
[100/300][20/49] Loss: 0.5130
[100/300][25/49] Loss: 0.4871
[100/300][30/49] Loss: 0.5550
[100/300][35/49] Loss: 0.5129
[100/300][40/49] Loss: 0.5409
[100/300][45/49] Loss: 0.5121
Saving model................
Test set: Average loss: 0.0039, Accuracy: 5028/6230 (80%)
[101/300][0/49] Loss: 0.4898
[101/300][5/49] Loss: 0.4957
[101/300][10/49] Loss: 0.5292
[101/300][15/49] Loss: 0.5741
[101/300][20/49] Loss: 0.5403
[101/300][25/49] Loss: 0.5290
[101/300][30/49] Loss: 0.5251
[101/300][35/49] Loss: 0.5096
[101/300][40/49] Loss: 0.5350
[101/300][45/49] Loss: 0.5559
Saving model................
Test set: Average loss: 0.0041, Accuracy: 4944/6230 (79%)
[102/300][0/49] Loss: 0.5383
[102/300][5/49] Loss: 0.5126
[102/300][10/49] Loss: 0.4639
[102/300][15/49] Loss: 0.5374
[102/300][20/49] Loss: 0.4871
[102/300][25/49] Loss: 0.5421
[102/300][30/49] Loss: 0.4198
[102/300][35/49] Loss: 0.4905
[102/300][40/49] Loss: 0.4914
[102/300][45/49] Loss: 0.5278
Saving model................
Test set: Average loss: 0.0041, Accuracy: 4897/6230 (78%)
[103/300][0/49] Loss: 0.5858
[103/300][5/49] Loss: 0.4891
[103/300][10/49] Loss: 0.5416
[103/300][15/49] Loss: 0.5131
[103/300][20/49] Loss: 0.5074
[103/300][25/49] Loss: 0.4651
[103/300][30/49] Loss: 0.4551
[103/300][35/49] Loss: 0.5319
[103/300][40/49] Loss: 0.5034
[103/300][45/49] Loss: 0.5347
Saving model................
Test set: Average loss: 0.0039, Accuracy: 5054/6230 (81%)
[104/300][0/49] Loss: 0.4634
[104/300][5/49] Loss: 0.4826
[104/300][10/49] Loss: 0.5063
[104/300][15/49] Loss: 0.5463
[104/300][20/49] Loss: 0.4655
[104/300][25/49] Loss: 0.4834
[104/300][30/49] Loss: 0.4612
[104/300][35/49] Loss: 0.5070
[104/300][40/49] Loss: 0.4931
[104/300][45/49] Loss: 0.4725
Saving model................
Test set: Average loss: 0.0038, Accuracy: 5110/6230 (82%)
[105/300][0/49] Loss: 0.4537
[105/300][5/49] Loss: 0.5303
[105/300][10/49] Loss: 0.5538
[105/300][15/49] Loss: 0.4874
[105/300][20/49] Loss: 0.5422
[105/300][25/49] Loss: 0.4793
[105/300][30/49] Loss: 0.5590
[105/300][35/49] Loss: 0.4976
[105/300][40/49] Loss: 0.5116
[105/300][45/49] Loss: 0.5368
Saving model................
Test set: Average loss: 0.0041, Accuracy: 4897/6230 (78%)
[106/300][0/49] Loss: 0.5773
[106/300][5/49] Loss: 0.4752
[106/300][10/49] Loss: 0.5359
[106/300][15/49] Loss: 0.4475
[106/300][20/49] Loss: 0.4965
[106/300][25/49] Loss: 0.5298
[106/300][30/49] Loss: 0.5137
[106/300][35/49] Loss: 0.5070
[106/300][40/49] Loss: 0.5247
[106/300][45/49] Loss: 0.5267
Saving model................
Test set: Average loss: 0.0039, Accuracy: 5057/6230 (81%)
[107/300][0/49] Loss: 0.5168
[107/300][5/49] Loss: 0.5420
[107/300][10/49] Loss: 0.5115
[107/300][15/49] Loss: 0.5093
[107/300][20/49] Loss: 0.4794
[107/300][25/49] Loss: 0.4424
[107/300][30/49] Loss: 0.4819
[107/300][35/49] Loss: 0.4922
[107/300][40/49] Loss: 0.5389
[107/300][45/49] Loss: 0.5021
Saving model................
Test set: Average loss: 0.0039, Accuracy: 5075/6230 (81%)
[108/300][0/49] Loss: 0.4933
[108/300][5/49] Loss: 0.5196
[108/300][10/49] Loss: 0.5121
[108/300][15/49] Loss: 0.5176
[108/300][20/49] Loss: 0.5073
[108/300][25/49] Loss: 0.5172
[108/300][30/49] Loss: 0.4968
[108/300][35/49] Loss: 0.4771
[108/300][40/49] Loss: 0.4704
[108/300][45/49] Loss: 0.5190
Saving model................
Test set: Average loss: 0.0040, Accuracy: 5000/6230 (80%)
[109/300][0/49] Loss: 0.5596
[109/300][5/49] Loss: 0.5358
[109/300][10/49] Loss: 0.5094
[109/300][15/49] Loss: 0.5295
[109/300][20/49] Loss: 0.4924
[109/300][25/49] Loss: 0.4866
[109/300][30/49] Loss: 0.5015
[109/300][35/49] Loss: 0.5182
[109/300][40/49] Loss: 0.5641
[109/300][45/49] Loss: 0.4953
Saving model................
Test set: Average loss: 0.0041, Accuracy: 4877/6230 (78%)
[110/300][0/49] Loss: 0.5411
[110/300][5/49] Loss: 0.4755
[110/300][10/49] Loss: 0.4772
[110/300][15/49] Loss: 0.4843
[110/300][20/49] Loss: 0.4923
[110/300][25/49] Loss: 0.5257
[110/300][30/49] Loss: 0.5016
[110/300][35/49] Loss: 0.5180
[110/300][40/49] Loss: 0.4485
[110/300][45/49] Loss: 0.5011
Saving model................
Test set: Average loss: 0.0039, Accuracy: 5057/6230 (81%)
[111/300][0/49] Loss: 0.5191
[111/300][5/49] Loss: 0.4672
[111/300][10/49] Loss: 0.5002
[111/300][15/49] Loss: 0.5710
[111/300][20/49] Loss: 0.5286
[111/300][25/49] Loss: 0.5090
[111/300][30/49] Loss: 0.5381
[111/300][35/49] Loss: 0.4871
[111/300][40/49] Loss: 0.4814
[111/300][45/49] Loss: 0.5081
Saving model................
Test set: Average loss: 0.0039, Accuracy: 5035/6230 (80%)
[112/300][0/49] Loss: 0.4825
[112/300][5/49] Loss: 0.5252
[112/300][10/49] Loss: 0.5051
[112/300][15/49] Loss: 0.5046
[112/300][20/49] Loss: 0.4840
[112/300][25/49] Loss: 0.4867
[112/300][30/49] Loss: 0.4713
[112/300][35/49] Loss: 0.5637
[112/300][40/49] Loss: 0.4909
[112/300][45/49] Loss: 0.4960
Saving model................
Test set: Average loss: 0.0039, Accuracy: 5049/6230 (81%)
[113/300][0/49] Loss: 0.5355
[113/300][5/49] Loss: 0.4626
[113/300][10/49] Loss: 0.5004
[113/300][15/49] Loss: 0.4962
[113/300][20/49] Loss: 0.4864
[113/300][25/49] Loss: 0.5009
[113/300][30/49] Loss: 0.5054
[113/300][35/49] Loss: 0.4798
[113/300][40/49] Loss: 0.4951
[113/300][45/49] Loss: 0.5353
Saving model................
Test set: Average loss: 0.0038, Accuracy: 5125/6230 (82%)
[114/300][0/49] Loss: 0.4454
[114/300][5/49] Loss: 0.4597
[114/300][10/49] Loss: 0.5167
[114/300][15/49] Loss: 0.5283
[114/300][20/49] Loss: 0.4995
[114/300][25/49] Loss: 0.4933
[114/300][30/49] Loss: 0.4879
[114/300][35/49] Loss: 0.4937
[114/300][40/49] Loss: 0.4357
[114/300][45/49] Loss: 0.4917
Saving model................
Test set: Average loss: 0.0038, Accuracy: 5117/6230 (82%)
[115/300][0/49] Loss: 0.4746
[115/300][5/49] Loss: 0.5230
[115/300][10/49] Loss: 0.4575
[115/300][15/49] Loss: 0.4866
[115/300][20/49] Loss: 0.4677
[115/300][25/49] Loss: 0.4419
[115/300][30/49] Loss: 0.4880
[115/300][35/49] Loss: 0.5028
[115/300][40/49] Loss: 0.5236
[115/300][45/49] Loss: 0.4847
Saving model................
Test set: Average loss: 0.0039, Accuracy: 5085/6230 (81%)
[116/300][0/49] Loss: 0.4799
[116/300][5/49] Loss: 0.5118
[116/300][10/49] Loss: 0.5443
[116/300][15/49] Loss: 0.4613
[116/300][20/49] Loss: 0.4954
[116/300][25/49] Loss: 0.4500
[116/300][30/49] Loss: 0.4774
[116/300][35/49] Loss: 0.5229
[116/300][40/49] Loss: 0.5133
[116/300][45/49] Loss: 0.5351
Saving model................
Test set: Average loss: 0.0039, Accuracy: 5098/6230 (81%)
[117/300][0/49] Loss: 0.4676
[117/300][5/49] Loss: 0.5012
[117/300][10/49] Loss: 0.4962
[117/300][15/49] Loss: 0.5435
[117/300][20/49] Loss: 0.4585
[117/300][25/49] Loss: 0.5581
[117/300][30/49] Loss: 0.5230
[117/300][35/49] Loss: 0.5003
[117/300][40/49] Loss: 0.4405
[117/300][45/49] Loss: 0.5114
Saving model................
Test set: Average loss: 0.0038, Accuracy: 5115/6230 (82%)
[118/300][0/49] Loss: 0.5051
[118/300][5/49] Loss: 0.4852
[118/300][10/49] Loss: 0.4851
[118/300][15/49] Loss: 0.4869
[118/300][20/49] Loss: 0.5353
[118/300][25/49] Loss: 0.5466
[118/300][30/49] Loss: 0.4756
[118/300][35/49] Loss: 0.4775
[118/300][40/49] Loss: 0.4747
[118/300][45/49] Loss: 0.5194
Saving model................
Test set: Average loss: 0.0039, Accuracy: 5100/6230 (81%)
[119/300][0/49] Loss: 0.4873
[119/300][5/49] Loss: 0.5501
[119/300][10/49] Loss: 0.5807
[119/300][15/49] Loss: 0.4915
[119/300][20/49] Loss: 0.4932
[119/300][25/49] Loss: 0.5166
[119/300][30/49] Loss: 0.4727
[119/300][35/49] Loss: 0.4639
[119/300][40/49] Loss: 0.4437
[119/300][45/49] Loss: 0.5212
Saving model................
Test set: Average loss: 0.0039, Accuracy: 5085/6230 (81%)
[120/300][0/49] Loss: 0.4671
[120/300][5/49] Loss: 0.4872
[120/300][10/49] Loss: 0.4895
[120/300][15/49] Loss: 0.5028
[120/300][20/49] Loss: 0.4500
[120/300][25/49] Loss: 0.4514
[120/300][30/49] Loss: 0.4859
[120/300][35/49] Loss: 0.4626
[120/300][40/49] Loss: 0.5016
[120/300][45/49] Loss: 0.4955
Saving model................
Test set: Average loss: 0.0038, Accuracy: 5149/6230 (82%)
[121/300][0/49] Loss: 0.5375
[121/300][5/49] Loss: 0.4320
[121/300][10/49] Loss: 0.4854
[121/300][15/49] Loss: 0.5076
[121/300][20/49] Loss: 0.4940
[121/300][25/49] Loss: 0.4876
[121/300][30/49] Loss: 0.5666
[121/300][35/49] Loss: 0.4803
[121/300][40/49] Loss: 0.4839
[121/300][45/49] Loss: 0.4609
Saving model................
Test set: Average loss: 0.0039, Accuracy: 5032/6230 (80%)
[122/300][0/49] Loss: 0.4890
[122/300][5/49] Loss: 0.5717
[122/300][10/49] Loss: 0.6029
[122/300][15/49] Loss: 0.5185
[122/300][20/49] Loss: 0.4785
[122/300][25/49] Loss: 0.4674
[122/300][30/49] Loss: 0.4641
[122/300][35/49] Loss: 0.4586
[122/300][40/49] Loss: 0.4668
[122/300][45/49] Loss: 0.5348
Saving model................
Test set: Average loss: 0.0039, Accuracy: 5092/6230 (81%)
[123/300][0/49] Loss: 0.4836
[123/300][5/49] Loss: 0.5083
[123/300][10/49] Loss: 0.5059
[123/300][15/49] Loss: 0.5069
[123/300][20/49] Loss: 0.5090
[123/300][25/49] Loss: 0.4786
[123/300][30/49] Loss: 0.4960
[123/300][35/49] Loss: 0.5021
[123/300][40/49] Loss: 0.4778
[123/300][45/49] Loss: 0.5116
Saving model................
Test set: Average loss: 0.0039, Accuracy: 5089/6230 (81%)
[124/300][0/49] Loss: 0.5493
[124/300][5/49] Loss: 0.5477
[124/300][10/49] Loss: 0.5201
[124/300][15/49] Loss: 0.5566
[124/300][20/49] Loss: 0.5308
[124/300][25/49] Loss: 0.5145
[124/300][30/49] Loss: 0.5086
[124/300][35/49] Loss: 0.4722
[124/300][40/49] Loss: 0.4356
[124/300][45/49] Loss: 0.5198
Saving model................
Test set: Average loss: 0.0038, Accuracy: 5127/6230 (82%)
[125/300][0/49] Loss: 0.4995
[125/300][5/49] Loss: 0.4657
[125/300][10/49] Loss: 0.5193
[125/300][15/49] Loss: 0.4771
[125/300][20/49] Loss: 0.4651
[125/300][25/49] Loss: 0.4980
[125/300][30/49] Loss: 0.5459
[125/300][35/49] Loss: 0.5309
[125/300][40/49] Loss: 0.4916
[125/300][45/49] Loss: 0.4748
Saving model................
Test set: Average loss: 0.0038, Accuracy: 5182/6230 (83%)
[126/300][0/49] Loss: 0.5011
[126/300][5/49] Loss: 0.4550
[126/300][10/49] Loss: 0.4826
[126/300][15/49] Loss: 0.5259
[126/300][20/49] Loss: 0.4972
[126/300][25/49] Loss: 0.5361
[126/300][30/49] Loss: 0.4517
[126/300][35/49] Loss: 0.4677
[126/300][40/49] Loss: 0.4811
[126/300][45/49] Loss: 0.5061
Saving model................
Test set: Average loss: 0.0038, Accuracy: 5127/6230 (82%)
[127/300][0/49] Loss: 0.4914
[127/300][5/49] Loss: 0.4659
[127/300][10/49] Loss: 0.5219
[127/300][15/49] Loss: 0.4054
[127/300][20/49] Loss: 0.5040
[127/300][25/49] Loss: 0.4497
[127/300][30/49] Loss: 0.5070
[127/300][35/49] Loss: 0.4884
[127/300][40/49] Loss: 0.4333
[127/300][45/49] Loss: 0.5481
Saving model................
Test set: Average loss: 0.0039, Accuracy: 5125/6230 (82%)
[128/300][0/49] Loss: 0.5340
[128/300][5/49] Loss: 0.4698
[128/300][10/49] Loss: 0.5290
[128/300][15/49] Loss: 0.4444
[128/300][20/49] Loss: 0.4983
[128/300][25/49] Loss: 0.5116
[128/300][30/49] Loss: 0.5271
[128/300][35/49] Loss: 0.4819
[128/300][40/49] Loss: 0.5305
[128/300][45/49] Loss: 0.5040
Saving model................
Test set: Average loss: 0.0038, Accuracy: 5128/6230 (82%)
[129/300][0/49] Loss: 0.4821
[129/300][5/49] Loss: 0.4943
[129/300][10/49] Loss: 0.4993
[129/300][15/49] Loss: 0.5467
[129/300][20/49] Loss: 0.4495
[129/300][25/49] Loss: 0.4281
[129/300][30/49] Loss: 0.4474
[129/300][35/49] Loss: 0.5742
[129/300][40/49] Loss: 0.4681
[129/300][45/49] Loss: 0.5540
Saving model................
Test set: Average loss: 0.0040, Accuracy: 4976/6230 (79%)
[130/300][0/49] Loss: 0.4848
[130/300][5/49] Loss: 0.5075
[130/300][10/49] Loss: 0.4813
[130/300][15/49] Loss: 0.4620
[130/300][20/49] Loss: 0.4827
[130/300][25/49] Loss: 0.4602
[130/300][30/49] Loss: 0.4981
[130/300][35/49] Loss: 0.5005
[130/300][40/49] Loss: 0.5157
[130/300][45/49] Loss: 0.5295
Saving model................
Test set: Average loss: 0.0038, Accuracy: 5162/6230 (82%)
[131/300][0/49] Loss: 0.5018
[131/300][5/49] Loss: 0.5053
[131/300][10/49] Loss: 0.5115
[131/300][15/49] Loss: 0.5554
[131/300][20/49] Loss: 0.5080
[131/300][25/49] Loss: 0.4507
[131/300][30/49] Loss: 0.5062
[131/300][35/49] Loss: 0.4964
[131/300][40/49] Loss: 0.4411
[131/300][45/49] Loss: 0.4526
Saving model................
Test set: Average loss: 0.0038, Accuracy: 5157/6230 (82%)
[132/300][0/49] Loss: 0.4949
[132/300][5/49] Loss: 0.4703
[132/300][10/49] Loss: 0.4439
[132/300][15/49] Loss: 0.4953
[132/300][20/49] Loss: 0.4442
[132/300][25/49] Loss: 0.4910
[132/300][30/49] Loss: 0.4817
[132/300][35/49] Loss: 0.5128
[132/300][40/49] Loss: 0.5664
[132/300][45/49] Loss: 0.5481
Saving model................
Test set: Average loss: 0.0039, Accuracy: 5066/6230 (81%)
[133/300][0/49] Loss: 0.4690
[133/300][5/49] Loss: 0.5133
[133/300][10/49] Loss: 0.5142
[133/300][15/49] Loss: 0.5116
[133/300][20/49] Loss: 0.4956
[133/300][25/49] Loss: 0.4648
[133/300][30/49] Loss: 0.5827
[133/300][35/49] Loss: 0.5302
[133/300][40/49] Loss: 0.5632
[133/300][45/49] Loss: 0.5015
Saving model................
Test set: Average loss: 0.0040, Accuracy: 5008/6230 (80%)
[134/300][0/49] Loss: 0.5917
[134/300][5/49] Loss: 0.5300
[134/300][10/49] Loss: 0.4920
[134/300][15/49] Loss: 0.4790
[134/300][20/49] Loss: 0.4556
[134/300][25/49] Loss: 0.4745
[134/300][30/49] Loss: 0.4952
[134/300][35/49] Loss: 0.4929
[134/300][40/49] Loss: 0.4294
[134/300][45/49] Loss: 0.5136
Saving model................
Test set: Average loss: 0.0039, Accuracy: 5049/6230 (81%)
[135/300][0/49] Loss: 0.5189
[135/300][5/49] Loss: 0.5582
[135/300][10/49] Loss: 0.5022
[135/300][15/49] Loss: 0.5245
[135/300][20/49] Loss: 0.4982
[135/300][25/49] Loss: 0.4996
[135/300][30/49] Loss: 0.4907
[135/300][35/49] Loss: 0.4870
[135/300][40/49] Loss: 0.4514
[135/300][45/49] Loss: 0.4662
Saving model................
Test set: Average loss: 0.0039, Accuracy: 5074/6230 (81%)
[136/300][0/49] Loss: 0.4701
[136/300][5/49] Loss: 0.5143
[136/300][10/49] Loss: 0.4460
[136/300][15/49] Loss: 0.5162
[136/300][20/49] Loss: 0.5420
[136/300][25/49] Loss: 0.4949
[136/300][30/49] Loss: 0.5163
[136/300][35/49] Loss: 0.5219
[136/300][40/49] Loss: 0.5025
[136/300][45/49] Loss: 0.5659
Saving model................
Test set: Average loss: 0.0038, Accuracy: 5140/6230 (82%)
[137/300][0/49] Loss: 0.5345
[137/300][5/49] Loss: 0.4722
[137/300][10/49] Loss: 0.5062
[137/300][15/49] Loss: 0.4602
[137/300][20/49] Loss: 0.5054
[137/300][25/49] Loss: 0.4758
[137/300][30/49] Loss: 0.4713
[137/300][35/49] Loss: 0.4725
[137/300][40/49] Loss: 0.5393
[137/300][45/49] Loss: 0.5206
Saving model................
Test set: Average loss: 0.0038, Accuracy: 5167/6230 (82%)
[138/300][0/49] Loss: 0.4732
[138/300][5/49] Loss: 0.5275
[138/300][10/49] Loss: 0.4772
[138/300][15/49] Loss: 0.4869
[138/300][20/49] Loss: 0.4726
[138/300][25/49] Loss: 0.4996
[138/300][30/49] Loss: 0.4856
[138/300][35/49] Loss: 0.4633
[138/300][40/49] Loss: 0.5171
[138/300][45/49] Loss: 0.5241
Saving model................
Test set: Average loss: 0.0038, Accuracy: 5195/6230 (83%)
[139/300][0/49] Loss: 0.5031
[139/300][5/49] Loss: 0.4953
[139/300][10/49] Loss: 0.4972
[139/300][15/49] Loss: 0.4608
[139/300][20/49] Loss: 0.4734
[139/300][25/49] Loss: 0.5036
[139/300][30/49] Loss: 0.5016
[139/300][35/49] Loss: 0.4571
[139/300][40/49] Loss: 0.5134
[139/300][45/49] Loss: 0.4878
Saving model................
Test set: Average loss: 0.0038, Accuracy: 5158/6230 (82%)
[140/300][0/49] Loss: 0.5006
[140/300][5/49] Loss: 0.4838
[140/300][10/49] Loss: 0.4630
[140/300][15/49] Loss: 0.4717
[140/300][20/49] Loss: 0.4672
[140/300][25/49] Loss: 0.4086
[140/300][30/49] Loss: 0.4683
[140/300][35/49] Loss: 0.4835
[140/300][40/49] Loss: 0.5551
[140/300][45/49] Loss: 0.5235
Saving model................
Test set: Average loss: 0.0039, Accuracy: 5089/6230 (81%)
[141/300][0/49] Loss: 0.4954
[141/300][5/49] Loss: 0.4541
[141/300][10/49] Loss: 0.4781
[141/300][15/49] Loss: 0.5137
[141/300][20/49] Loss: 0.5245
[141/300][25/49] Loss: 0.5069
[141/300][30/49] Loss: 0.4849
[141/300][35/49] Loss: 0.5153
[141/300][40/49] Loss: 0.4677
[141/300][45/49] Loss: 0.5018
Saving model................
Test set: Average loss: 0.0039, Accuracy: 5110/6230 (82%)
[142/300][0/49] Loss: 0.4756
[142/300][5/49] Loss: 0.5195
[142/300][10/49] Loss: 0.4743
[142/300][15/49] Loss: 0.4681
[142/300][20/49] Loss: 0.4877
[142/300][25/49] Loss: 0.4641
[142/300][30/49] Loss: 0.4859
[142/300][35/49] Loss: 0.4513
[142/300][40/49] Loss: 0.4737
[142/300][45/49] Loss: 0.5322
Saving model................
Test set: Average loss: 0.0038, Accuracy: 5188/6230 (83%)
[143/300][0/49] Loss: 0.4821
[143/300][5/49] Loss: 0.4665
[143/300][10/49] Loss: 0.5420
[143/300][15/49] Loss: 0.4967
[143/300][20/49] Loss: 0.4651
[143/300][25/49] Loss: 0.4653
[143/300][30/49] Loss: 0.5119
[143/300][35/49] Loss: 0.4666
[143/300][40/49] Loss: 0.4214
[143/300][45/49] Loss: 0.4768
Saving model................
Test set: Average loss: 0.0040, Accuracy: 4987/6230 (80%)
[144/300][0/49] Loss: 0.4866
[144/300][5/49] Loss: 0.5065
[144/300][10/49] Loss: 0.4856
[144/300][15/49] Loss: 0.5095
[144/300][20/49] Loss: 0.4385
[144/300][25/49] Loss: 0.5379
[144/300][30/49] Loss: 0.4859
[144/300][35/49] Loss: 0.4420
[144/300][40/49] Loss: 0.5028
[144/300][45/49] Loss: 0.4927
Saving model................
Test set: Average loss: 0.0038, Accuracy: 5134/6230 (82%)
[145/300][0/49] Loss: 0.5203
[145/300][5/49] Loss: 0.4922
[145/300][10/49] Loss: 0.5487
[145/300][15/49] Loss: 0.5597
[145/300][20/49] Loss: 0.4933
[145/300][25/49] Loss: 0.4803
[145/300][30/49] Loss: 0.5554
[145/300][35/49] Loss: 0.4785
[145/300][40/49] Loss: 0.4154
[145/300][45/49] Loss: 0.4808
Saving model................
Test set: Average loss: 0.0039, Accuracy: 5089/6230 (81%)
[146/300][0/49] Loss: 0.4867
[146/300][5/49] Loss: 0.4545
[146/300][10/49] Loss: 0.4861
[146/300][15/49] Loss: 0.5574
[146/300][20/49] Loss: 0.4357
[146/300][25/49] Loss: 0.4968
[146/300][30/49] Loss: 0.4382
[146/300][35/49] Loss: 0.4477
[146/300][40/49] Loss: 0.5023
[146/300][45/49] Loss: 0.5256
Saving model................
Test set: Average loss: 0.0039, Accuracy: 5087/6230 (81%)
[147/300][0/49] Loss: 0.4815
[147/300][5/49] Loss: 0.4486
[147/300][10/49] Loss: 0.5473
[147/300][15/49] Loss: 0.5086
[147/300][20/49] Loss: 0.5075
[147/300][25/49] Loss: 0.5600
[147/300][30/49] Loss: 0.4540
[147/300][35/49] Loss: 0.4874
[147/300][40/49] Loss: 0.4335
[147/300][45/49] Loss: 0.4918
Saving model................
Test set: Average loss: 0.0038, Accuracy: 5176/6230 (83%)
[148/300][0/49] Loss: 0.4813
[148/300][5/49] Loss: 0.4940
[148/300][10/49] Loss: 0.4908
[148/300][15/49] Loss: 0.4385
[148/300][20/49] Loss: 0.5020
[148/300][25/49] Loss: 0.5015
[148/300][30/49] Loss: 0.4310
[148/300][35/49] Loss: 0.4843
[148/300][40/49] Loss: 0.4852
[148/300][45/49] Loss: 0.5213
Saving model................
Test set: Average loss: 0.0038, Accuracy: 5139/6230 (82%)
[149/300][0/49] Loss: 0.4751
[149/300][5/49] Loss: 0.4888
[149/300][10/49] Loss: 0.4702
[149/300][15/49] Loss: 0.4874
[149/300][20/49] Loss: 0.4884
[149/300][25/49] Loss: 0.5036
[149/300][30/49] Loss: 0.4611
[149/300][35/49] Loss: 0.4860
[149/300][40/49] Loss: 0.4420
[149/300][45/49] Loss: 0.5328
Saving model................
Test set: Average loss: 0.0039, Accuracy: 5092/6230 (81%)
[150/300][0/49] Loss: 0.4406
[150/300][5/49] Loss: 0.4732
[150/300][10/49] Loss: 0.4784
[150/300][15/49] Loss: 0.4426
[150/300][20/49] Loss: 0.4890
[150/300][25/49] Loss: 0.4958
[150/300][30/49] Loss: 0.4500
[150/300][35/49] Loss: 0.5553
[150/300][40/49] Loss: 0.5034
[150/300][45/49] Loss: 0.4843
Saving model................
Test set: Average loss: 0.0038, Accuracy: 5126/6230 (82%)
[151/300][0/49] Loss: 0.4619
[151/300][5/49] Loss: 0.5313
[151/300][10/49] Loss: 0.5222
[151/300][15/49] Loss: 0.4934
[151/300][20/49] Loss: 0.4302
[151/300][25/49] Loss: 0.5731
[151/300][30/49] Loss: 0.4992
[151/300][35/49] Loss: 0.5151
[151/300][40/49] Loss: 0.4796
[151/300][45/49] Loss: 0.5698
Saving model................
Test set: Average loss: 0.0040, Accuracy: 4982/6230 (79%)
[152/300][0/49] Loss: 0.5400
[152/300][5/49] Loss: 0.5711
[152/300][10/49] Loss: 0.4883
[152/300][15/49] Loss: 0.5024
[152/300][20/49] Loss: 0.4799
[152/300][25/49] Loss: 0.4703
[152/300][30/49] Loss: 0.4965
[152/300][35/49] Loss: 0.4496
[152/300][40/49] Loss: 0.5145
[152/300][45/49] Loss: 0.4699
Saving model................
Test set: Average loss: 0.0041, Accuracy: 4928/6230 (79%)
[153/300][0/49] Loss: 0.4600
[153/300][5/49] Loss: 0.5039
[153/300][10/49] Loss: 0.5190
[153/300][15/49] Loss: 0.4888
[153/300][20/49] Loss: 0.5213
[153/300][25/49] Loss: 0.5017
[153/300][30/49] Loss: 0.4669
[153/300][35/49] Loss: 0.5072
[153/300][40/49] Loss: 0.4476
[153/300][45/49] Loss: 0.4862
Saving model................
Test set: Average loss: 0.0038, Accuracy: 5147/6230 (82%)
[154/300][0/49] Loss: 0.4684
[154/300][5/49] Loss: 0.5018
[154/300][10/49] Loss: 0.5054
[154/300][15/49] Loss: 0.5380
[154/300][20/49] Loss: 0.4902
[154/300][25/49] Loss: 0.5170
[154/300][30/49] Loss: 0.4996
[154/300][35/49] Loss: 0.4876
[154/300][40/49] Loss: 0.4973
[154/300][45/49] Loss: 0.4549
Saving model................
Test set: Average loss: 0.0038, Accuracy: 5150/6230 (82%)
[155/300][0/49] Loss: 0.5083
[155/300][5/49] Loss: 0.5067
[155/300][10/49] Loss: 0.4602
[155/300][15/49] Loss: 0.4967
[155/300][20/49] Loss: 0.4300
[155/300][25/49] Loss: 0.5076
[155/300][30/49] Loss: 0.5429
[155/300][35/49] Loss: 0.4936
[155/300][40/49] Loss: 0.4707
[155/300][45/49] Loss: 0.4673
Saving model................
Test set: Average loss: 0.0039, Accuracy: 5107/6230 (81%)
[156/300][0/49] Loss: 0.5086
[156/300][5/49] Loss: 0.4562
[156/300][10/49] Loss: 0.5423
[156/300][15/49] Loss: 0.4565
[156/300][20/49] Loss: 0.5178
[156/300][25/49] Loss: 0.4966
[156/300][30/49] Loss: 0.4814
[156/300][35/49] Loss: 0.4557
[156/300][40/49] Loss: 0.5008
[156/300][45/49] Loss: 0.5167
Saving model................
Test set: Average loss: 0.0038, Accuracy: 5127/6230 (82%)
[157/300][0/49] Loss: 0.4803
[157/300][5/49] Loss: 0.5009
[157/300][10/49] Loss: 0.4887
[157/300][15/49] Loss: 0.4751
[157/300][20/49] Loss: 0.4576
[157/300][25/49] Loss: 0.4215
[157/300][30/49] Loss: 0.5282
[157/300][35/49] Loss: 0.5229
[157/300][40/49] Loss: 0.4349
[157/300][45/49] Loss: 0.5375
Saving model................
Test set: Average loss: 0.0038, Accuracy: 5196/6230 (83%)
[158/300][0/49] Loss: 0.4412
[158/300][5/49] Loss: 0.4679
[158/300][10/49] Loss: 0.4563
[158/300][15/49] Loss: 0.4934
[158/300][20/49] Loss: 0.4888
[158/300][25/49] Loss: 0.4639
[158/300][30/49] Loss: 0.5490
[158/300][35/49] Loss: 0.5127
[158/300][40/49] Loss: 0.5047
[158/300][45/49] Loss: 0.4858
Saving model................
Test set: Average loss: 0.0038, Accuracy: 5196/6230 (83%)
[159/300][0/49] Loss: 0.5707
[159/300][5/49] Loss: 0.4459
[159/300][10/49] Loss: 0.4696
[159/300][15/49] Loss: 0.5123
[159/300][20/49] Loss: 0.4607
[159/300][25/49] Loss: 0.5084
[159/300][30/49] Loss: 0.4508
[159/300][35/49] Loss: 0.5132
[159/300][40/49] Loss: 0.4941
[159/300][45/49] Loss: 0.4847
Saving model................
Test set: Average loss: 0.0038, Accuracy: 5143/6230 (82%)
[160/300][0/49] Loss: 0.5085
[160/300][5/49] Loss: 0.5138
[160/300][10/49] Loss: 0.4550
[160/300][15/49] Loss: 0.5755
[160/300][20/49] Loss: 0.5318
[160/300][25/49] Loss: 0.4599
[160/300][30/49] Loss: 0.5222
[160/300][35/49] Loss: 0.4404
[160/300][40/49] Loss: 0.5229
[160/300][45/49] Loss: 0.4525
Saving model................
Test set: Average loss: 0.0039, Accuracy: 5087/6230 (81%)
[161/300][0/49] Loss: 0.5053
[161/300][5/49] Loss: 0.5154
[161/300][10/49] Loss: 0.4579
[161/300][15/49] Loss: 0.5755
[161/300][20/49] Loss: 0.5155
[161/300][25/49] Loss: 0.4844
[161/300][30/49] Loss: 0.4436
[161/300][35/49] Loss: 0.5096
[161/300][40/49] Loss: 0.4350
[161/300][45/49] Loss: 0.4733
Saving model................
Test set: Average loss: 0.0038, Accuracy: 5164/6230 (82%)
[162/300][0/49] Loss: 0.4970
[162/300][5/49] Loss: 0.4632
[162/300][10/49] Loss: 0.5093
[162/300][15/49] Loss: 0.4886
[162/300][20/49] Loss: 0.4891
[162/300][25/49] Loss: 0.5063
[162/300][30/49] Loss: 0.4583
[162/300][35/49] Loss: 0.4934
[162/300][40/49] Loss: 0.4781
[162/300][45/49] Loss: 0.5033
Saving model................
Test set: Average loss: 0.0038, Accuracy: 5190/6230 (83%)
[163/300][0/49] Loss: 0.4267
[163/300][5/49] Loss: 0.4459
[163/300][10/49] Loss: 0.5259
[163/300][15/49] Loss: 0.4593
[163/300][20/49] Loss: 0.5351
[163/300][25/49] Loss: 0.4733
[163/300][30/49] Loss: 0.5256
[163/300][35/49] Loss: 0.5226
[163/300][40/49] Loss: 0.5830
[163/300][45/49] Loss: 0.4830
Saving model................
Test set: Average loss: 0.0038, Accuracy: 5151/6230 (82%)
[164/300][0/49] Loss: 0.4399
[164/300][5/49] Loss: 0.4957
[164/300][10/49] Loss: 0.5341
[164/300][15/49] Loss: 0.5322
[164/300][20/49] Loss: 0.6008
[164/300][25/49] Loss: 0.5281
[164/300][30/49] Loss: 0.4949
[164/300][35/49] Loss: 0.4800
[164/300][40/49] Loss: 0.5084
[164/300][45/49] Loss: 0.5020
Saving model................
Test set: Average loss: 0.0038, Accuracy: 5134/6230 (82%)
[165/300][0/49] Loss: 0.4513
[165/300][5/49] Loss: 0.4637
[165/300][10/49] Loss: 0.4582
[165/300][15/49] Loss: 0.4660
[165/300][20/49] Loss: 0.4588
[165/300][25/49] Loss: 0.5098
[165/300][30/49] Loss: 0.5215
[165/300][35/49] Loss: 0.4856
[165/300][40/49] Loss: 0.5350
[165/300][45/49] Loss: 0.5419
Saving model................
Test set: Average loss: 0.0038, Accuracy: 5166/6230 (82%)
[166/300][0/49] Loss: 0.4446
[166/300][5/49] Loss: 0.4875
[166/300][10/49] Loss: 0.4852
[166/300][15/49] Loss: 0.5006
[166/300][20/49] Loss: 0.4829
[166/300][25/49] Loss: 0.4869
[166/300][30/49] Loss: 0.5244
[166/300][35/49] Loss: 0.4834
[166/300][40/49] Loss: 0.4974
[166/300][45/49] Loss: 0.4690
Saving model................
Test set: Average loss: 0.0038, Accuracy: 5163/6230 (82%)
[167/300][0/49] Loss: 0.4804
[167/300][5/49] Loss: 0.4763
[167/300][10/49] Loss: 0.4421
[167/300][15/49] Loss: 0.5588
[167/300][20/49] Loss: 0.5425
[167/300][25/49] Loss: 0.5501
[167/300][30/49] Loss: 0.4693
[167/300][35/49] Loss: 0.4829
[167/300][40/49] Loss: 0.5376
[167/300][45/49] Loss: 0.5100
Saving model................
Test set: Average loss: 0.0039, Accuracy: 5111/6230 (82%)
[168/300][0/49] Loss: 0.4850
[168/300][5/49] Loss: 0.4716
[168/300][10/49] Loss: 0.4501
[168/300][15/49] Loss: 0.4908
[168/300][20/49] Loss: 0.5126
[168/300][25/49] Loss: 0.5149
[168/300][30/49] Loss: 0.4636
[168/300][35/49] Loss: 0.4932
[168/300][40/49] Loss: 0.4522
[168/300][45/49] Loss: 0.5210
Saving model................
Test set: Average loss: 0.0037, Accuracy: 5210/6230 (83%)
[169/300][0/49] Loss: 0.4218
[169/300][5/49] Loss: 0.4628
[169/300][10/49] Loss: 0.4794
[169/300][15/49] Loss: 0.4467
[169/300][20/49] Loss: 0.4689
[169/300][25/49] Loss: 0.4503
[169/300][30/49] Loss: 0.4917
[169/300][35/49] Loss: 0.4699
[169/300][40/49] Loss: 0.5231
[169/300][45/49] Loss: 0.4409
Saving model................
Test set: Average loss: 0.0037, Accuracy: 5243/6230 (84%)
[170/300][0/49] Loss: 0.4363
[170/300][5/49] Loss: 0.5299
[170/300][10/49] Loss: 0.5183
[170/300][15/49] Loss: 0.4935
[170/300][20/49] Loss: 0.4536
[170/300][25/49] Loss: 0.4762
[170/300][30/49] Loss: 0.4804
[170/300][35/49] Loss: 0.4569
[170/300][40/49] Loss: 0.5242
[170/300][45/49] Loss: 0.5480
Saving model................
Test set: Average loss: 0.0038, Accuracy: 5112/6230 (82%)
[171/300][0/49] Loss: 0.4652
[171/300][5/49] Loss: 0.4934
[171/300][10/49] Loss: 0.4698
[171/300][15/49] Loss: 0.5545
[171/300][20/49] Loss: 0.5275
[171/300][25/49] Loss: 0.4505
[171/300][30/49] Loss: 0.5346
[171/300][35/49] Loss: 0.5098
[171/300][40/49] Loss: 0.4875
[171/300][45/49] Loss: 0.4958
Saving model................
Test set: Average loss: 0.0039, Accuracy: 5078/6230 (81%)
[172/300][0/49] Loss: 0.4433
[172/300][5/49] Loss: 0.5333
[172/300][10/49] Loss: 0.5239
[172/300][15/49] Loss: 0.5354
[172/300][20/49] Loss: 0.4677
[172/300][25/49] Loss: 0.5079
[172/300][30/49] Loss: 0.4868
[172/300][35/49] Loss: 0.5063
[172/300][40/49] Loss: 0.4664
[172/300][45/49] Loss: 0.4510
Saving model................
Test set: Average loss: 0.0039, Accuracy: 5049/6230 (81%)
[173/300][0/49] Loss: 0.4429
[173/300][5/49] Loss: 0.5461
[173/300][10/49] Loss: 0.5044
[173/300][15/49] Loss: 0.4673
[173/300][20/49] Loss: 0.4867
[173/300][25/49] Loss: 0.5217
[173/300][30/49] Loss: 0.5085
[173/300][35/49] Loss: 0.4611
[173/300][40/49] Loss: 0.4656
[173/300][45/49] Loss: 0.4894
Saving model................
Test set: Average loss: 0.0038, Accuracy: 5134/6230 (82%)
[174/300][0/49] Loss: 0.4890
[174/300][5/49] Loss: 0.5057
[174/300][10/49] Loss: 0.4675
[174/300][15/49] Loss: 0.5548
[174/300][20/49] Loss: 0.4582
[174/300][25/49] Loss: 0.5023
[174/300][30/49] Loss: 0.4935
[174/300][35/49] Loss: 0.4472
[174/300][40/49] Loss: 0.5294
[174/300][45/49] Loss: 0.4513
Saving model................
Test set: Average loss: 0.0040, Accuracy: 5029/6230 (80%)
[175/300][0/49] Loss: 0.5210
[175/300][5/49] Loss: 0.5330
[175/300][10/49] Loss: 0.4909
[175/300][15/49] Loss: 0.5079
[175/300][20/49] Loss: 0.4503
[175/300][25/49] Loss: 0.4667
[175/300][30/49] Loss: 0.5082
[175/300][35/49] Loss: 0.5530
[175/300][40/49] Loss: 0.4353
[175/300][45/49] Loss: 0.4903
Saving model................
Test set: Average loss: 0.0039, Accuracy: 5059/6230 (81%)
[176/300][0/49] Loss: 0.5025
[176/300][5/49] Loss: 0.5362
[176/300][10/49] Loss: 0.4533
[176/300][15/49] Loss: 0.4649
[176/300][20/49] Loss: 0.4952
[176/300][25/49] Loss: 0.5339
[176/300][30/49] Loss: 0.5291
[176/300][35/49] Loss: 0.5279
[176/300][40/49] Loss: 0.4230
[176/300][45/49] Loss: 0.4737
Saving model................
Test set: Average loss: 0.0038, Accuracy: 5173/6230 (83%)
[177/300][0/49] Loss: 0.5061
[177/300][5/49] Loss: 0.5028
[177/300][10/49] Loss: 0.4926
[177/300][15/49] Loss: 0.5248
[177/300][20/49] Loss: 0.4737
[177/300][25/49] Loss: 0.4839
[177/300][30/49] Loss: 0.5335
[177/300][35/49] Loss: 0.4812
[177/300][40/49] Loss: 0.4335
[177/300][45/49] Loss: 0.4194
Saving model................
Test set: Average loss: 0.0038, Accuracy: 5178/6230 (83%)
[178/300][0/49] Loss: 0.5161
[178/300][5/49] Loss: 0.5226
[178/300][10/49] Loss: 0.5004
[178/300][15/49] Loss: 0.4321
[178/300][20/49] Loss: 0.5133
[178/300][25/49] Loss: 0.5836
[178/300][30/49] Loss: 0.5732
[178/300][35/49] Loss: 0.4470
[178/300][40/49] Loss: 0.4655
[178/300][45/49] Loss: 0.4381
Saving model................
Test set: Average loss: 0.0039, Accuracy: 5049/6230 (81%)
[179/300][0/49] Loss: 0.5431
[179/300][5/49] Loss: 0.4901
[179/300][10/49] Loss: 0.5061
[179/300][15/49] Loss: 0.5126
[179/300][20/49] Loss: 0.5102
[179/300][25/49] Loss: 0.4794
[179/300][30/49] Loss: 0.5264
[179/300][35/49] Loss: 0.4981
[179/300][40/49] Loss: 0.4948
[179/300][45/49] Loss: 0.4248
Saving model................
Test set: Average loss: 0.0038, Accuracy: 5197/6230 (83%)
[180/300][0/49] Loss: 0.4654
[180/300][5/49] Loss: 0.4384
[180/300][10/49] Loss: 0.4643
[180/300][15/49] Loss: 0.4740
[180/300][20/49] Loss: 0.5097
[180/300][25/49] Loss: 0.5250
[180/300][30/49] Loss: 0.5499
[180/300][35/49] Loss: 0.3973
[180/300][40/49] Loss: 0.5421
[180/300][45/49] Loss: 0.5061
Saving model................
Test set: Average loss: 0.0038, Accuracy: 5168/6230 (82%)
[181/300][0/49] Loss: 0.5403
[181/300][5/49] Loss: 0.4869
[181/300][10/49] Loss: 0.4746
[181/300][15/49] Loss: 0.4718
[181/300][20/49] Loss: 0.5053
[181/300][25/49] Loss: 0.4547
[181/300][30/49] Loss: 0.4991
[181/300][35/49] Loss: 0.4801
[181/300][40/49] Loss: 0.5264
[181/300][45/49] Loss: 0.4835
Saving model................
Test set: Average loss: 0.0037, Accuracy: 5214/6230 (83%)
[182/300][0/49] Loss: 0.4771
[182/300][5/49] Loss: 0.4679
[182/300][10/49] Loss: 0.5203
[182/300][15/49] Loss: 0.5262
[182/300][20/49] Loss: 0.4160
[182/300][25/49] Loss: 0.5371
[182/300][30/49] Loss: 0.5271
[182/300][35/49] Loss: 0.4559
[182/300][40/49] Loss: 0.4079
[182/300][45/49] Loss: 0.5384
Saving model................
Test set: Average loss: 0.0040, Accuracy: 4966/6230 (79%)
[183/300][0/49] Loss: 0.5337
[183/300][5/49] Loss: 0.4958
[183/300][10/49] Loss: 0.5205
[183/300][15/49] Loss: 0.4800
[183/300][20/49] Loss: 0.5043
[183/300][25/49] Loss: 0.5408
[183/300][30/49] Loss: 0.4721
[183/300][35/49] Loss: 0.4902
[183/300][40/49] Loss: 0.5060
[183/300][45/49] Loss: 0.4437
Saving model................
Test set: Average loss: 0.0039, Accuracy: 5086/6230 (81%)
[184/300][0/49] Loss: 0.5246
[184/300][5/49] Loss: 0.4846
[184/300][10/49] Loss: 0.4836
[184/300][15/49] Loss: 0.4824
[184/300][20/49] Loss: 0.4737
[184/300][25/49] Loss: 0.4632
[184/300][30/49] Loss: 0.5585
[184/300][35/49] Loss: 0.4942
[184/300][40/49] Loss: 0.4816
[184/300][45/49] Loss: 0.5452
Saving model................
Test set: Average loss: 0.0038, Accuracy: 5114/6230 (82%)
[185/300][0/49] Loss: 0.4723
[185/300][5/49] Loss: 0.4547
[185/300][10/49] Loss: 0.5013
[185/300][15/49] Loss: 0.4899
[185/300][20/49] Loss: 0.4607
[185/300][25/49] Loss: 0.5673
[185/300][30/49] Loss: 0.4419
[185/300][35/49] Loss: 0.5257
[185/300][40/49] Loss: 0.4851
[185/300][45/49] Loss: 0.4798
Saving model................
Test set: Average loss: 0.0038, Accuracy: 5149/6230 (82%)
[186/300][0/49] Loss: 0.4648
[186/300][5/49] Loss: 0.4669
[186/300][10/49] Loss: 0.4693
[186/300][15/49] Loss: 0.5229
[186/300][20/49] Loss: 0.4390
[186/300][25/49] Loss: 0.4748
[186/300][30/49] Loss: 0.4775
[186/300][35/49] Loss: 0.5215
[186/300][40/49] Loss: 0.4988
[186/300][45/49] Loss: 0.5136
Saving model................
Test set: Average loss: 0.0038, Accuracy: 5147/6230 (82%)
[187/300][0/49] Loss: 0.6060
[187/300][5/49] Loss: 0.4934
[187/300][10/49] Loss: 0.5295
[187/300][15/49] Loss: 0.4884
[187/300][20/49] Loss: 0.4717
[187/300][25/49] Loss: 0.5230
[187/300][30/49] Loss: 0.4911
[187/300][35/49] Loss: 0.5235
[187/300][40/49] Loss: 0.5239
[187/300][45/49] Loss: 0.4855
Saving model................
Test set: Average loss: 0.0038, Accuracy: 5143/6230 (82%)
[188/300][0/49] Loss: 0.4509
[188/300][5/49] Loss: 0.4995
[188/300][10/49] Loss: 0.5145
[188/300][15/49] Loss: 0.4495
[188/300][20/49] Loss: 0.4685
[188/300][25/49] Loss: 0.4445
[188/300][30/49] Loss: 0.5052
[188/300][35/49] Loss: 0.5061
[188/300][40/49] Loss: 0.4769
[188/300][45/49] Loss: 0.4643
Saving model................
Test set: Average loss: 0.0038, Accuracy: 5153/6230 (82%)
[189/300][0/49] Loss: 0.5136
[189/300][5/49] Loss: 0.4460
[189/300][10/49] Loss: 0.5375
[189/300][15/49] Loss: 0.5191
[189/300][20/49] Loss: 0.4962
[189/300][25/49] Loss: 0.4694
[189/300][30/49] Loss: 0.4851
[189/300][35/49] Loss: 0.5307
[189/300][40/49] Loss: 0.5272
[189/300][45/49] Loss: 0.5269
Saving model................
Test set: Average loss: 0.0040, Accuracy: 5001/6230 (80%)
[190/300][0/49] Loss: 0.4603
[190/300][5/49] Loss: 0.4861
[190/300][10/49] Loss: 0.4964
[190/300][15/49] Loss: 0.4597
[190/300][20/49] Loss: 0.5548
[190/300][25/49] Loss: 0.5507
[190/300][30/49] Loss: 0.5389
[190/300][35/49] Loss: 0.5179
[190/300][40/49] Loss: 0.5052
[190/300][45/49] Loss: 0.4930
Saving model................
Test set: Average loss: 0.0039, Accuracy: 5111/6230 (82%)
[191/300][0/49] Loss: 0.4355
[191/300][5/49] Loss: 0.4779
[191/300][10/49] Loss: 0.4671
[191/300][15/49] Loss: 0.4668
[191/300][20/49] Loss: 0.5090
[191/300][25/49] Loss: 0.5121
[191/300][30/49] Loss: 0.5086
[191/300][35/49] Loss: 0.4711
[191/300][40/49] Loss: 0.4607
[191/300][45/49] Loss: 0.5122
Saving model................
Test set: Average loss: 0.0038, Accuracy: 5152/6230 (82%)
[192/300][0/49] Loss: 0.5423
[192/300][5/49] Loss: 0.4946
[192/300][10/49] Loss: 0.4983
[192/300][15/49] Loss: 0.4692
[192/300][20/49] Loss: 0.5162
[192/300][25/49] Loss: 0.5305
[192/300][30/49] Loss: 0.4648
[192/300][35/49] Loss: 0.4799
[192/300][40/49] Loss: 0.5346
[192/300][45/49] Loss: 0.4887
Saving model................
Test set: Average loss: 0.0039, Accuracy: 5079/6230 (81%)
[193/300][0/49] Loss: 0.5068
[193/300][5/49] Loss: 0.5770
[193/300][10/49] Loss: 0.4687
[193/300][15/49] Loss: 0.4904
[193/300][20/49] Loss: 0.4777
[193/300][25/49] Loss: 0.5185
[193/300][30/49] Loss: 0.5570
[193/300][35/49] Loss: 0.5291
[193/300][40/49] Loss: 0.4813
[193/300][45/49] Loss: 0.4759
Saving model................
Test set: Average loss: 0.0041, Accuracy: 4933/6230 (79%)
[194/300][0/49] Loss: 0.6080
[194/300][5/49] Loss: 0.5133
[194/300][10/49] Loss: 0.5192
[194/300][15/49] Loss: 0.5126
[194/300][20/49] Loss: 0.5028
[194/300][25/49] Loss: 0.4656
[194/300][30/49] Loss: 0.4919
[194/300][35/49] Loss: 0.5161
[194/300][40/49] Loss: 0.5525
[194/300][45/49] Loss: 0.5701
Saving model................
Test set: Average loss: 0.0042, Accuracy: 4842/6230 (77%)
[195/300][0/49] Loss: 0.4943
[195/300][5/49] Loss: 0.5176
[195/300][10/49] Loss: 0.5056
[195/300][15/49] Loss: 0.4833
[195/300][20/49] Loss: 0.5134
[195/300][25/49] Loss: 0.5157
[195/300][30/49] Loss: 0.5659
[195/300][35/49] Loss: 0.4566
[195/300][40/49] Loss: 0.4930
[195/300][45/49] Loss: 0.4715
Saving model................
Test set: Average loss: 0.0038, Accuracy: 5132/6230 (82%)
[196/300][0/49] Loss: 0.5234
[196/300][5/49] Loss: 0.5106
[196/300][10/49] Loss: 0.4774
[196/300][15/49] Loss: 0.4484
[196/300][20/49] Loss: 0.5110
[196/300][25/49] Loss: 0.5957
[196/300][30/49] Loss: 0.5251
[196/300][35/49] Loss: 0.4716
[196/300][40/49] Loss: 0.4834
[196/300][45/49] Loss: 0.5214
Saving model................
Test set: Average loss: 0.0040, Accuracy: 4982/6230 (79%)
[197/300][0/49] Loss: 0.4885
[197/300][5/49] Loss: 0.4749
[197/300][10/49] Loss: 0.4666
[197/300][15/49] Loss: 0.4673
[197/300][20/49] Loss: 0.5323
[197/300][25/49] Loss: 0.4426
[197/300][30/49] Loss: 0.4666
[197/300][35/49] Loss: 0.4542
[197/300][40/49] Loss: 0.5462
[197/300][45/49] Loss: 0.5501
Saving model................
Test set: Average loss: 0.0039, Accuracy: 5058/6230 (81%)
[198/300][0/49] Loss: 0.5126
[198/300][5/49] Loss: 0.4714
[198/300][10/49] Loss: 0.4928
[198/300][15/49] Loss: 0.4325
[198/300][20/49] Loss: 0.4502
[198/300][25/49] Loss: 0.5122
[198/300][30/49] Loss: 0.5076
[198/300][35/49] Loss: 0.4669
[198/300][40/49] Loss: 0.4851
[198/300][45/49] Loss: 0.4796
Saving model................
Test set: Average loss: 0.0039, Accuracy: 5115/6230 (82%)
[199/300][0/49] Loss: 0.5258
[199/300][5/49] Loss: 0.5190
[199/300][10/49] Loss: 0.4806
[199/300][15/49] Loss: 0.4693
[199/300][20/49] Loss: 0.5125
[199/300][25/49] Loss: 0.5165
[199/300][30/49] Loss: 0.5143
[199/300][35/49] Loss: 0.5003
[199/300][40/49] Loss: 0.5559
[199/300][45/49] Loss: 0.5113
Saving model................
Test set: Average loss: 0.0038, Accuracy: 5136/6230 (82%)
[200/300][0/49] Loss: 0.4119
[200/300][5/49] Loss: 0.5351
[200/300][10/49] Loss: 0.5546
[200/300][15/49] Loss: 0.5087
[200/300][20/49] Loss: 0.5083
[200/300][25/49] Loss: 0.5123
[200/300][30/49] Loss: 0.4487
[200/300][35/49] Loss: 0.4880
[200/300][40/49] Loss: 0.4709
[200/300][45/49] Loss: 0.4794
Saving model................
Test set: Average loss: 0.0038, Accuracy: 5142/6230 (82%)
[201/300][0/49] Loss: 0.4341
[201/300][5/49] Loss: 0.4953
[201/300][10/49] Loss: 0.5038
[201/300][15/49] Loss: 0.4674
[201/300][20/49] Loss: 0.4478
[201/300][25/49] Loss: 0.5123
[201/300][30/49] Loss: 0.5079
[201/300][35/49] Loss: 0.4795
[201/300][40/49] Loss: 0.5009
[201/300][45/49] Loss: 0.4944
Saving model................
Test set: Average loss: 0.0039, Accuracy: 5091/6230 (81%)
[202/300][0/49] Loss: 0.4596
[202/300][5/49] Loss: 0.5063
[202/300][10/49] Loss: 0.4948
[202/300][15/49] Loss: 0.5354
[202/300][20/49] Loss: 0.4441
[202/300][25/49] Loss: 0.5376
[202/300][30/49] Loss: 0.4889
[202/300][35/49] Loss: 0.4709
[202/300][40/49] Loss: 0.4691
[202/300][45/49] Loss: 0.5016
Saving model................
Test set: Average loss: 0.0038, Accuracy: 5178/6230 (83%)
[203/300][0/49] Loss: 0.4800
[203/300][5/49] Loss: 0.4494
[203/300][10/49] Loss: 0.4086
[203/300][15/49] Loss: 0.4465
[203/300][20/49] Loss: 0.4959
[203/300][25/49] Loss: 0.4862
[203/300][30/49] Loss: 0.5374
[203/300][35/49] Loss: 0.4492
[203/300][40/49] Loss: 0.4791
[203/300][45/49] Loss: 0.5393
Saving model................
Test set: Average loss: 0.0039, Accuracy: 5064/6230 (81%)
[204/300][0/49] Loss: 0.5111
[204/300][5/49] Loss: 0.4685
[204/300][10/49] Loss: 0.4854
[204/300][15/49] Loss: 0.5304
[204/300][20/49] Loss: 0.4782
[204/300][25/49] Loss: 0.4632
[204/300][30/49] Loss: 0.5122
[204/300][35/49] Loss: 0.5026
[204/300][40/49] Loss: 0.5295
[204/300][45/49] Loss: 0.5143
Saving model................
Test set: Average loss: 0.0041, Accuracy: 4922/6230 (79%)
[205/300][0/49] Loss: 0.5245
[205/300][5/49] Loss: 0.4396
[205/300][10/49] Loss: 0.4558
[205/300][15/49] Loss: 0.4675
[205/300][20/49] Loss: 0.5108
[205/300][25/49] Loss: 0.4260
[205/300][30/49] Loss: 0.5484
[205/300][35/49] Loss: 0.5135
[205/300][40/49] Loss: 0.5601
[205/300][45/49] Loss: 0.5126
Saving model................
Test set: Average loss: 0.0038, Accuracy: 5128/6230 (82%)
[206/300][0/49] Loss: 0.4832
[206/300][5/49] Loss: 0.5848
[206/300][10/49] Loss: 0.4984
[206/300][15/49] Loss: 0.5563
[206/300][20/49] Loss: 0.4536
[206/300][25/49] Loss: 0.5309
[206/300][30/49] Loss: 0.5334
[206/300][35/49] Loss: 0.5250
[206/300][40/49] Loss: 0.5365
[206/300][45/49] Loss: 0.6327
Saving model................
Test set: Average loss: 0.0041, Accuracy: 4940/6230 (79%)
[207/300][0/49] Loss: 0.4811
[207/300][5/49] Loss: 0.4922
[207/300][10/49] Loss: 0.5132
[207/300][15/49] Loss: 0.4567
[207/300][20/49] Loss: 0.4310
[207/300][25/49] Loss: 0.5504
[207/300][30/49] Loss: 0.5200
[207/300][35/49] Loss: 0.5331
[207/300][40/49] Loss: 0.4950
[207/300][45/49] Loss: 0.5702
Saving model................
Test set: Average loss: 0.0039, Accuracy: 5052/6230 (81%)
[208/300][0/49] Loss: 0.4957
[208/300][5/49] Loss: 0.5454
[208/300][10/49] Loss: 0.4784
[208/300][15/49] Loss: 0.4783
[208/300][20/49] Loss: 0.5507
[208/300][25/49] Loss: 0.4735
[208/300][30/49] Loss: 0.4995
[208/300][35/49] Loss: 0.4920
[208/300][40/49] Loss: 0.4934
[208/300][45/49] Loss: 0.4473
Saving model................
Test set: Average loss: 0.0040, Accuracy: 5002/6230 (80%)
[209/300][0/49] Loss: 0.5445
[209/300][5/49] Loss: 0.5036
[209/300][10/49] Loss: 0.5001
[209/300][15/49] Loss: 0.4681
[209/300][20/49] Loss: 0.4808
[209/300][25/49] Loss: 0.4917
[209/300][30/49] Loss: 0.4742
[209/300][35/49] Loss: 0.4564
[209/300][40/49] Loss: 0.5695
[209/300][45/49] Loss: 0.4561
Saving model................
Test set: Average loss: 0.0038, Accuracy: 5126/6230 (82%)
[210/300][0/49] Loss: 0.4871
[210/300][5/49] Loss: 0.5382
[210/300][10/49] Loss: 0.4622
[210/300][15/49] Loss: 0.5279
[210/300][20/49] Loss: 0.4635
[210/300][25/49] Loss: 0.5128
[210/300][30/49] Loss: 0.5330
[210/300][35/49] Loss: 0.4854
[210/300][40/49] Loss: 0.4919
[210/300][45/49] Loss: 0.5154
Saving model................
Test set: Average loss: 0.0038, Accuracy: 5145/6230 (82%)
[211/300][0/49] Loss: 0.5109
[211/300][5/49] Loss: 0.5052
[211/300][10/49] Loss: 0.4675
[211/300][15/49] Loss: 0.5026
[211/300][20/49] Loss: 0.4865
[211/300][25/49] Loss: 0.4863
[211/300][30/49] Loss: 0.4972
[211/300][35/49] Loss: 0.5040
[211/300][40/49] Loss: 0.5247
[211/300][45/49] Loss: 0.4720
Saving model................
Test set: Average loss: 0.0039, Accuracy: 5077/6230 (81%)
[212/300][0/49] Loss: 0.5010
[212/300][5/49] Loss: 0.4863
[212/300][10/49] Loss: 0.5296
[212/300][15/49] Loss: 0.4954
[212/300][20/49] Loss: 0.5044
[212/300][25/49] Loss: 0.5390
[212/300][30/49] Loss: 0.4856
[212/300][35/49] Loss: 0.5017
[212/300][40/49] Loss: 0.4322
[212/300][45/49] Loss: 0.5421
Saving model................
Test set: Average loss: 0.0038, Accuracy: 5140/6230 (82%)
[213/300][0/49] Loss: 0.5063
[213/300][5/49] Loss: 0.4968
[213/300][10/49] Loss: 0.4417
[213/300][15/49] Loss: 0.4958
[213/300][20/49] Loss: 0.5215
[213/300][25/49] Loss: 0.5479
[213/300][30/49] Loss: 0.4328
[213/300][35/49] Loss: 0.5201
[213/300][40/49] Loss: 0.5003
[213/300][45/49] Loss: 0.5241
Saving model................
Test set: Average loss: 0.0038, Accuracy: 5126/6230 (82%)
[214/300][0/49] Loss: 0.5035
[214/300][5/49] Loss: 0.4508
[214/300][10/49] Loss: 0.4847
[214/300][15/49] Loss: 0.4750
[214/300][20/49] Loss: 0.4598
[214/300][25/49] Loss: 0.4709
[214/300][30/49] Loss: 0.5277
[214/300][35/49] Loss: 0.5206
[214/300][40/49] Loss: 0.4852
[214/300][45/49] Loss: 0.4610
Saving model................
Test set: Average loss: 0.0038, Accuracy: 5192/6230 (83%)
[215/300][0/49] Loss: 0.5087
[215/300][5/49] Loss: 0.4450
[215/300][10/49] Loss: 0.4372
[215/300][15/49] Loss: 0.4497
[215/300][20/49] Loss: 0.4299
[215/300][25/49] Loss: 0.4288
[215/300][30/49] Loss: 0.4656
[215/300][35/49] Loss: 0.5147
[215/300][40/49] Loss: 0.4526
[215/300][45/49] Loss: 0.4410
Saving model................
Test set: Average loss: 0.0038, Accuracy: 5155/6230 (82%)
[216/300][0/49] Loss: 0.4906
[216/300][5/49] Loss: 0.4677
[216/300][10/49] Loss: 0.4836
[216/300][15/49] Loss: 0.4940
[216/300][20/49] Loss: 0.4884
[216/300][25/49] Loss: 0.4985
[216/300][30/49] Loss: 0.4639
[216/300][35/49] Loss: 0.4667
[216/300][40/49] Loss: 0.5074
[216/300][45/49] Loss: 0.5362
Saving model................
Test set: Average loss: 0.0038, Accuracy: 5106/6230 (81%)
[217/300][0/49] Loss: 0.4403
[217/300][5/49] Loss: 0.5307
[217/300][10/49] Loss: 0.5145
[217/300][15/49] Loss: 0.4615
[217/300][20/49] Loss: 0.4584
[217/300][25/49] Loss: 0.4321
[217/300][30/49] Loss: 0.4836
[217/300][35/49] Loss: 0.4324
[217/300][40/49] Loss: 0.4644
[217/300][45/49] Loss: 0.4211
Saving model................
Test set: Average loss: 0.0038, Accuracy: 5196/6230 (83%)
[218/300][0/49] Loss: 0.5444
[218/300][5/49] Loss: 0.4219
[218/300][10/49] Loss: 0.5602
[218/300][15/49] Loss: 0.4525
[218/300][20/49] Loss: 0.4631
[218/300][25/49] Loss: 0.4651
[218/300][30/49] Loss: 0.4711
[218/300][35/49] Loss: 0.5129
[218/300][40/49] Loss: 0.5248
[218/300][45/49] Loss: 0.4971
Saving model................
Test set: Average loss: 0.0038, Accuracy: 5182/6230 (83%)
[219/300][0/49] Loss: 0.4937
[219/300][5/49] Loss: 0.4947
[219/300][10/49] Loss: 0.5260
[219/300][15/49] Loss: 0.4720
[219/300][20/49] Loss: 0.5256
[219/300][25/49] Loss: 0.4935
[219/300][30/49] Loss: 0.5087
[219/300][35/49] Loss: 0.5157
[219/300][40/49] Loss: 0.4903
[219/300][45/49] Loss: 0.4477
Saving model................
Test set: Average loss: 0.0039, Accuracy: 5106/6230 (81%)
[220/300][0/49] Loss: 0.4726
[220/300][5/49] Loss: 0.5132
[220/300][10/49] Loss: 0.4970
[220/300][15/49] Loss: 0.4949
[220/300][20/49] Loss: 0.4882
[220/300][25/49] Loss: 0.4840
[220/300][30/49] Loss: 0.4596
[220/300][35/49] Loss: 0.4828
[220/300][40/49] Loss: 0.4876
[220/300][45/49] Loss: 0.5098
Saving model................
Test set: Average loss: 0.0038, Accuracy: 5146/6230 (82%)
[221/300][0/49] Loss: 0.4469
[221/300][5/49] Loss: 0.4702
[221/300][10/49] Loss: 0.5007
[221/300][15/49] Loss: 0.5339
[221/300][20/49] Loss: 0.4972
[221/300][25/49] Loss: 0.4994
[221/300][30/49] Loss: 0.4996
[221/300][35/49] Loss: 0.5612
[221/300][40/49] Loss: 0.4762
[221/300][45/49] Loss: 0.4869
Saving model................
Test set: Average loss: 0.0038, Accuracy: 5143/6230 (82%)
[222/300][0/49] Loss: 0.4878
[222/300][5/49] Loss: 0.5350
[222/300][10/49] Loss: 0.4475
[222/300][15/49] Loss: 0.4683
[222/300][20/49] Loss: 0.4953
[222/300][25/49] Loss: 0.4783
[222/300][30/49] Loss: 0.5398
[222/300][35/49] Loss: 0.4875
[222/300][40/49] Loss: 0.4780
[222/300][45/49] Loss: 0.4684
Saving model................
Test set: Average loss: 0.0039, Accuracy: 5108/6230 (81%)
[223/300][0/49] Loss: 0.5258
[223/300][5/49] Loss: 0.5280
[223/300][10/49] Loss: 0.4854
[223/300][15/49] Loss: 0.4923
[223/300][20/49] Loss: 0.5096
[223/300][25/49] Loss: 0.5886
[223/300][30/49] Loss: 0.5329
[223/300][35/49] Loss: 0.5186
[223/300][40/49] Loss: 0.4485
[223/300][45/49] Loss: 0.4883
Saving model................
Test set: Average loss: 0.0037, Accuracy: 5202/6230 (83%)
[224/300][0/49] Loss: 0.4975
[224/300][5/49] Loss: 0.5055
[224/300][10/49] Loss: 0.4486
[224/300][15/49] Loss: 0.4799
[224/300][20/49] Loss: 0.5181
[224/300][25/49] Loss: 0.4854
[224/300][30/49] Loss: 0.4937
[224/300][35/49] Loss: 0.5143
[224/300][40/49] Loss: 0.4863
[224/300][45/49] Loss: 0.4840
Saving model................
Test set: Average loss: 0.0038, Accuracy: 5190/6230 (83%)
[225/300][0/49] Loss: 0.4714
[225/300][5/49] Loss: 0.4887
[225/300][10/49] Loss: 0.4833
[225/300][15/49] Loss: 0.4795
[225/300][20/49] Loss: 0.5157
[225/300][25/49] Loss: 0.4802
[225/300][30/49] Loss: 0.4707
[225/300][35/49] Loss: 0.4441
[225/300][40/49] Loss: 0.4629
[225/300][45/49] Loss: 0.4566
Saving model................
Test set: Average loss: 0.0037, Accuracy: 5212/6230 (83%)
[226/300][0/49] Loss: 0.4730
[226/300][5/49] Loss: 0.4810
[226/300][10/49] Loss: 0.4831
[226/300][15/49] Loss: 0.4589
[226/300][20/49] Loss: 0.5024
[226/300][25/49] Loss: 0.4468
[226/300][30/49] Loss: 0.4994
[226/300][35/49] Loss: 0.4901
[226/300][40/49] Loss: 0.4641
[226/300][45/49] Loss: 0.5263
Saving model................
Test set: Average loss: 0.0038, Accuracy: 5188/6230 (83%)
[227/300][0/49] Loss: 0.4903
[227/300][5/49] Loss: 0.4620
[227/300][10/49] Loss: 0.4607
[227/300][15/49] Loss: 0.5177
[227/300][20/49] Loss: 0.4657
[227/300][25/49] Loss: 0.4640
[227/300][30/49] Loss: 0.4498
[227/300][35/49] Loss: 0.4947
[227/300][40/49] Loss: 0.4520
[227/300][45/49] Loss: 0.4584
Saving model................
Test set: Average loss: 0.0038, Accuracy: 5168/6230 (82%)
[228/300][0/49] Loss: 0.5332
[228/300][5/49] Loss: 0.5047
[228/300][10/49] Loss: 0.4597
[228/300][15/49] Loss: 0.5064
[228/300][20/49] Loss: 0.5103
[228/300][25/49] Loss: 0.4542
[228/300][30/49] Loss: 0.4935
[228/300][35/49] Loss: 0.4849
[228/300][40/49] Loss: 0.4166
[228/300][45/49] Loss: 0.4542
Saving model................
Test set: Average loss: 0.0038, Accuracy: 5151/6230 (82%)
[229/300][0/49] Loss: 0.5330
[229/300][5/49] Loss: 0.5147
[229/300][10/49] Loss: 0.4760
[229/300][15/49] Loss: 0.5185
[229/300][20/49] Loss: 0.4876
[229/300][25/49] Loss: 0.5419
[229/300][30/49] Loss: 0.4924
[229/300][35/49] Loss: 0.4413
[229/300][40/49] Loss: 0.4709
[229/300][45/49] Loss: 0.4743
Saving model................
n Test set: Average loss: 0.0038, Accuracy: 5152/6230 (82%)
^[[A^[[A^[[A^[[A^[[A^[[A^[[A^[[A^[[A^[[A^[[A^[[A^[[A^[[A^[[A^[[A^[[A^[[A^[[A^[[A^[[A^[[A^[[A^[[A^[[A^[[A^[[A^[[A^[[A^[[A^[[A^[[A^[[A^[[A                                                    [230/300][0/49] Loss: 0.5149
                                                                                    ^L  
[230/300][5/49] Loss: 0.4615
[230/300][10/49] Loss: 0.5152
[230/300][15/49] Loss: 0.4614
[230/300][20/49] Loss: 0.4841
[230/300][25/49] Loss: 0.4704
[230/300][30/49] Loss: 0.4978
[230/300][35/49] Loss: 0.5038
[230/300][40/49] Loss: 0.5584
[230/300][45/49] Loss: 0.5001
Saving model................
Test set: Average loss: 0.0038, Accuracy: 5160/6230 (82%)
[231/300][0/49] Loss: 0.4561
[231/300][5/49] Loss: 0.5117
[231/300][10/49] Loss: 0.4950
[231/300][15/49] Loss: 0.4717
[231/300][20/49] Loss: 0.4924
[231/300][25/49] Loss: 0.5008
[231/300][30/49] Loss: 0.5385
[231/300][35/49] Loss: 0.5109
[231/300][40/49] Loss: 0.4697
[231/300][45/49] Loss: 0.4663
Saving model................
Test set: Average loss: 0.0037, Accuracy: 5223/6230 (83%)
[232/300][0/49] Loss: 0.4579
[232/300][5/49] Loss: 0.4750
[232/300][10/49] Loss: 0.4936
[232/300][15/49] Loss: 0.4565
[232/300][20/49] Loss: 0.5483
[232/300][25/49] Loss: 0.5064
[232/300][30/49] Loss: 0.5317
[232/300][35/49] Loss: 0.4934
[232/300][40/49] Loss: 0.4505
[232/300][45/49] Loss: 0.5653
Saving model................
Test set: Average loss: 0.0039, Accuracy: 5086/6230 (81%)
[233/300][0/49] Loss: 0.5344
[233/300][5/49] Loss: 0.4781
[233/300][10/49] Loss: 0.5084
[233/300][15/49] Loss: 0.4632
[233/300][20/49] Loss: 0.4567
[233/300][25/49] Loss: 0.4938
[233/300][30/49] Loss: 0.4933
[233/300][35/49] Loss: 0.5377
[233/300][40/49] Loss: 0.4816
[233/300][45/49] Loss: 0.4597
Saving model................
Test set: Average loss: 0.0038, Accuracy: 5193/6230 (83%)
[234/300][0/49] Loss: 0.4367
[234/300][5/49] Loss: 0.4709
[234/300][10/49] Loss: 0.5286
[234/300][15/49] Loss: 0.4522
[234/300][20/49] Loss: 0.4841
[234/300][25/49] Loss: 0.4579
[234/300][30/49] Loss: 0.5066
[234/300][35/49] Loss: 0.5773
[234/300][40/49] Loss: 0.4799
[234/300][45/49] Loss: 0.4951
Saving model................
Test set: Average loss: 0.0039, Accuracy: 5066/6230 (81%)
[235/300][0/49] Loss: 0.5091
[235/300][5/49] Loss: 0.4969
[235/300][10/49] Loss: 0.4855
[235/300][15/49] Loss: 0.4694
[235/300][20/49] Loss: 0.5146
[235/300][25/49] Loss: 0.5189
[235/300][30/49] Loss: 0.4971
[235/300][35/49] Loss: 0.5703
[235/300][40/49] Loss: 0.5165
[235/300][45/49] Loss: 0.5496
Saving model................
Test set: Average loss: 0.0041, Accuracy: 4886/6230 (78%)
[236/300][0/49] Loss: 0.4929
[236/300][5/49] Loss: 0.4557
[236/300][10/49] Loss: 0.4464
[236/300][15/49] Loss: 0.5415
[236/300][20/49] Loss: 0.4822
[236/300][25/49] Loss: 0.5309
[236/300][30/49] Loss: 0.5183
[236/300][35/49] Loss: 0.4456
[236/300][40/49] Loss: 0.4168
[236/300][45/49] Loss: 0.5882
Saving model................
Test set: Average loss: 0.0039, Accuracy: 5093/6230 (81%)
[237/300][0/49] Loss: 0.4993
zz  [237/300][5/49] Loss: 0.4691
[237/300][10/49] Loss: 0.4693
[237/300][15/49] Loss: 0.5270
[237/300][20/49] Loss: 0.5306
[237/300][25/49] Loss: 0.4745
[237/300][30/49] Loss: 0.4741
[237/300][35/49] Loss: 0.5365
[237/300][40/49] Loss: 0.4794
[237/300][45/49] Loss: 0.4791
Saving model................
Test set: Average loss: 0.0042, Accuracy: 4861/6230 (78%)
[238/300][0/49] Loss: 0.6117
[238/300][5/49] Loss: 0.5398
[238/300][10/49] Loss: 0.4950
[238/300][15/49] Loss: 0.5609
[238/300][20/49] Loss: 0.5400
[238/300][25/49] Loss: 0.4551
[238/300][30/49] Loss: 0.5360
[238/300][35/49] Loss: 0.6007
[238/300][40/49] Loss: 0.5504
[238/300][45/49] Loss: 0.5972
Saving model................
Test set: Average loss: 0.0038, Accuracy: 5156/6230 (82%)
[239/300][0/49] Loss: 0.4765
[239/300][5/49] Loss: 0.4891
[239/300][10/49] Loss: 0.5002
[239/300][15/49] Loss: 0.4885
[239/300][20/49] Loss: 0.5732
[239/300][25/49] Loss: 0.5029
[239/300][30/49] Loss: 0.5279
[239/300][35/49] Loss: 0.5379
[239/300][40/49] Loss: 0.5026
[239/300][45/49] Loss: 0.4451
Saving model................
Test set: Average loss: 0.0039, Accuracy: 5068/6230 (81%)
[240/300][0/49] Loss: 0.5493
[240/300][5/49] Loss: 0.4598
[240/300][10/49] Loss: 0.4725
[240/300][15/49] Loss: 0.5080
[240/300][20/49] Loss: 0.5092
[240/300][25/49] Loss: 0.5082
[240/300][30/49] Loss: 0.5291
[240/300][35/49] Loss: 0.4949
[240/300][40/49] Loss: 0.4893
[240/300][45/49] Loss: 0.5601
Saving model................
Test set: Average loss: 0.0040, Accuracy: 5019/6230 (80%)
[241/300][0/49] Loss: 0.5005
[241/300][5/49] Loss: 0.5143
[241/300][10/49] Loss: 0.5083
[241/300][15/49] Loss: 0.4929
[241/300][20/49] Loss: 0.5245
[241/300][25/49] Loss: 0.4651
[241/300][30/49] Loss: 0.5354
[241/300][35/49] Loss: 0.5249
[241/300][40/49] Loss: 0.4955
[241/300][45/49] Loss: 0.5912
Saving model................
Test set: Average loss: 0.0040, Accuracy: 5002/6230 (80%)
[242/300][0/49] Loss: 0.5045
[242/300][5/49] Loss: 0.4860
[242/300][10/49] Loss: 0.4959
[242/300][15/49] Loss: 0.4805
[242/300][20/49] Loss: 0.5235
[242/300][25/49] Loss: 0.5193
[242/300][30/49] Loss: 0.4800
[242/300][35/49] Loss: 0.5050
[242/300][40/49] Loss: 0.5160
[242/300][45/49] Loss: 0.5075
Saving model................
Test set: Average loss: 0.0039, Accuracy: 5110/6230 (82%)
[243/300][0/49] Loss: 0.4536
[243/300][5/49] Loss: 0.5385
[243/300][10/49] Loss: 0.4955
[243/300][15/49] Loss: 0.5173
[243/300][20/49] Loss: 0.5045
[243/300][25/49] Loss: 0.4355
[243/300][30/49] Loss: 0.4470
[243/300][35/49] Loss: 0.5275
[243/300][40/49] Loss: 0.5148
[243/300][45/49] Loss: 0.5349
Saving model................
Test set: Average loss: 0.0043, Accuracy: 4749/6230 (76%)
[244/300][0/49] Loss: 0.5001
[244/300][5/49] Loss: 0.5390
[244/300][10/49] Loss: 0.6051
[244/300][15/49] Loss: 0.5584
[244/300][20/49] Loss: 0.5558
[244/300][25/49] Loss: 0.5856
[244/300][30/49] Loss: 0.5028
[244/300][35/49] Loss: 0.5202
[244/300][40/49] Loss: 0.4678
[244/300][45/49] Loss: 0.5374
Saving model................
Test set: Average loss: 0.0040, Accuracy: 5019/6230 (80%)
[245/300][0/49] Loss: 0.4144
[245/300][5/49] Loss: 0.4852
[245/300][10/49] Loss: 0.5744
[245/300][15/49] Loss: 0.4856
[245/300][20/49] Loss: 0.5120
[245/300][25/49] Loss: 0.5431
[245/300][30/49] Loss: 0.5112
[245/300][35/49] Loss: 0.5308
[245/300][40/49] Loss: 0.5298
[245/300][45/49] Loss: 0.4758
Saving model................
Test set: Average loss: 0.0039, Accuracy: 5053/6230 (81%)
[246/300][0/49] Loss: 0.5075
[246/300][5/49] Loss: 0.5158
[246/300][10/49] Loss: 0.4983
[246/300][15/49] Loss: 0.4988
[246/300][20/49] Loss: 0.5684
[246/300][25/49] Loss: 0.5094
[246/300][30/49] Loss: 0.4690
[246/300][35/49] Loss: 0.4783
[246/300][40/49] Loss: 0.5106
[246/300][45/49] Loss: 0.5285
Saving model................
Test set: Average loss: 0.0038, Accuracy: 5171/6230 (83%)
[247/300][0/49] Loss: 0.4819
[247/300][5/49] Loss: 0.5035
[247/300][10/49] Loss: 0.5141
[247/300][15/49] Loss: 0.4814
[247/300][20/49] Loss: 0.5522
[247/300][25/49] Loss: 0.4793
[247/300][30/49] Loss: 0.5171
[247/300][35/49] Loss: 0.4698
[247/300][40/49] Loss: 0.5342
[247/300][45/49] Loss: 0.4576
Saving model................
Test set: Average loss: 0.0039, Accuracy: 5050/6230 (81%)
[248/300][0/49] Loss: 0.5174
[248/300][5/49] Loss: 0.5296
[248/300][10/49] Loss: 0.4890
[248/300][15/49] Loss: 0.4850
[248/300][20/49] Loss: 0.5202
[248/300][25/49] Loss: 0.4590
[248/300][30/49] Loss: 0.5270
[248/300][35/49] Loss: 0.5369
[248/300][40/49] Loss: 0.5121
[248/300][45/49] Loss: 0.4888
Saving model................
Test set: Average loss: 0.0040, Accuracy: 5036/6230 (80%)
[249/300][0/49] Loss: 0.5274
[249/300][5/49] Loss: 0.4751
[249/300][10/49] Loss: 0.5223
[249/300][15/49] Loss: 0.5274
[249/300][20/49] Loss: 0.5545
[249/300][25/49] Loss: 0.5360
[249/300][30/49] Loss: 0.4969
[249/300][35/49] Loss: 0.4747
[249/300][40/49] Loss: 0.5173
[249/300][45/49] Loss: 0.5640
Saving model................
Test set: Average loss: 0.0038, Accuracy: 5146/6230 (82%)
[250/300][0/49] Loss: 0.4836
[250/300][5/49] Loss: 0.4708
[250/300][10/49] Loss: 0.5383
[250/300][15/49] Loss: 0.5407
[250/300][20/49] Loss: 0.4808
[250/300][25/49] Loss: 0.4765
[250/300][30/49] Loss: 0.5076
[250/300][35/49] Loss: 0.4849
[250/300][40/49] Loss: 0.4439
[250/300][45/49] Loss: 0.4976
Saving model................
Test set: Average loss: 0.0038, Accuracy: 5122/6230 (82%)
[251/300][0/49] Loss: 0.4574
[251/300][5/49] Loss: 0.4766
[251/300][10/49] Loss: 0.4322
[251/300][15/49] Loss: 0.5164
[251/300][20/49] Loss: 0.4660
[251/300][25/49] Loss: 0.5044
[251/300][30/49] Loss: 0.4803
[251/300][35/49] Loss: 0.5054
[251/300][40/49] Loss: 0.4560
[251/300][45/49] Loss: 0.5370
Saving model................
Test set: Average loss: 0.0040, Accuracy: 4980/6230 (79%)
[252/300][0/49] Loss: 0.5177
[252/300][5/49] Loss: 0.5206
[252/300][10/49] Loss: 0.5131
[252/300][15/49] Loss: 0.4661
[252/300][20/49] Loss: 0.5005
[252/300][25/49] Loss: 0.4990
[252/300][30/49] Loss: 0.5249
[252/300][35/49] Loss: 0.5428
[252/300][40/49] Loss: 0.5096
[252/300][45/49] Loss: 0.5239
Saving model................
Test set: Average loss: 0.0040, Accuracy: 5030/6230 (80%)
[253/300][0/49] Loss: 0.4641
[253/300][5/49] Loss: 0.5129
[253/300][10/49] Loss: 0.5178
[253/300][15/49] Loss: 0.5252
[253/300][20/49] Loss: 0.5415
[253/300][25/49] Loss: 0.4794
[253/300][30/49] Loss: 0.4943
[253/300][35/49] Loss: 0.4906
[253/300][40/49] Loss: 0.4466
[253/300][45/49] Loss: 0.4898
Saving model................
Test set: Average loss: 0.0039, Accuracy: 5094/6230 (81%)
[254/300][0/49] Loss: 0.5115
[254/300][5/49] Loss: 0.5458
[254/300][10/49] Loss: 0.4913
[254/300][15/49] Loss: 0.4781
[254/300][20/49] Loss: 0.5398
[254/300][25/49] Loss: 0.5558
[254/300][30/49] Loss: 0.4743
[254/300][35/49] Loss: 0.4650
[254/300][40/49] Loss: 0.4476
[254/300][45/49] Loss: 0.4714
Saving model................
Test set: Average loss: 0.0037, Accuracy: 5220/6230 (83%)
[255/300][0/49] Loss: 0.4554
[255/300][5/49] Loss: 0.4536
[255/300][10/49] Loss: 0.4904
[255/300][15/49] Loss: 0.4809
[255/300][20/49] Loss: 0.4419
[255/300][25/49] Loss: 0.5022
[255/300][30/49] Loss: 0.4492
[255/300][35/49] Loss: 0.4127
[255/300][40/49] Loss: 0.5240
[255/300][45/49] Loss: 0.4697
Saving model................
Test set: Average loss: 0.0038, Accuracy: 5178/6230 (83%)
[256/300][0/49] Loss: 0.5012
[256/300][5/49] Loss: 0.4799
[256/300][10/49] Loss: 0.5105
[256/300][15/49] Loss: 0.4832
[256/300][20/49] Loss: 0.4700
[256/300][25/49] Loss: 0.4881
[256/300][30/49] Loss: 0.4625
[256/300][35/49] Loss: 0.4619
[256/300][40/49] Loss: 0.4807
[256/300][45/49] Loss: 0.4273
Saving model................
Test set: Average loss: 0.0037, Accuracy: 5214/6230 (83%)
[257/300][0/49] Loss: 0.4812
[257/300][5/49] Loss: 0.4405
[257/300][10/49] Loss: 0.5010
[257/300][15/49] Loss: 0.4743
[257/300][20/49] Loss: 0.5125
[257/300][25/49] Loss: 0.5164
[257/300][30/49] Loss: 0.4668
[257/300][35/49] Loss: 0.4397
[257/300][40/49] Loss: 0.4892
[257/300][45/49] Loss: 0.4607
Saving model................
Test set: Average loss: 0.0038, Accuracy: 5203/6230 (83%)
[258/300][0/49] Loss: 0.4708
[258/300][5/49] Loss: 0.4533
[258/300][10/49] Loss: 0.4834
[258/300][15/49] Loss: 0.5027
[258/300][20/49] Loss: 0.5053
[258/300][25/49] Loss: 0.4635
[258/300][30/49] Loss: 0.5108
[258/300][35/49] Loss: 0.5003
[258/300][40/49] Loss: 0.5511
[258/300][45/49] Loss: 0.4717
Saving model................
Test set: Average loss: 0.0038, Accuracy: 5197/6230 (83%)
[259/300][0/49] Loss: 0.4990
[259/300][5/49] Loss: 0.5256
[259/300][10/49] Loss: 0.4781
[259/300][15/49] Loss: 0.4497
[259/300][20/49] Loss: 0.4814
[259/300][25/49] Loss: 0.4659
[259/300][30/49] Loss: 0.4916
[259/300][35/49] Loss: 0.5208
[259/300][40/49] Loss: 0.5165
[259/300][45/49] Loss: 0.4659
Saving model................
Test set: Average loss: 0.0039, Accuracy: 5051/6230 (81%)
[260/300][0/49] Loss: 0.5447
[260/300][5/49] Loss: 0.4942
[260/300][10/49] Loss: 0.5669
[260/300][15/49] Loss: 0.4520
[260/300][20/49] Loss: 0.4788
[260/300][25/49] Loss: 0.4747
[260/300][30/49] Loss: 0.4556
[260/300][35/49] Loss: 0.4953
[260/300][40/49] Loss: 0.4756
[260/300][45/49] Loss: 0.5217
Saving model................
Test set: Average loss: 0.0038, Accuracy: 5196/6230 (83%)
[261/300][0/49] Loss: 0.4718
[261/300][5/49] Loss: 0.4556
[261/300][10/49] Loss: 0.4580
[261/300][15/49] Loss: 0.5009
[261/300][20/49] Loss: 0.4748
[261/300][25/49] Loss: 0.5076
[261/300][30/49] Loss: 0.4347
[261/300][35/49] Loss: 0.4207
[261/300][40/49] Loss: 0.5692
[261/300][45/49] Loss: 0.4727
Saving model................
Test set: Average loss: 0.0038, Accuracy: 5205/6230 (83%)
[262/300][0/49] Loss: 0.4677
[262/300][5/49] Loss: 0.4388
[262/300][10/49] Loss: 0.4454
[262/300][15/49] Loss: 0.5001
[262/300][20/49] Loss: 0.4966
[262/300][25/49] Loss: 0.4905
[262/300][30/49] Loss: 0.4945
[262/300][35/49] Loss: 0.4934
[262/300][40/49] Loss: 0.4884
[262/300][45/49] Loss: 0.5526
Saving model................
Test set: Average loss: 0.0038, Accuracy: 5135/6230 (82%)
[263/300][0/49] Loss: 0.4946
[263/300][5/49] Loss: 0.4815
[263/300][10/49] Loss: 0.4877
[263/300][15/49] Loss: 0.4798
[263/300][20/49] Loss: 0.4316
[263/300][25/49] Loss: 0.4394
[263/300][30/49] Loss: 0.4637
[263/300][35/49] Loss: 0.4431
[263/300][40/49] Loss: 0.4519
[263/300][45/49] Loss: 0.4608
Saving model................
Test set: Average loss: 0.0037, Accuracy: 5208/6230 (83%)
[264/300][0/49] Loss: 0.4590
[264/300][5/49] Loss: 0.4738
[264/300][10/49] Loss: 0.4838
[264/300][15/49] Loss: 0.4652
[264/300][20/49] Loss: 0.4863
[264/300][25/49] Loss: 0.4965
[264/300][30/49] Loss: 0.5017
[264/300][35/49] Loss: 0.4843
[264/300][40/49] Loss: 0.4984
[264/300][45/49] Loss: 0.4854
Saving model................
Test set: Average loss: 0.0038, Accuracy: 5165/6230 (82%)
[265/300][0/49] Loss: 0.4957
[265/300][5/49] Loss: 0.4382
[265/300][10/49] Loss: 0.4373
[265/300][15/49] Loss: 0.4507
[265/300][20/49] Loss: 0.4457
[265/300][25/49] Loss: 0.4839
[265/300][30/49] Loss: 0.4840
[265/300][35/49] Loss: 0.4529
[265/300][40/49] Loss: 0.4941
[265/300][45/49] Loss: 0.5453
Saving model................
Test set: Average loss: 0.0038, Accuracy: 5182/6230 (83%)
[266/300][0/49] Loss: 0.4882
[266/300][5/49] Loss: 0.4527
[266/300][10/49] Loss: 0.4975
[266/300][15/49] Loss: 0.4936
[266/300][20/49] Loss: 0.4418
[266/300][25/49] Loss: 0.5597
[266/300][30/49] Loss: 0.4897
[266/300][35/49] Loss: 0.4519
[266/300][40/49] Loss: 0.4998
[266/300][45/49] Loss: 0.4735
Saving model................
Test set: Average loss: 0.0037, Accuracy: 5233/6230 (83%)
[267/300][0/49] Loss: 0.4426
[267/300][5/49] Loss: 0.5001
[267/300][10/49] Loss: 0.4774
[267/300][15/49] Loss: 0.5086
[267/300][20/49] Loss: 0.4972
[267/300][25/49] Loss: 0.5170
[267/300][30/49] Loss: 0.4605
[267/300][35/49] Loss: 0.4857
[267/300][40/49] Loss: 0.4461
[267/300][45/49] Loss: 0.4461
Saving model................
Test set: Average loss: 0.0038, Accuracy: 5146/6230 (82%)
[268/300][0/49] Loss: 0.5279
[268/300][5/49] Loss: 0.4731
[268/300][10/49] Loss: 0.4889
[268/300][15/49] Loss: 0.4751
[268/300][20/49] Loss: 0.4395
[268/300][25/49] Loss: 0.4552
[268/300][30/49] Loss: 0.5475
[268/300][35/49] Loss: 0.4820
[268/300][40/49] Loss: 0.5299
[268/300][45/49] Loss: 0.5440
Saving model................
Test set: Average loss: 0.0039, Accuracy: 5080/6230 (81%)
[269/300][0/49] Loss: 0.4861
[269/300][5/49] Loss: 0.5363
[269/300][10/49] Loss: 0.5978
[269/300][15/49] Loss: 0.5548
[269/300][20/49] Loss: 0.5416
[269/300][25/49] Loss: 0.5522
[269/300][30/49] Loss: 0.4509
[269/300][35/49] Loss: 0.5154
[269/300][40/49] Loss: 0.4300
[269/300][45/49] Loss: 0.4949
Saving model................
Test set: Average loss: 0.0040, Accuracy: 5008/6230 (80%)
[270/300][0/49] Loss: 0.5785
[270/300][5/49] Loss: 0.4696
[270/300][10/49] Loss: 0.4913
[270/300][15/49] Loss: 0.4938
[270/300][20/49] Loss: 0.4863
[270/300][25/49] Loss: 0.4261
[270/300][30/49] Loss: 0.5355
[270/300][35/49] Loss: 0.4825
[270/300][40/49] Loss: 0.5342
[270/300][45/49] Loss: 0.4919
Saving model................
Test set: Average loss: 0.0039, Accuracy: 5048/6230 (81%)
[271/300][0/49] Loss: 0.4874
[271/300][5/49] Loss: 0.4819
[271/300][10/49] Loss: 0.4995
[271/300][15/49] Loss: 0.4774
[271/300][20/49] Loss: 0.4658
[271/300][25/49] Loss: 0.4772
[271/300][30/49] Loss: 0.4806
[271/300][35/49] Loss: 0.4926
[271/300][40/49] Loss: 0.4621
[271/300][45/49] Loss: 0.4100
Saving model................
Test set: Average loss: 0.0038, Accuracy: 5198/6230 (83%)
[272/300][0/49] Loss: 0.4617
[272/300][5/49] Loss: 0.5039
[272/300][10/49] Loss: 0.5309
[272/300][15/49] Loss: 0.4825
[272/300][20/49] Loss: 0.4099
[272/300][25/49] Loss: 0.5166
[272/300][30/49] Loss: 0.5231
[272/300][35/49] Loss: 0.5112
[272/300][40/49] Loss: 0.4556
[272/300][45/49] Loss: 0.4572
Saving model................
Test set: Average loss: 0.0038, Accuracy: 5183/6230 (83%)
[273/300][0/49] Loss: 0.5106
[273/300][5/49] Loss: 0.4443
[273/300][10/49] Loss: 0.5475
[273/300][15/49] Loss: 0.4868
[273/300][20/49] Loss: 0.4980
[273/300][25/49] Loss: 0.5169
[273/300][30/49] Loss: 0.5207
[273/300][35/49] Loss: 0.4701
[273/300][40/49] Loss: 0.5237
[273/300][45/49] Loss: 0.5449
Saving model................
Test set: Average loss: 0.0040, Accuracy: 5005/6230 (80%)
[274/300][0/49] Loss: 0.4984
[274/300][5/49] Loss: 0.5122
[274/300][10/49] Loss: 0.5477
[274/300][15/49] Loss: 0.4753
[274/300][20/49] Loss: 0.5107
[274/300][25/49] Loss: 0.4666
[274/300][30/49] Loss: 0.4391
[274/300][35/49] Loss: 0.4855
[274/300][40/49] Loss: 0.5260
[274/300][45/49] Loss: 0.6291
Saving model................
Test set: Average loss: 0.0040, Accuracy: 4965/6230 (79%)
[275/300][0/49] Loss: 0.5600
[275/300][5/49] Loss: 0.4945
[275/300][10/49] Loss: 0.5405
[275/300][15/49] Loss: 0.5191
[275/300][20/49] Loss: 0.4946
[275/300][25/49] Loss: 0.4999
[275/300][30/49] Loss: 0.4657
[275/300][35/49] Loss: 0.5399
[275/300][40/49] Loss: 0.4668
[275/300][45/49] Loss: 0.5063
Saving model................
Test set: Average loss: 0.0038, Accuracy: 5176/6230 (83%)
[276/300][0/49] Loss: 0.4564
[276/300][5/49] Loss: 0.4995
[276/300][10/49] Loss: 0.5385
[276/300][15/49] Loss: 0.4911
[276/300][20/49] Loss: 0.5173
[276/300][25/49] Loss: 0.4812
[276/300][30/49] Loss: 0.5021
[276/300][35/49] Loss: 0.5518
[276/300][40/49] Loss: 0.5619
[276/300][45/49] Loss: 0.5042
Saving model................
Test set: Average loss: 0.0039, Accuracy: 5063/6230 (81%)
[277/300][0/49] Loss: 0.5277
[277/300][5/49] Loss: 0.5259
[277/300][10/49] Loss: 0.4844
[277/300][15/49] Loss: 0.4913
[277/300][20/49] Loss: 0.5592
[277/300][25/49] Loss: 0.5046
[277/300][30/49] Loss: 0.4829
[277/300][35/49] Loss: 0.4952
[277/300][40/49] Loss: 0.5224
[277/300][45/49] Loss: 0.5154
Saving model................
Test set: Average loss: 0.0039, Accuracy: 5111/6230 (82%)
[278/300][0/49] Loss: 0.4535
[278/300][5/49] Loss: 0.4935
[278/300][10/49] Loss: 0.4824
[278/300][15/49] Loss: 0.4387
[278/300][20/49] Loss: 0.4946
[278/300][25/49] Loss: 0.4341
[278/300][30/49] Loss: 0.4776
[278/300][35/49] Loss: 0.5572
[278/300][40/49] Loss: 0.4930
[278/300][45/49] Loss: 0.4867
Saving model................
Test set: Average loss: 0.0041, Accuracy: 4936/6230 (79%)
[279/300][0/49] Loss: 0.5284
[279/300][5/49] Loss: 0.5343
[279/300][10/49] Loss: 0.5777
[279/300][15/49] Loss: 0.5546
[279/300][20/49] Loss: 0.4571
[279/300][25/49] Loss: 0.5238
[279/300][30/49] Loss: 0.4971
[279/300][35/49] Loss: 0.5258
[279/300][40/49] Loss: 0.4799
[279/300][45/49] Loss: 0.5233
Saving model................
Test set: Average loss: 0.0038, Accuracy: 5147/6230 (82%)
[280/300][0/49] Loss: 0.5197
[280/300][5/49] Loss: 0.5538
[280/300][10/49] Loss: 0.4878
[280/300][15/49] Loss: 0.5352
[280/300][20/49] Loss: 0.4896
[280/300][25/49] Loss: 0.4559
[280/300][30/49] Loss: 0.5029
[280/300][35/49] Loss: 0.4716
[280/300][40/49] Loss: 0.5019
[280/300][45/49] Loss: 0.5127
Saving model................
Test set: Average loss: 0.0038, Accuracy: 5137/6230 (82%)
[281/300][0/49] Loss: 0.4633
[281/300][5/49] Loss: 0.5120
[281/300][10/49] Loss: 0.4982
[281/300][15/49] Loss: 0.4490
[281/300][20/49] Loss: 0.5546
[281/300][25/49] Loss: 0.4692
[281/300][30/49] Loss: 0.5423
[281/300][35/49] Loss: 0.4761
[281/300][40/49] Loss: 0.5404
[281/300][45/49] Loss: 0.4912
Saving model................
Test set: Average loss: 0.0040, Accuracy: 4990/6230 (80%)
[282/300][0/49] Loss: 0.5324
[282/300][5/49] Loss: 0.5359
[282/300][10/49] Loss: 0.5139
[282/300][15/49] Loss: 0.4553
[282/300][20/49] Loss: 0.4836
[282/300][25/49] Loss: 0.4695
[282/300][30/49] Loss: 0.5305
[282/300][35/49] Loss: 0.5567
[282/300][40/49] Loss: 0.4625
[282/300][45/49] Loss: 0.4730
Saving model................
Test set: Average loss: 0.0039, Accuracy: 5103/6230 (81%)
[283/300][0/49] Loss: 0.5071
[283/300][5/49] Loss: 0.4926
[283/300][10/49] Loss: 0.5209
[283/300][15/49] Loss: 0.4520
[283/300][20/49] Loss: 0.5277
[283/300][25/49] Loss: 0.4745
[283/300][30/49] Loss: 0.5372
[283/300][35/49] Loss: 0.5252
[283/300][40/49] Loss: 0.4944
[283/300][45/49] Loss: 0.5161
Saving model................
Test set: Average loss: 0.0038, Accuracy: 5144/6230 (82%)
[284/300][0/49] Loss: 0.5242
[284/300][5/49] Loss: 0.4828
[284/300][10/49] Loss: 0.4807
[284/300][15/49] Loss: 0.5188
[284/300][20/49] Loss: 0.3933
[284/300][25/49] Loss: 0.4586
[284/300][30/49] Loss: 0.4693
[284/300][35/49] Loss: 0.4885
[284/300][40/49] Loss: 0.5267
[284/300][45/49] Loss: 0.4913
Saving model................
Test set: Average loss: 0.0038, Accuracy: 5154/6230 (82%)
[285/300][0/49] Loss: 0.4631
[285/300][5/49] Loss: 0.4610
[285/300][10/49] Loss: 0.5178
[285/300][15/49] Loss: 0.5306
[285/300][20/49] Loss: 0.4226
[285/300][25/49] Loss: 0.4964
[285/300][30/49] Loss: 0.5138
[285/300][35/49] Loss: 0.5678
[285/300][40/49] Loss: 0.5089
[285/300][45/49] Loss: 0.5211
Saving model................
Test set: Average loss: 0.0038, Accuracy: 5121/6230 (82%)
[286/300][0/49] Loss: 0.4410
[286/300][5/49] Loss: 0.4928
[286/300][10/49] Loss: 0.5499
[286/300][15/49] Loss: 0.5104
[286/300][20/49] Loss: 0.5093
[286/300][25/49] Loss: 0.4945
[286/300][30/49] Loss: 0.5922
[286/300][35/49] Loss: 0.4175
[286/300][40/49] Loss: 0.4539
[286/300][45/49] Loss: 0.4778
Saving model................
Test set: Average loss: 0.0039, Accuracy: 5102/6230 (81%)
[287/300][0/49] Loss: 0.4927
[287/300][5/49] Loss: 0.4646
[287/300][10/49] Loss: 0.5085
[287/300][15/49] Loss: 0.4909
[287/300][20/49] Loss: 0.4871
[287/300][25/49] Loss: 0.4716
[287/300][30/49] Loss: 0.5108
[287/300][35/49] Loss: 0.4896
[287/300][40/49] Loss: 0.4672
[287/300][45/49] Loss: 0.5525
Saving model................
Test set: Average loss: 0.0039, Accuracy: 5082/6230 (81%)
[288/300][0/49] Loss: 0.4781
[288/300][5/49] Loss: 0.4855
[288/300][10/49] Loss: 0.4930
[288/300][15/49] Loss: 0.4848
[288/300][20/49] Loss: 0.4635
[288/300][25/49] Loss: 0.4874
[288/300][30/49] Loss: 0.4851
[288/300][35/49] Loss: 0.5485
[288/300][40/49] Loss: 0.4951
[288/300][45/49] Loss: 0.5267
Saving model................
Test set: Average loss: 0.0038, Accuracy: 5129/6230 (82%)
[289/300][0/49] Loss: 0.5082
[289/300][5/49] Loss: 0.4824
[289/300][10/49] Loss: 0.4863
[289/300][15/49] Loss: 0.5087
[289/300][20/49] Loss: 0.5545
[289/300][25/49] Loss: 0.4489
[289/300][30/49] Loss: 0.4943
[289/300][35/49] Loss: 0.5516
[289/300][40/49] Loss: 0.5481
[289/300][45/49] Loss: 0.4704
Saving model................
Test set: Average loss: 0.0040, Accuracy: 5011/6230 (80%)
[290/300][0/49] Loss: 0.5163
[290/300][5/49] Loss: 0.5242
[290/300][10/49] Loss: 0.4852
[290/300][15/49] Loss: 0.4868
[290/300][20/49] Loss: 0.4844
[290/300][25/49] Loss: 0.4413
[290/300][30/49] Loss: 0.5339
[290/300][35/49] Loss: 0.4938
[290/300][40/49] Loss: 0.4849
[290/300][45/49] Loss: 0.4835
Saving model................
Test set: Average loss: 0.0039, Accuracy: 5062/6230 (81%)
[291/300][0/49] Loss: 0.4630
[291/300][5/49] Loss: 0.4442
[291/300][10/49] Loss: 0.4765
[291/300][15/49] Loss: 0.4669
[291/300][20/49] Loss: 0.4333
[291/300][25/49] Loss: 0.4566
[291/300][30/49] Loss: 0.4656
[291/300][35/49] Loss: 0.5164
[291/300][40/49] Loss: 0.4805
[291/300][45/49] Loss: 0.4559
Saving model................
Test set: Average loss: 0.0038, Accuracy: 5132/6230 (82%)
[292/300][0/49] Loss: 0.4808
[292/300][5/49] Loss: 0.5165
[292/300][10/49] Loss: 0.4519
[292/300][15/49] Loss: 0.5710
[292/300][20/49] Loss: 0.4933
[292/300][25/49] Loss: 0.4549
[292/300][30/49] Loss: 0.5184
[292/300][35/49] Loss: 0.4903
[292/300][40/49] Loss: 0.4867
[292/300][45/49] Loss: 0.5504
Saving model................
Test set: Average loss: 0.0040, Accuracy: 4972/6230 (79%)
[293/300][0/49] Loss: 0.4987
[293/300][5/49] Loss: 0.5862
[293/300][10/49] Loss: 0.4588
[293/300][15/49] Loss: 0.4980
[293/300][20/49] Loss: 0.5145
[293/300][25/49] Loss: 0.5150
[293/300][30/49] Loss: 0.4991
[293/300][35/49] Loss: 0.4936
[293/300][40/49] Loss: 0.5043
[293/300][45/49] Loss: 0.5263
Saving model................
Test set: Average loss: 0.0039, Accuracy: 5049/6230 (81%)
[294/300][0/49] Loss: 0.4693
[294/300][5/49] Loss: 0.5149
[294/300][10/49] Loss: 0.5446
[294/300][15/49] Loss: 0.5276
[294/300][20/49] Loss: 0.5039
[294/300][25/49] Loss: 0.5622
[294/300][30/49] Loss: 0.5387
[294/300][35/49] Loss: 0.5251
[294/300][40/49] Loss: 0.5111
[294/300][45/49] Loss: 0.4328
Saving model................
Test set: Average loss: 0.0038, Accuracy: 5133/6230 (82%)
[295/300][0/49] Loss: 0.4994
[295/300][5/49] Loss: 0.4832
[295/300][10/49] Loss: 0.4748
[295/300][15/49] Loss: 0.4682
[295/300][20/49] Loss: 0.4396
[295/300][25/49] Loss: 0.4555
[295/300][30/49] Loss: 0.4977
[295/300][35/49] Loss: 0.5314
[295/300][40/49] Loss: 0.5089
[295/300][45/49] Loss: 0.5405
Saving model................
Test set: Average loss: 0.0038, Accuracy: 5175/6230 (83%)
[296/300][0/49] Loss: 0.4604
[296/300][5/49] Loss: 0.4503
[296/300][10/49] Loss: 0.4926
[296/300][15/49] Loss: 0.4642
[296/300][20/49] Loss: 0.4410
[296/300][25/49] Loss: 0.4734
[296/300][30/49] Loss: 0.5373
[296/300][35/49] Loss: 0.5634
[296/300][40/49] Loss: 0.5522
[296/300][45/49] Loss: 0.6222
Saving model................
Test set: Average loss: 0.0039, Accuracy: 5058/6230 (81%)
[297/300][0/49] Loss: 0.5335
[297/300][5/49] Loss: 0.5265
[297/300][10/49] Loss: 0.4904
[297/300][15/49] Loss: 0.4976
[297/300][20/49] Loss: 0.4745
[297/300][25/49] Loss: 0.4777
[297/300][30/49] Loss: 0.4685
[297/300][35/49] Loss: 0.4542
[297/300][40/49] Loss: 0.4864
[297/300][45/49] Loss: 0.4715
Saving model................
Test set: Average loss: 0.0039, Accuracy: 5086/6230 (81%)
[298/300][0/49] Loss: 0.5143
[298/300][5/49] Loss: 0.4690
[298/300][10/49] Loss: 0.5216
[298/300][15/49] Loss: 0.5372
[298/300][20/49] Loss: 0.4791
[298/300][25/49] Loss: 0.4916
[298/300][30/49] Loss: 0.4904
[298/300][35/49] Loss: 0.5110
[298/300][40/49] Loss: 0.5073
[298/300][45/49] Loss: 0.5041
Saving model................
Test set: Average loss: 0.0039, Accuracy: 5081/6230 (81%)
[299/300][0/49] Loss: 0.4723
[299/300][5/49] Loss: 0.5708
[299/300][10/49] Loss: 0.4929
[299/300][15/49] Loss: 0.4954
[299/300][20/49] Loss: 0.4826
[299/300][25/49] Loss: 0.4935
[299/300][30/49] Loss: 0.5174
[299/300][35/49] Loss: 0.5044
[299/300][40/49] Loss: 0.5155
[299/300][45/49] Loss: 0.4840
Saving model................
Test set: Average loss: 0.0042, Accuracy: 4862/6230 (78%)
(49%)
(50%)
(50%)
(50%)
(50%)
(50%)
(50%)
(50%)
(50%)
(50%)
(50%)
(50%)
(50%)
(50%)
(50%)
(50%)
(50%)
(50%)
(50%)
(51%)
(51%)
(52%)
(52%)
(52%)
(52%)
(53%)
(57%)
(57%)
(61%)
(61%)
(62%)
(62%)
(63%)
(65%)
(66%)
(67%)
(68%)
(68%)
(69%)
(69%)
(70%)
(71%)
(71%)
(71%)
(72%)
(72%)
(72%)
(72%)
(73%)
(73%)
(74%)
(74%)
(75%)
(75%)
(75%)
(76%)
(76%)
(76%)
(76%)
(76%)
(76%)
(76%)
(76%)
(76%)
(76%)
(76%)
(77%)
(77%)
(77%)
(78%)
(78%)
(78%)
(78%)
(78%)
(78%)
(78%)
(78%)
(78%)
(78%)
(78%)
(78%)
(78%)
(79%)
(79%)
(79%)
(79%)
(79%)
(79%)
(79%)
(79%)
(79%)
(79%)
(79%)
(79%)
(79%)
(79%)
(79%)
(79%)
(79%)
(79%)
(79%)
(80%)
(80%)
(80%)
(80%)
(80%)
(80%)
(80%)
(80%)
(80%)
(80%)
(80%)
(80%)
(80%)
(80%)
(80%)
(80%)
(80%)
(80%)
(80%)
(80%)
(80%)
(80%)
(80%)
(80%)
(80%)
(80%)
(80%)
(80%)
(80%)
(80%)
(80%)
(81%)
(81%)
(81%)
(81%)
(81%)
(81%)
(81%)
(81%)
(81%)
(81%)
(81%)
(81%)
(81%)
(81%)
(81%)
(81%)
(81%)
(81%)
(81%)
(81%)
(81%)
(81%)
(81%)
(81%)
(81%)
(81%)
(81%)
(81%)
(81%)
(81%)
(81%)
(81%)
(81%)
(81%)
(81%)
(81%)
(81%)
(81%)
(81%)
(81%)
(81%)
(81%)
(81%)
(81%)
(81%)
(81%)
(81%)
(81%)
(81%)
(81%)
(81%)
(81%)
(81%)
(81%)
(81%)
(81%)
(81%)
(81%)
(81%)
(82%)
(82%)
(82%)
(82%)
(82%)
(82%)
(82%)
(82%)
(82%)
(82%)
(82%)
(82%)
(82%)
(82%)
(82%)
(82%)
(82%)
(82%)
(82%)
(82%)
(82%)
(82%)
(82%)
(82%)
(82%)
(82%)
(82%)
(82%)
(82%)
(82%)
(82%)
(82%)
(82%)
(82%)
(82%)
(82%)
(82%)
(82%)
(82%)
(82%)
(82%)
(82%)
(82%)
(82%)
(82%)
(82%)
(82%)
(82%)
(82%)
(82%)
(82%)
(82%)
(82%)
(82%)
(82%)
(82%)
(82%)
(82%)
(82%)
(82%)
(82%)
(82%)
(82%)
(82%)
(82%)
(82%)
(82%)
(82%)
(82%)
(82%)
(83%)
(83%)
(83%)
(83%)
(83%)
(83%)
(83%)
(83%)
(83%)
(83%)
(83%)
(83%)
(83%)
(83%)
(83%)
(83%)
(83%)
(83%)
(83%)
(83%)
(83%)
(83%)
(83%)
(83%)
(83%)
(83%)
(83%)
(83%)
(83%)
(83%)
(83%)
(83%)
(83%)
(83%)
(83%)
(83%)
(83%)
(84%)
5152/6230
